{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English to Indonesian translation using attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Loss function: https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6752, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run !</td>\n",
       "      <td>lari !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who ?</td>\n",
       "      <td>siapa ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow !</td>\n",
       "      <td>wow !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>help !</td>\n",
       "      <td>tolong !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jump !</td>\n",
       "      <td>lompat !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English Indonesian\n",
       "0   run !     lari !\n",
       "1   who ?    siapa ?\n",
       "2   wow !      wow !\n",
       "3  help !   tolong !\n",
       "4  jump !   lompat !"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open('./corpus/eng-indo.txt', 'r')\n",
    "text = fp.read()\n",
    "text = text.splitlines()\n",
    "fp.close()\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "text_dict = {\"English\": [], \"Indonesian\": []}\n",
    "for l in text:\n",
    "    split_text = l.split(\"\\t\")\n",
    "    text_dict[\"English\"].append(normalizeString(split_text[0]))\n",
    "    text_dict[\"Indonesian\"].append(normalizeString(split_text[1]))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(text_dict)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25\n",
    "MIN_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6752, 3)\n",
      "Current shape: (6752, 3)\n",
      "New shape: (6609, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>i m sad .</td>\n",
       "      <td>saya sedih .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>it s me !</td>\n",
       "      <td>ini aku !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>i get it .</td>\n",
       "      <td>aku mengerti .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>i got it .</td>\n",
       "      <td>aku mengerti .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>i m okay .</td>\n",
       "      <td>aku baik baik saja .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     English            Indonesian\n",
       "0     34   i m sad .          saya sedih .\n",
       "1     35   it s me !             ini aku !\n",
       "2     53  i get it .        aku mengerti .\n",
       "3     54  i got it .        aku mengerti .\n",
       "4     57  i m okay .  aku baik baik saja ."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \",\n",
    "    \"tom is\", \"tom s\",\n",
    "    \"what s\", \"what a\",\n",
    "   \"are you\", \"do you\",\n",
    "   \"what is\", \"tom was\",\n",
    "   \"don t\", \"it s\", \"where s\",\n",
    "   \"where did\", \"where is\",\n",
    ")\n",
    "\n",
    "def should_keep_row(row):\n",
    "    \"\"\" Should the current row be kept as training set\"\"\"\n",
    "    # indo_num_words = len(word_tokenize(row[\"Indonesian\"]))\n",
    "    eng_num_words = len(word_tokenize(row[\"English\"]))\n",
    "    max_words_required = MAX_LENGTH - 2\n",
    "    min_words_required = MIN_LENGTH\n",
    "\n",
    "    return min_words_required <= eng_num_words <= max_words_required\n",
    "\n",
    "df[\"keep_row\"] = df.apply(should_keep_row, axis=1)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "print(\"Current shape: \" + str(df.shape))\n",
    "df = df[df[\"keep_row\"]]\n",
    "print(\"New shape: \" + str(df.shape))\n",
    "df.head()\n",
    "df = df.reset_index().drop(columns=[\"keep_row\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First English sentence: ['<s>', 'i', 'm', 'sad', '.', '</s>']\n",
      "First Indo sentence: ['<s>', 'saya', 'sedih', '.', '</s>']\n",
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'saya'), (5, 'sedih'), (6, '!'), (7, 'aku'), (8, 'ini'), (9, 'mengerti')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'i'), (5, 'm'), (6, 'sad'), (7, '!'), (8, 'it'), (9, 'me')]\n",
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'saya'), (5, 'sedih'), (6, '!'), (7, 'aku'), (8, 'ini'), (9, 'mengerti')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'i'), (5, 'm'), (6, 'sad'), (7, '!'), (8, 'it'), (9, 'me')]\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "UNK, UNK_IDX = 'UNK', 2\n",
    "\n",
    "SOS_token = START_IDX\n",
    "EOS_token = END_IDX\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "english_sents = [START] + df['English'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "indo_sents = [START] + df['Indonesian'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First English sentence:', english_sents[0])\n",
    "print('First Indo sentence:', indo_sents[0])\n",
    "\n",
    "english_vocab = Dictionary([['<s>'], ['</s>'],['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])\n",
    "\n",
    "english_vocab = Dictionary([['<s>'], ['</s>'],['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Lets save our dictionaries.\n",
    "#with open('./vocabs/simple_indo_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "#    pickle.dump(indo_vocab, fout)\n",
    "    \n",
    "#with open('./vocabs/simple_english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "#    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0],\n",
       "        [32],\n",
       "        [ 8],\n",
       "        [45],\n",
       "        [15],\n",
       "        [ 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizes a sentence with a given vocab\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END], unknown_word_index=2)\n",
    "\n",
    "# Creates a PyTorch variable from a sentence against a given vocab\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    #print(vsent)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    #print(result)\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Test\n",
    "new_kopi = \"Is it love?\"\n",
    "variable_from_sent(new_kopi, english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5617, 3)\n",
      "(992, 3)\n",
      "berbicara tentang wisata apa kau pernah ke kobe ?\n",
      "('speaking about trips have you ever been to kobe ?', 'berbicara tentang wisata apa kau pernah ke kobe ?')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_val = train_test_split(df, test_size=0.15)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_train.head()\n",
    "\n",
    "indo_tensors = df_train['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(df_train.iloc[0]['Indonesian'])\n",
    "df_train\n",
    "\n",
    "english_tensors = df_train['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "#print(df_train.iloc[0]['English'])\n",
    "#print(english_tensors[0])\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "#print(\"############################\")\n",
    "sent_pairs = list(zip(english_tensors.values, indo_tensors.values))\n",
    "#print(sent_pairs[:5])\n",
    "#print(\"############################\")\n",
    "pairs = list(zip(df_train['English'], df_train['Indonesian']))\n",
    "print(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tom motioned for mary to follow him .', 'tom mengisyaratkan mary untuk mengikutinya .')\n"
     ]
    }
   ],
   "source": [
    "def get_validation_pairs():\n",
    "    indo_val_tensors = df_val['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "    english_val_tensors = df_val['English'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "    val_sent_tensor_pairs = list(zip(english_val_tensors.values, indo_val_tensors.values))\n",
    "    val_sent_pairs = list(zip(df_val['English'], df_val['Indonesian']))\n",
    "    return val_sent_pairs, val_sent_tensor_pairs\n",
    "\n",
    "val_sent_pairs, val_sent_tensor_pairs = get_validation_pairs()\n",
    "print(val_sent_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tom is growing a mustache .', 'tom menumbuhkan kumis .')\n"
     ]
    }
   ],
   "source": [
    "print(val_sent_pairs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tom looked confused .', 'tom terlihat kebingungan .')\n"
     ]
    }
   ],
   "source": [
    "print(val_sent_pairs[154])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom looked confused .\n",
      "[21]\n",
      "[197]\n",
      "[693]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(val_sent_pairs[154][0])\n",
    "\n",
    "for w in val_sent_pairs[154][0].split(' '):\n",
    "    print(english_vocab.doc2idx([w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training and validation loss <- Bug here for evaluation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def get_train_loss(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    #print(\"Train\")\n",
    "    #print(\"Input tensor shape: {0}\".format(input_tensor.shape))\n",
    "    #print(\"Target tensor shape: {0}\".format(target_tensor.shape))\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def get_validation_loss(input_tensor, target_tensor, encoder, decoder, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    #print(\"Validation\")\n",
    "    #print(\"Input tensor shape: {0}\".format(input_tensor.shape))\n",
    "    #print(\"Target tensor shape: {0}\".format(target_tensor.shape))\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss = criterion(decoder_output, target_tensor[di])\n",
    "            total_loss += float(loss.item())\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    return total_loss / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "SAVE_PATH = 'results'\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "  os.makedirs(SAVE_PATH)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop and get evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, batch_size = 1, print_every=1000, save_every=1000, plot_every=100, learning_rate=0.0001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    val_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    #training_pairs = [sent_pairs[i] for i in range(n_iters)]\n",
    "    training_pairs = [random.sample(sent_pairs, batch_size) for i in range(n_iters)]\n",
    "\n",
    "    # training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    num_validation_records = 50\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        #print(\"################################\")\n",
    "        #print(training_pair)\n",
    "        input_tensor = training_pair[0][0]\n",
    "        target_tensor = training_pair[0][1]\n",
    "        #print(\"printing tensors for training...\")\n",
    "        #print(input_tensor)\n",
    "        #print(target_tensor)\n",
    "\n",
    "        loss = get_train_loss(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('Training loss: %s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            total_val_loss = 0\n",
    "            total_val_pairs = len(val_sent_tensor_pairs)\n",
    "            for itr in range(0, num_validation_records):\n",
    "                val_input_tensor = val_sent_tensor_pairs[itr][0]\n",
    "                val_target_tensor = val_sent_tensor_pairs[itr][1]\n",
    "                #print(\"Validation record: {0}\".format(itr))\n",
    "                #print(val_sent_pairs[itr])\n",
    "                val_loss = get_validation_loss(val_input_tensor, val_target_tensor, encoder, decoder, criterion)\n",
    "                total_val_loss += val_loss\n",
    "\n",
    "            avg_val_loss = total_val_loss / total_val_pairs\n",
    "            val_losses.append(avg_val_loss)\n",
    "            print('Validation loss: %s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, avg_val_loss))\n",
    "\n",
    "            print(\"##########################################################\")\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "        # save trained encoder and decoder\n",
    "        if iter % save_every == 0:\n",
    "            encoder_save_path = '%s/%s-%d.pth' % (SAVE_PATH, 'encoder', iter)\n",
    "            print('save encoder weights to ', encoder_save_path)\n",
    "            torch.save(encoder.state_dict(), encoder_save_path)\n",
    "            decoder_save_path = '%s/%s-%d.pth' % (SAVE_PATH, 'decoder', iter)\n",
    "            print('save decoder weights to ', decoder_save_path)\n",
    "            torch.save(decoder.state_dict(), decoder_save_path)\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    showPlot(val_losses)\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        # input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_tensor = variable_from_sent(sentence, english_vocab)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('</s>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(indo_vocab.id2token[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0m 6s (- 8m 24s) (100 1%) 8.3235\n",
      "Validation loss: 0m 7s (- 8m 55s) (100 1%) 0.4184\n",
      "##########################################################\n",
      "Training loss: 0m 14s (- 8m 36s) (200 2%) 8.2784\n",
      "Validation loss: 0m 14s (- 8m 51s) (200 2%) 0.4162\n",
      "##########################################################\n",
      "Training loss: 0m 21s (- 8m 41s) (300 4%) 8.2356\n",
      "Validation loss: 0m 22s (- 8m 52s) (300 4%) 0.4129\n",
      "##########################################################\n",
      "Training loss: 0m 28s (- 8m 34s) (400 5%) 8.1654\n",
      "Validation loss: 0m 29s (- 8m 42s) (400 5%) 0.4094\n",
      "##########################################################\n",
      "Training loss: 0m 36s (- 8m 28s) (500 6%) 8.0912\n",
      "Validation loss: 0m 36s (- 8m 34s) (500 6%) 0.4049\n",
      "##########################################################\n",
      "Training loss: 0m 43s (- 8m 24s) (600 8%) 8.0295\n",
      "Validation loss: 0m 44s (- 8m 29s) (600 8%) 0.4001\n",
      "##########################################################\n",
      "Training loss: 0m 51s (- 8m 17s) (700 9%) 7.9180\n",
      "Validation loss: 0m 51s (- 8m 21s) (700 9%) 0.3942\n",
      "##########################################################\n",
      "Training loss: 0m 58s (- 8m 9s) (800 10%) 7.8683\n",
      "Validation loss: 0m 58s (- 8m 12s) (800 10%) 0.3879\n",
      "##########################################################\n",
      "Training loss: 1m 5s (- 8m 1s) (900 12%) 7.6417\n",
      "Validation loss: 1m 6s (- 8m 4s) (900 12%) 0.3799\n",
      "##########################################################\n",
      "Training loss: 1m 13s (- 7m 55s) (1000 13%) 7.4579\n",
      "Validation loss: 1m 13s (- 7m 58s) (1000 13%) 0.3712\n",
      "##########################################################\n",
      "save encoder weights to  results/encoder-1000.pth\n",
      "save decoder weights to  results/decoder-1000.pth\n",
      "Training loss: 1m 20s (- 7m 47s) (1100 14%) 7.3119\n",
      "Validation loss: 1m 20s (- 7m 50s) (1100 14%) 0.3613\n",
      "##########################################################\n",
      "Training loss: 1m 27s (- 7m 39s) (1200 16%) 7.2604\n",
      "Validation loss: 1m 27s (- 7m 41s) (1200 16%) 0.3506\n",
      "##########################################################\n",
      "Training loss: 1m 34s (- 7m 29s) (1300 17%) 7.0219\n",
      "Validation loss: 1m 34s (- 7m 31s) (1300 17%) 0.3319\n",
      "##########################################################\n",
      "Training loss: 1m 40s (- 7m 19s) (1400 18%) 6.8385\n",
      "Validation loss: 1m 41s (- 7m 21s) (1400 18%) 0.3217\n",
      "##########################################################\n",
      "Training loss: 1m 48s (- 7m 12s) (1500 20%) 6.6766\n",
      "Validation loss: 1m 48s (- 7m 13s) (1500 20%) 0.3116\n",
      "##########################################################\n",
      "Training loss: 1m 54s (- 7m 1s) (1600 21%) 6.1970\n",
      "Validation loss: 1m 54s (- 7m 2s) (1600 21%) 0.2804\n",
      "##########################################################\n",
      "Training loss: 2m 1s (- 6m 53s) (1700 22%) 6.3780\n",
      "Validation loss: 2m 1s (- 6m 55s) (1700 22%) 0.2942\n",
      "##########################################################\n",
      "Training loss: 2m 8s (- 6m 46s) (1800 24%) 6.1564\n",
      "Validation loss: 2m 8s (- 6m 47s) (1800 24%) 0.2603\n",
      "##########################################################\n",
      "Training loss: 2m 14s (- 6m 37s) (1900 25%) 5.7228\n",
      "Validation loss: 2m 15s (- 6m 38s) (1900 25%) 0.2477\n",
      "##########################################################\n",
      "Training loss: 2m 21s (- 6m 29s) (2000 26%) 5.6951\n",
      "Validation loss: 2m 21s (- 6m 30s) (2000 26%) 0.2460\n",
      "##########################################################\n",
      "save encoder weights to  results/encoder-2000.pth\n",
      "save decoder weights to  results/decoder-2000.pth\n",
      "Training loss: 2m 27s (- 6m 19s) (2100 28%) 5.6144\n",
      "Validation loss: 2m 27s (- 6m 20s) (2100 28%) 0.2373\n",
      "##########################################################\n",
      "Training loss: 2m 33s (- 6m 9s) (2200 29%) 5.3827\n",
      "Validation loss: 2m 33s (- 6m 10s) (2200 29%) 0.2357\n",
      "##########################################################\n",
      "Training loss: 2m 39s (- 6m 0s) (2300 30%) 5.3300\n",
      "Validation loss: 2m 39s (- 6m 1s) (2300 30%) 0.2039\n",
      "##########################################################\n",
      "Training loss: 2m 45s (- 5m 51s) (2400 32%) 5.3764\n",
      "Validation loss: 2m 45s (- 5m 51s) (2400 32%) 0.2029\n",
      "##########################################################\n",
      "Training loss: 2m 51s (- 5m 42s) (2500 33%) 5.5027\n",
      "Validation loss: 2m 51s (- 5m 43s) (2500 33%) 0.2006\n",
      "##########################################################\n",
      "Training loss: 2m 56s (- 5m 33s) (2600 34%) 4.9101\n",
      "Validation loss: 2m 57s (- 5m 33s) (2600 34%) 0.1908\n",
      "##########################################################\n",
      "Training loss: 3m 2s (- 5m 24s) (2700 36%) 4.9532\n",
      "Validation loss: 3m 3s (- 5m 25s) (2700 36%) 0.1547\n",
      "##########################################################\n",
      "Training loss: 3m 8s (- 5m 16s) (2800 37%) 4.4969\n",
      "Validation loss: 3m 8s (- 5m 16s) (2800 37%) 0.1536\n",
      "##########################################################\n",
      "Training loss: 3m 15s (- 5m 9s) (2900 38%) 4.9060\n",
      "Validation loss: 3m 15s (- 5m 9s) (2900 38%) 0.1531\n",
      "##########################################################\n",
      "Training loss: 3m 20s (- 5m 1s) (3000 40%) 4.6005\n",
      "Validation loss: 3m 21s (- 5m 1s) (3000 40%) 0.1519\n",
      "##########################################################\n",
      "save encoder weights to  results/encoder-3000.pth\n",
      "save decoder weights to  results/decoder-3000.pth\n",
      "Training loss: 3m 26s (- 4m 53s) (3100 41%) 4.3129\n",
      "Validation loss: 3m 26s (- 4m 53s) (3100 41%) 0.1507\n",
      "##########################################################\n",
      "Training loss: 3m 32s (- 4m 44s) (3200 42%) 4.4934\n",
      "Validation loss: 3m 32s (- 4m 45s) (3200 42%) 0.1497\n",
      "##########################################################\n",
      "Training loss: 3m 37s (- 4m 37s) (3300 44%) 4.3612\n",
      "Validation loss: 3m 37s (- 4m 37s) (3300 44%) 0.1487\n",
      "##########################################################\n",
      "Training loss: 3m 43s (- 4m 29s) (3400 45%) 4.5194\n",
      "Validation loss: 3m 43s (- 4m 29s) (3400 45%) 0.1456\n",
      "##########################################################\n",
      "Training loss: 3m 49s (- 4m 21s) (3500 46%) 4.3188\n",
      "Validation loss: 3m 49s (- 4m 22s) (3500 46%) 0.1374\n",
      "##########################################################\n",
      "Training loss: 3m 55s (- 4m 14s) (3600 48%) 4.0814\n",
      "Validation loss: 3m 55s (- 4m 15s) (3600 48%) 0.1364\n",
      "##########################################################\n",
      "Training loss: 4m 1s (- 4m 7s) (3700 49%) 4.2076\n",
      "Validation loss: 4m 1s (- 4m 7s) (3700 49%) 0.1355\n",
      "##########################################################\n",
      "Training loss: 4m 6s (- 4m 0s) (3800 50%) 4.2098\n",
      "Validation loss: 4m 7s (- 4m 0s) (3800 50%) 0.1349\n",
      "##########################################################\n",
      "Training loss: 4m 12s (- 3m 53s) (3900 52%) 4.5439\n",
      "Validation loss: 4m 13s (- 3m 53s) (3900 52%) 0.1346\n",
      "##########################################################\n",
      "Training loss: 4m 18s (- 3m 46s) (4000 53%) 3.7483\n",
      "Validation loss: 4m 18s (- 3m 46s) (4000 53%) 0.0910\n",
      "##########################################################\n",
      "save encoder weights to  results/encoder-4000.pth\n",
      "save decoder weights to  results/decoder-4000.pth\n",
      "Training loss: 4m 24s (- 3m 39s) (4100 54%) 3.8301\n",
      "Validation loss: 4m 24s (- 3m 39s) (4100 54%) 0.0905\n",
      "##########################################################\n",
      "Training loss: 4m 29s (- 3m 31s) (4200 56%) 3.5661\n",
      "Validation loss: 4m 29s (- 3m 32s) (4200 56%) 0.0900\n",
      "##########################################################\n",
      "Training loss: 4m 35s (- 3m 25s) (4300 57%) 3.7549\n",
      "Validation loss: 4m 35s (- 3m 25s) (4300 57%) 0.0894\n",
      "##########################################################\n",
      "Training loss: 4m 41s (- 3m 18s) (4400 58%) 3.7552\n",
      "Validation loss: 4m 41s (- 3m 18s) (4400 58%) 0.0890\n",
      "##########################################################\n",
      "Training loss: 4m 46s (- 3m 11s) (4500 60%) 3.8334\n",
      "Validation loss: 4m 47s (- 3m 11s) (4500 60%) 0.1439\n",
      "##########################################################\n",
      "Training loss: 4m 52s (- 3m 4s) (4600 61%) 3.8476\n",
      "Validation loss: 4m 52s (- 3m 4s) (4600 61%) 0.1750\n",
      "##########################################################\n",
      "Training loss: 4m 58s (- 2m 57s) (4700 62%) 4.3939\n",
      "Validation loss: 4m 59s (- 2m 58s) (4700 62%) 0.1740\n",
      "##########################################################\n",
      "Training loss: 5m 5s (- 2m 51s) (4800 64%) 4.3881\n",
      "Validation loss: 5m 5s (- 2m 52s) (4800 64%) 0.1819\n",
      "##########################################################\n",
      "Training loss: 5m 12s (- 2m 45s) (4900 65%) 4.4022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 5m 12s (- 2m 45s) (4900 65%) 0.1810\n",
      "##########################################################\n",
      "Training loss: 5m 19s (- 2m 39s) (5000 66%) 4.3425\n",
      "Validation loss: 5m 19s (- 2m 39s) (5000 66%) 0.1800\n",
      "##########################################################\n",
      "save encoder weights to  results/encoder-5000.pth\n",
      "save decoder weights to  results/decoder-5000.pth\n",
      "Training loss: 5m 25s (- 2m 33s) (5100 68%) 4.6559\n",
      "Validation loss: 5m 25s (- 2m 33s) (5100 68%) 0.1792\n",
      "##########################################################\n",
      "Training loss: 5m 31s (- 2m 26s) (5200 69%) 4.4214\n",
      "Validation loss: 5m 31s (- 2m 26s) (5200 69%) 0.1787\n",
      "##########################################################\n",
      "Training loss: 5m 37s (- 2m 20s) (5300 70%) 4.4527\n",
      "Validation loss: 5m 37s (- 2m 20s) (5300 70%) 0.1784\n",
      "##########################################################\n",
      "Training loss: 5m 43s (- 2m 13s) (5400 72%) 4.5230\n",
      "Validation loss: 5m 44s (- 2m 13s) (5400 72%) 0.1776\n",
      "##########################################################\n",
      "Training loss: 5m 49s (- 2m 7s) (5500 73%) 4.4748\n",
      "Validation loss: 5m 50s (- 2m 7s) (5500 73%) 0.1771\n",
      "##########################################################\n",
      "Training loss: 5m 56s (- 2m 0s) (5600 74%) 4.1721\n",
      "Validation loss: 5m 56s (- 2m 1s) (5600 74%) 0.1763\n",
      "##########################################################\n",
      "Training loss: 6m 2s (- 1m 54s) (5700 76%) 4.5572\n",
      "Validation loss: 6m 2s (- 1m 54s) (5700 76%) 0.1760\n",
      "##########################################################\n",
      "Training loss: 6m 8s (- 1m 48s) (5800 77%) 4.3978\n",
      "Validation loss: 6m 9s (- 1m 48s) (5800 77%) 0.1756\n",
      "##########################################################\n",
      "Training loss: 6m 15s (- 1m 41s) (5900 78%) 4.3778\n",
      "Validation loss: 6m 15s (- 1m 41s) (5900 78%) 0.1751\n",
      "##########################################################\n",
      "Training loss: 6m 21s (- 1m 35s) (6000 80%) 4.2869\n",
      "Validation loss: 6m 21s (- 1m 35s) (6000 80%) 0.1747\n",
      "##########################################################\n",
      "save encoder weights to  results/encoder-6000.pth\n",
      "save decoder weights to  results/decoder-6000.pth\n",
      "Training loss: 6m 27s (- 1m 28s) (6100 81%) 4.4275\n",
      "Validation loss: 6m 28s (- 1m 29s) (6100 81%) 0.1743\n",
      "##########################################################\n",
      "Training loss: 6m 33s (- 1m 22s) (6200 82%) 4.4081\n",
      "Validation loss: 6m 34s (- 1m 22s) (6200 82%) 0.1740\n",
      "##########################################################\n",
      "Training loss: 6m 40s (- 1m 16s) (6300 84%) 4.3717\n",
      "Validation loss: 6m 40s (- 1m 16s) (6300 84%) 0.1736\n",
      "##########################################################\n",
      "Training loss: 6m 46s (- 1m 9s) (6400 85%) 4.3890\n",
      "Validation loss: 6m 46s (- 1m 9s) (6400 85%) 0.1729\n",
      "##########################################################\n",
      "Training loss: 6m 52s (- 1m 3s) (6500 86%) 4.3045\n",
      "Validation loss: 6m 52s (- 1m 3s) (6500 86%) 0.1725\n",
      "##########################################################\n",
      "Training loss: 6m 58s (- 0m 57s) (6600 88%) 4.1944\n",
      "Validation loss: 6m 58s (- 0m 57s) (6600 88%) 0.1721\n",
      "##########################################################\n",
      "Training loss: 7m 4s (- 0m 50s) (6700 89%) 4.2070\n",
      "Validation loss: 7m 4s (- 0m 50s) (6700 89%) 0.1717\n",
      "##########################################################\n",
      "Training loss: 7m 10s (- 0m 44s) (6800 90%) 4.3006\n",
      "Validation loss: 7m 11s (- 0m 44s) (6800 90%) 0.1715\n",
      "##########################################################\n",
      "Training loss: 7m 18s (- 0m 38s) (6900 92%) 4.0455\n",
      "Validation loss: 7m 18s (- 0m 38s) (6900 92%) 0.1709\n",
      "##########################################################\n",
      "Training loss: 7m 24s (- 0m 31s) (7000 93%) 4.2630\n",
      "Validation loss: 7m 24s (- 0m 31s) (7000 93%) 0.1708\n",
      "##########################################################\n",
      "save encoder weights to  results/encoder-7000.pth\n",
      "save decoder weights to  results/decoder-7000.pth\n",
      "Training loss: 7m 30s (- 0m 25s) (7100 94%) 4.0192\n",
      "Validation loss: 7m 31s (- 0m 25s) (7100 94%) 0.1706\n",
      "##########################################################\n",
      "Training loss: 7m 36s (- 0m 19s) (7200 96%) 4.0938\n",
      "Validation loss: 7m 37s (- 0m 19s) (7200 96%) 0.1704\n",
      "##########################################################\n",
      "Training loss: 7m 43s (- 0m 12s) (7300 97%) 4.1190\n",
      "Validation loss: 7m 43s (- 0m 12s) (7300 97%) 0.1693\n",
      "##########################################################\n",
      "Training loss: 7m 49s (- 0m 6s) (7400 98%) 4.2635\n",
      "Validation loss: 7m 49s (- 0m 6s) (7400 98%) 0.1692\n",
      "##########################################################\n",
      "Training loss: 7m 55s (- 0m 0s) (7500 100%) 4.1953\n",
      "Validation loss: 7m 55s (- 0m 0s) (7500 100%) 0.1687\n",
      "##########################################################\n",
      "> why was this a secret ?\n",
      "= mengapa ini rahasia ?\n",
      "< <s> <s> tom . </s>\n",
      "\n",
      "> my dog likes you .\n",
      "= anjingku menyukaimu .\n",
      "< <s> <s> aku . </s>\n",
      "\n",
      "> it s time to go .\n",
      "= sudah waktunya untuk pergi .\n",
      "< <s> <s> tom . </s>\n",
      "\n",
      "> how often do you go abroad ?\n",
      "= seberapa sering kamu pergi ke luar negeri ?\n",
      "< <s> <s> tom . </s>\n",
      "\n",
      "> where is the railroad station ?\n",
      "= stasiun kereta ada di mana ?\n",
      "< <s> <s> tom . </s>\n",
      "\n",
      "> call my husband .\n",
      "= panggil suamiku .\n",
      "< <s> <s> tom . </s>\n",
      "\n",
      "> that isn t enough .\n",
      "= itu tidak cukup .\n",
      "< <s> <s> tom . </s>\n",
      "\n",
      "> tom is good with his hands and has built many interesting things .\n",
      "= tom memiliki tangan yang kreatif dan telah membuat berbagai benda yang menarik .\n",
      "< <s> <s> tom . </s>\n",
      "\n",
      "> we didn t learn a thing .\n",
      "= kita tidak mengambil hikmah sama sekali .\n",
      "< <s> <s> aku . </s>\n",
      "\n",
      "> my home is in the country .\n",
      "= rumahku di kampung .\n",
      "< <s> <s> aku . </s>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH/pJREFUeJzt3Xt8nHWB7/HPb67JZJKZXCZtmgtp0kLvtDRyV0QBqa54AQ+wq+JRcVU8yqrrgfXsqrseb7gCe2QXEHbVVVFggUV2EVkUDngBUtJS2tL7JZe2SdpcJ5kkk/ntHzMpKS1N2s7kmZl8369XXslMnk6+ZMJ3nvk9v+f3GGstIiKSX1xOBxARkfRTuYuI5CGVu4hIHlK5i4jkIZW7iEgeUrmLiOQhlbuISB5SuYuI5CGVu4hIHvI49YMrKipsfX29Uz9eRCQnrV27tttaG5lqO8fKvb6+nubmZqd+vIhITjLG7JnOdhqWERHJQyp3EZE8pHIXEclDKncRkTykchcRyUMqdxGRPKRyFxHJQzlX7utae/n+b7axvXPA6SgiIlnLsZOYTtbzOw/y3V9v5bu/3kpjpIjLl81lzbIqllWHnI4mIpI1jFMXyG5qarIne4bq/r4YT27az6827uePOw8xnrCcPb+MGy5ewFsWVmCMSXNaEZHsYIxZa61tmnK7XCz3yXqiozzc0s4Pnt3Jvr4YS+eVcMPFC7h86VxcLpW8iOSXWVPuE0bjCR5paefOZ3awszvKornFfP7S07l0yRztyYtI3ph15T5hPGF57OUObvuvbezqjnJmbZgvXnY6Fy7QcI2I5L7plnvOzZaZittleM/Kap78i7fwnStX0D0wwofufYHrf7yW/X0xp+OJiMyIvCv3CR63i//xplp+88WLuHnNIp7b3sWl33uGnz2/l0TCmXcrIiIzJW/LfYLf4+bPL2rkiRvfwrLqEH/18Aau/cEf2XMw6nQ0EZGMmVa5G2MuN8ZsMcZsN8bcdJztrjLGWGPMlONBM+208iJ+dv05fPvK5Wza1887b3+WB5pbceqYg4hIJk1Z7sYYN3AHsAZYAlxrjFlyjO2Kgc8Cz6c7ZLoYY7j6TXU8ceNbWF4T4i8ffJkbfvYSvUOjTkcTEUmr6ey5nw1st9butNaOAj8H3nOM7f4O+A6Q9Uct54UL+enHz+WmNYv49cYDXH7bszy/86DTsURE0mY65V4NtE663Za67zBjzCqg1lr72PEeyBjzCWNMszGmuaur64TDppPbZfjkRY08/OkLKPS5+eC9z/PQS22OZhIRSZfplPuxJocfHqg2xriAW4EvTPVA1tq7rbVN1tqmSGTKi3fPiOU1IR759AU0nVbG5+9fz61PbtU4vIjkvOmUextQO+l2DdAx6XYxsAx42hizGzgXeDQbD6q+kVDAy48+ejZXra7h9qe28YX71zMSH3c6lojISZvOqpAvAguNMfOBduAa4E8nvmmt7QMqJm4bY54GvmitTf/ppxnk87i45aoVnFYW4O+f3EpH3zB3f7iJkgKv09FERE7YlHvu1to48BngCWAzcL+1dqMx5m+NMVdkOuBMMsbwv96+kNuuXknz7h6uueuPdA5k/fFhEZGj5N3aMunyzNYuPvWTtZQHffzrR8+hvqLI6UgiIrN3bZl0uej0CD+7/lwGY3Gu/Kffs6Gtz+lIIiLTpnI/jpW1YR781PkUeJNTJXd2DTodSURkWlTuU2iMBLnv+nNxuwwf+1GzzmYVkZygcp+GuvIAd39oNe09w/z5v65lNJ5wOpKIyHGp3Kepqb6M71y1gud3HeKvHt6gE51EJKtNZ567pLx3VTW7uqPc/tQ2GiJFfPqtC5yOJCJyTCr3E3TjJQvZ1R3llie2sLiqhIvPqHQ6kojIUTQsc4KMMXz7yhUsnlvC5+5r0UU/RCQrqdxPQqHPzV0fWo0xhk/+5CWGR7UOjYhkF5X7SaotC3D7NSt5dX8/Nz/0sg6wikhWUbmfgreeUcnnLzmdR9Z18KPf73Y6jojIYSr3U3TDxQu4ZHElX/+PzVqiQESyhsr9FLlchr//wEoqgn5u/EULsTGNv4uI81TuaRAKeLnlAyvY0RXlW4+/6nQcERGVe7q8eWGEj5xfzw9/v5vntnU7HUdEZjmVexrdtGYRjZEivvjAevqGxpyOIyKzmMo9jQq8bm67ehXdgyP89b+/4nQcEZnFVO5ptrwmxI2XLOTR9R08vmGf03FEZJZSuWfAJy9qZOm8Ev7m0Y30DWt4RkRmnso9AzxuF9++cgWHoqN86/HNTscRkVlI5Z4hy6pDfPzC+dz3Qit/2HHQ6TgiMsuo3DPoxktOp64swF89vEEnN4nIjFK5Z1Chz8033recXd1R/t9vtjkdR0RmEZV7hl24sIKrVtdw1zM72d454HQcEZklVO4z4OY1izAGfv5Cq9NRRGSWULnPgPKgn4vPqOSRdR3ExxNOxxGRWUDlPkPef1YN3YMjPLtd686ISOap3GfIxYsihANeHnqp3ekoIjILqNxniN/j5t0r5vHrjfvpj+msVRHJLJX7DHr/WdWMxBNac0ZEMk7lPoNW1oZpqCji3zQ0IyIZpnKfQcYYrlxdwwu7DtF6aMjpOCKSx1TuM+y9q6oBeKRFe+8ikjkq9xlWHS7kvIZyHmppx1rrdBwRyVMqdwe8/6xqdnVHWbunx+koIpKnVO4OWLO8ivIiH1/75SbGdMaqiGSAyt0BQb+Hr793GRva+7jz6R1OxxGRPKRyd8ia5VVcceY8/uE329jU0e90HBHJMyp3B33tiqWEAz6+8MB6RuManhGR9FG5O6i0yMc33reczfv6+b4u5iEiaaRyd9ilS+bw/rOquePpHbzc1ut0HBHJEyr3LPCVdy8lEvTzhfvX61qrIpIWKvcsECr08u2rVrCtc5Bbn9zqdBwRyQMq9yxx0ekRrj27jruf3cnaPYecjiMiOU7lnkW+/K7FVIcL+cL96xkajTsdR0RymMo9iwT9Hr77gTPZfXCIbz/+qtNxRCSHqdyzzLkN5Xz0gvn86A97+L2utyoiJ0nlnoW+dPkZVIUK+Off7XY6iojkKJV7Firwujm/sYJ1rT1aFlhETorKPUutqgvTPThKW8+w01FEJAep3LPUWXWlALy0V2u+i8iJU7lnqdPnBAn43LTs1ZIEInLiVO5ZyuN2saImRIv23EXkJKjcs9iqulI2dvRrvRkROWEq9yy2qjZMPGHZ2NHndBQRyTEq9yy2auKg6h6Nu4vIiVG5Z7FIsZ/askJaWjXuLiInRuWe5VbVlh5zxsw3/3Mzn/hxswOJRCQXqNyz3Kq6MPv6Yuzre+1kptZDQ9z73C6eerVTB1tF5JhU7lluYtx93aS99zt+u514wjKesGze1+9UNBHJYir3LLekqgSfx0VLa7LcWw8N8eDaNi5bMgeADe2aSSMiR1O5Zzmfx8Xy6hAv7UkeVP3Hp7fjMoavvWcpFUEfL7ep3EXkaCr3HLCqNsyG9j52dUd5oLmNa86upSpUyPLqEBtU7iJyDCr3HLCqrpSReIIbf7EOlzF86q2NACyvCbOtc4DhUR1UFZEjqdxzwKq6MADrW3u5+k3JvXaAFdUhEhY27dPeu4gcSeWeA6pCBcwp8eNzuw7vtQMsrwkBaNxdRI7icTqATM0Yww0XL8BamBcuPHz/nJICKov9GncXkaOo3HPEh8+rP+b9K2pCvKzpkCLyOhqWyXHLq8Ps6BokOhJ3OoqIZBGVe45bURPCWtjYoTNVReQ1Kvcct6x64qCqlgUWkdeo3HNcpNhPVahAyxCIyBFU7nlgeXVI5S4iR1C554EVNSF2dkUZiI05HUVEsoTKPQ8sr0mewfpKuw6qikiSyj0PLE8dVN3QroOqIpKkcs8DZUU+qsOFWoZARA5TueeJFTUhXm7rw1rrdBQRyQIq9zzx5oUR9h4a4uktXU5HEZEsoHLPE1etruG08gDfevxVxhPaexeZ7VTuecLncfGX7ziDLQcGeOilNqfjiIjDVO555F3LqzizJsT3ntxKbExXZxKZzVTuecQYw83vXMy+vhj/8rvdTscREQep3PPMuQ3lvG1RJf/49HZ6oqNOxxERh6jc89D/vnwR0ZE4d/x2u9NRRMQhuhJTHjpjbjFXnlXDPc/t4pmtXZzTUMbZ88s5t6GMyuICp+OJyAxQueepr16xlIZIkD/uPMgjLR385I978boN91z3Ji46PeJ0PBHJMOPUGY1NTU22ubnZkZ8928THE2za18+XHnyZ/f0xfvmZC6ktCzgdS0ROgjFmrbW2aartNOY+C3jcLlbUhLnzg6sZT1g+9dO1miopkudU7rNIfUURt129klfa+/nrR17ROjQieUzlPsu8ffEcPvv2hTywto2fvbDX6TgikiE6oDoLfe7tC1nf2stXH93Ii7sO0VRfRlN9KadXFuNyGafjiUgaqNxnIbfLcPs1K/naLzfx3PZuHlnXAUCo0MtdH1rNuQ3lDicUkVOlcp+lwgEft169EmstrYeGeXH3If7PI6/wq1f2q9xF8oDKfZYzxlBXHqCuPMD9za20tOpSfSL5QAdU5bCVdWE2d/QzEtc0SZFcp3KXw1bVhhkdT7Cpo9/pKCJyilTuctiqulIA1mloRiTnqdzlsDklBVSFCmjZq3IXyXUqdznCytqw9txF8oDKXY6wsjbM3kNDHBwccTqKiJwClbscYWLcfX2b9t5FcpnKXY6wvDqE22U07i6S41TucoRCn5sz5hRr3F0kx6nc5Sgr65IHVRMJLQkskqtU7nKUVbVhBmJxdnYPOh1FRE6Syl2OsqouDKBxd5EcpnKXozRUBCku8GjcXSSHqdzlKC6X4cwancwkkstU7nJMq+rCvLp/gOFRrRApkotU7nJMK2vDjCcsG9r7nI4iIidhWhfrMMZcDtwOuIF7rLXfet33Pw98HIgDXcBHrbV70pxVZtDK2uRB1a88upE31Zcyv6KIhkiQlTVhQgGvw+lEZCpTlrsxxg3cAVwKtAEvGmMetdZumrRZC9BkrR0yxnwK+A5wdSYCy8woD/r5zMULeHZ7Nw+3tDMQiwPgcRnevLCCd62Yx2VL51BSoKIXyUbG2uOfqGKMOQ/4qrX2HanbNwNYa7/5BtuvAr5vrb3geI/b1NRkm5ubTyq0zCxrLd2Do2zvHOTpLZ089vI+2nuH8bldfPTC+dy0ZpHTEUVmDWPMWmtt01TbTWdYphponXS7DTjnONt/DHj8DUJ9AvgEQF1d3TR+tGQDYwyRYj+RYj/nNZZz05pFrGvt5d7ndnHnMzs4sybEmuVVTscUkUmmc0DVHOO+Y+7uG2M+CDQBtxzr+9bau621TdbapkgkMv2UklWMMayqK+XWq1eyoibEzQ9v4EB/zOlYIjLJdMq9DaiddLsG6Hj9RsaYS4AvA1dYa7UY+Czgdbu49eqVxMbG+eID67UWjUgWmU65vwgsNMbMN8b4gGuARydvkBpnv4tksXemP6Zkq8ZIkC+/awnPbuvmx3/Y7XQcEUmZstyttXHgM8ATwGbgfmvtRmPM3xpjrkhtdgsQBB4wxqwzxjz6Bg8neeiD59Rx8RkRvvn4q2w7MOB0HBFhGrNlMkWzZfJL50CMy297lsZIEQ988nyn44jkrenOltEZqpIWlcUF/OnZdby0t5fYmJYsEHGayl3SZum8EsYTli37NTQj4jSVu6TNknklAGza1+9wEhFRuUva1JYGKPZ72NihxcZEnDathcNEpsPlMiyeV8LGDu25Z9Lw6Dh3/f8dWAs1pYVUlxZSEw4wL1yAx639NUlSuUtaLakq4RcvtjKesLhdxzq5WU7FeMLy2Z+38OSmAxgDkye7ed2GurIADZEgDZEiaksDVIcLmRcupCpcoEXeZhmVu6TV0nklDI+Ns6s7yoLKoNNx8oq1lr97bBNPbjrAV9+9hGvPqWN/X4z2nmHaeobZdTDKzq5BdnZFeWZLF6PjiSP+vd/jIlToJVToJRzwUlzgpcjvIeh3U+TzUFrkY25JAVXhAqpChVSFCijwuh36r5VTpXKXtFo6LwTAxo4+lXua3fvcLn74+9187ML5fOSC+QCcVl7EaeVFR207nrB0DYzQ3jtMR+rjYHSUvqEx+obH6B0e5UB/jOhInMGRcaIjcYaPMYU14HNTGvBRHvRRXuRjbqiAuSXJ4p8TKqC4wEOx30NR6iPo9+gdW5ZQuUtaLagM4nUbNu3r5z0rq52Ok5P6hsd4oLmVOSUFzK8oYn5FEc9s7eL//udm1iyby5ffuXjKx3C7TLKIQwWsPq10Wj83NjbOvr4Y+3qH2dcXY39/jJ7oKIeioxyMjtI5MMKG9j66B0eP+zgBn5ug30OwwEOo0EtZwEdpkY/SQPJdQ3GBl6Dfk3xhKPBSUuihpMBLSaFXLw5ppHKXtPJ5XJw+p5hNOqh60h5obuXr/7H5iPuMgVW1YW69eiWuDJVfgdd9+MXkeEbi43T2j7C/P8ZgLM7gSDz1DiBOdGScwZExBkfi9Mfi9A2Nsb8/xuZ9/RwaGiU2ljjuY0PygjAFXjd+j4tCn/vwMFLys49I0E9liZ9IMLkMdXGBh6DfS7DAQ8DrztjvJ9eo3CXtls4r4b82d2KtxRj9j3aiWvb2Uh0u5N6PNLGzK8qu7iiDI3Guf3NDVoyB+z1uassC1JYFTvjfjsTHD78gDMTi9MfG6B+OMxAboz+WfJEYiY8TG0swEh9naGQ8NYw0xv6+AXqGxjgUfeN3DsZA0OehpNCbemeQfHcw+etCr5sCrwu/x334OERFsZ+KoJ+KoI+g35MXf7cqd0m7JVUl3N/cxoH+EeaGCpyOk3Na9vawur6MRXNLWDS3xOk4aeX3uPEH3ZQH/Sf9GGPjCboHR+jsH+FgdISB2KR3DLE4AyPxSS8YY3QOxNjRlXwxGYiNMTY+vfW0XAZcxuBxG/ye5AvCxDuKiRcGv9dF0O+hMRJk4ZwgCyuLmV9RhM/jwmUMLoNjLxQqd0m7pdWvHVRVuZ+Y/X0xOvpiXF8XdjpK1vK6XanZPIUn9e/j4wlG4gliY+PE4gl6h0bpHhyle2CE7sERhkbHsdZigYS1jI1bRsaS7yZi8XFiY+OMxiceI8H+vkGe2txJ/A2uZ2AMlBQkh5bChV5CAR8fOf803rZozin8Fqamcpe0W1yVWoago5+3L87sH3C+adnbA8CquukdBJUT53G78LhdFPmT9VcdPrkXicnGxhPsORhl64FB9hwcYjyRIGGTLw7xcctALDm01DuU/Dwan/rYw6lSuUvaBf0e6ssDOlP1JLS09uLzuFhSlV/DMfnO63axoLKYBZXFTkc5TOcqS0YsnRdi4z6tMXOiXtrTw7J5Jfg8+l9TTo3+giQjlswrofXQMH3DY05HyRmj8QQb2vs4S0MykgYqd8mIieV/N2v532l7dX8/I/GExtslLVTukhFLU+Wucffpe2nPxMFUzZSRU6dyl4yoLC4gUuzXmaonoKW1l7klBcxLw+wNEZW7ZMySqhLWtfbQ3jtM4g3mAMtrWvb2aq9d0kZTISVjzqor5ZmtXVzwrd9Q6HXTWFlEfXkRFUE/pQEfZUVeyoN+FlQGmV9RhHcWX2iie3CEvYeG+OC5dU5HkTyhcpeM+fTFjZzbUMb2rkG2dw6yoyvKK+19HIqO0h+LH7Gt121oqAhy+txiFs0tZklVCYurSphT4s+LdT6m0rK3F9DJS5I+KnfJGK/bxTkN5ZzTUH7U98bGE/QOjXGgP8aOrkG27B9g64EBWvb28Mv1HYe3Kw14aYwEqa8oor48kPpcRF15IK+uLNSytwePy7A8tXSDyKlSuYsjvG4XkeLkkq3LXldo/bExXt03wOZ9/by6v5+dXVGe3dbFg2tHjtiurMhHXVmACxdUcN359USKT34xKqe17O1lybySrFj1UfKDyl2yTkmBl7Pnl3H2/LIj7h8ajbO7e4i9h6LsPjjEnoND7Oga5I6nt3P3szu5anUNn3hzA/VTrEeebeLjCda39fKB1TVOR5E8onKXnBHweVgyr+TwCVITdnYN8oNnd/Jgcxv3vbCX686r5yvvXpIzY/VbDwwyNDrOWdO8YpLIdMze6QmSNxoiQb75/hU8d9PFXPOmOn74+93c+cxOp2NNW0tr6uSlWpW7pI/23CVvVBYX8I33LWNwJM53nniVhkgR71g61+lYU9rRGSXgc1NbppOXJH205y55xRjDLVetYEV1iL/4xTo2dmT/ypRtPUPUlBbmzDCS5AaVu+SdAq+bH3y4iZICL9f/qJnOgZjTkY6rrWeYmtITvx6pyPFoWEbyUmVJAfdc18QH7vwDf/IPz7GiJsT8iiLmVwSprwhQWxpgbqggK86KbesZoqle4+2SXip3yVvLqkPce10TP/7DHnYfjPLstm5GJl3ezGWgKlRIdbiQimIf5UV+KoJ+yoI+gn43AZ+HIp+HcMDL0nklGRk26Rseoz8Wp6ZU4+2SXip3yWvnL6jg/AUVACQSln39MXZ3R2nvGaatZ4i2nmHae4fZsn+Ag9GD9A4d++Iid39oNZdl4OBse88wgIZlJO1U7jJruFyG6nDhcS+IPDaeoGdolOjIONGROP2xMf7snufZtK8/I+Xe1jMEoD13STuVu8gkXreLyuICmHSd45rSQnZ0RTPy89q05y4Z4vzRJJEstyASZHvnYEYeu61nmIDPTWkgfxZBk+ygcheZQmMkyM6uwYxccKStZ4jqsOa4S/qp3EWm0FgZZCSeoL13OO2PnZzjrvF2ST+Vu8gUFlQGAdjelf6hmeTZqRpvl/RTuYtMoTGSLPcdaR53749pjrtkjspdZAplRT5KA960z5jRHHfJJJW7yDQsqAymfc/9tWmQ2nOX9FO5i0xDYyTIjjSPuesEJskklbvINDRGghyMjtITHU3bY7b1DFPodVNW5EvbY4pMULmLTENjZfK6rOnce9c67pJJKneRaVgQSa5HkN5y1xx3yRyVu8g0VJcW4vO40jpjRhfpkExSuYtMg9tlaKgoStsaM/2xMfqGx7TnLhmjcheZpsbK9M2Y0Rx3yTSVu8g0NUaCtB4aIjY2fsqPpTnukmkqd5FpaowUkbCw++Cpj7trjrtkmspdZJomFhDb0ZmOctccd8kslbvINDVUpMo9DePumuMumaZyF5mmQp+b6nBhWmbMaI67ZJrKXeQELEjTjBnNcZdMU7mLnIDkJfeip3TJvYk57tXac5cMUrmLnIDGyiKGx8bp6Dv5S+61axqkzACVu8gJWJC6KtO2Ayc/NNOmE5hkBnicDiCSSyamQ/7PH75I0O+htMhLWZGf0oCXcKGXcMBHOOClrMh3+KO8yE9pkZdQoRe/x6057jIjVO4iJ6A86OfuD61m64GBw+u7H4yOcig6yo6uQXqHxhiIxd/w3wd8bgAKvC7KNcddMkjlLnKCLls6l8uWzn3D74+NJ+gdGuNQdJSD0REORUfpGRqjb2iU3qExeofHWDS3WHPcJaNU7iJp5nW7iBT7iRT7gWKn48gspQOqIiJ5SOUuIpKHVO4iInlI5S4ikodU7iIieUjlLiKSh1TuIiJ5SOUuIpKHjLUnv3TpKf1gY7qAPSf5zyuA7jTGyYRcyAi5kVMZ00MZ08PpjKdZayNTbeRYuZ8KY0yztbbJ6RzHkwsZITdyKmN6KGN65EJG0LCMiEheUrmLiOShXC33u50OMA25kBFyI6cypocypkcuZMzNMXcRETm+XN1zFxGR48i5cjfGXG6M2WKM2W6MucnpPADGmH82xnQaY16ZdF+ZMeZJY8y21OdShzPWGmN+a4zZbIzZaIz5XLblNMYUGGNeMMasT2X8Wur++caY51MZf2GMcfwSRsYYtzGmxRjzWDZmNMbsNsZsMMasM8Y0p+7Lmud6Us6wMeZBY8yrqb/N87IppzHmjNTvcOKj3xhzYzZlfCM5Ve7GGDdwB7AGWAJca4xZ4mwqAH4IXP66+24CnrLWLgSeSt12Uhz4grV2MXAucEPqd5dNOUeAt1lrzwRWApcbY84Fvg3cmsrYA3zMwYwTPgdsnnQ7GzNebK1dOWnaXjY91xNuB35lrV0EnEnyd5o1Oa21W1K/w5XAamAIeDibMr4ha23OfADnAU9Mun0zcLPTuVJZ6oFXJt3eAlSlvq4Ctjid8XV5/x24NFtzAgHgJeAckieMeI71N+BQthqS/0O/DXgMMFmYcTdQ8br7suq5BkqAXaSO/WVrzkm5LgN+l80ZJ3/k1J47UA20TrrdlrovG82x1u4DSH2udDjPYcaYemAV8DxZljM13LEO6ASeBHYAvdbaiatOZ8NzfhvwJSCRul1O9mW0wK+NMWuNMZ9I3ZdVzzXQAHQB/5Ia4rrHGFNE9uWccA1wX+rrbM14WK6V+7GuKKzpPifAGBME/g240Vrb73Se17PWjtvkW+Aa4Gxg8bE2m9lUrzHG/AnQaa1dO/nuY2zq9N/lBdbas0gOYd5gjHmLw3mOxQOcBfyTtXYVECUbhzeA1DGUK4AHnM4yXblW7m1A7aTbNUCHQ1mmcsAYUwWQ+tzpcB6MMV6Sxf5Ta+1DqbuzLieAtbYXeJrk8YGwMWbiYu5OP+cXAFcYY3YDPyc5NHMb2ZURa21H6nMnyTHis8m+57oNaLPWPp+6/SDJss+2nJB8kXzJWnsgdTsbMx4h18r9RWBhamaCj+TbpEcdzvRGHgWuS319HckxbscYYwxwL7DZWvu9Sd/KmpzGmIgxJpz6uhC4hOQBtt8CV6U2czSjtfZma22Ntbae5N/fb6y1f0YWZTTGFBljiie+JjlW/ApZ9FwDWGv3A63GmDNSd70d2ESW5Uy5lteGZCA7Mx7J6UH/kzio8U5gK8mx2C87nSeV6T5gHzBGcm/kYyTHYZ8CtqU+lzmc8UKSQwUvA+tSH+/MppzACqAllfEV4G9S9zcALwDbSb4t9jv9nKdyvRV4LNsyprKsT31snPj/JJue60lZVwLNqef8EaA023KSPLh/EAhNui+rMh7rQ2eoiojkoVwblhERkWlQuYuI5CGVu4hIHlK5i4jkIZW7iEgeUrmLiOQhlbuISB5SuYuI5KH/Bn5CwFnZvW22AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(len(english_vocab), hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, len(indo_vocab), dropout_p=0.001).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 7500, print_every=100)\n",
    "\n",
    "evaluateRandomly(encoder1, attn_decoder1)\n",
    "\n",
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"do you love me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check some translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = tom is playing with ball.\n",
      "output = <s> <s> aku . </s>\n",
      "input = she is standing there .\n",
      "output = <s> <s> aku . </s>\n",
      "input = he is a bad man .\n",
      "output = <s> <s> aku . </s>\n",
      "input = he wants to sleep .\n",
      "output = <s> <s> tom . </s>\n"
     ]
    }
   ],
   "source": [
    "def translate(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "\n",
    "translate(\"tom is playing with ball.\")\n",
    "\n",
    "translate(\"she is standing there .\")\n",
    "\n",
    "translate(\"he is a bad man .\")\n",
    "\n",
    "translate(\"he wants to sleep .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
