{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English to Indonesian translation using attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Loss function: https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6752, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run !</td>\n",
       "      <td>lari !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who ?</td>\n",
       "      <td>siapa ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow !</td>\n",
       "      <td>wow !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>help !</td>\n",
       "      <td>tolong !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jump !</td>\n",
       "      <td>lompat !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English Indonesian\n",
       "0   run !     lari !\n",
       "1   who ?    siapa ?\n",
       "2   wow !      wow !\n",
       "3  help !   tolong !\n",
       "4  jump !   lompat !"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open('./corpus/eng-indo.txt', 'r')\n",
    "text = fp.read()\n",
    "text = text.splitlines()\n",
    "fp.close()\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "text_dict = {\"English\": [], \"Indonesian\": []}\n",
    "for l in text:\n",
    "    split_text = l.split(\"\\t\")\n",
    "    text_dict[\"English\"].append(normalizeString(split_text[0]))\n",
    "    text_dict[\"Indonesian\"].append(normalizeString(split_text[1]))\n",
    "    \n",
    "df = pd.DataFrame.from_dict(text_dict)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25\n",
    "MIN_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6752, 3)\n",
      "Current shape: (6752, 3)\n",
      "New shape: (6609, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>i m sad .</td>\n",
       "      <td>saya sedih .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>it s me !</td>\n",
       "      <td>ini aku !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>i get it .</td>\n",
       "      <td>aku mengerti .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>i got it .</td>\n",
       "      <td>aku mengerti .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>i m okay .</td>\n",
       "      <td>aku baik baik saja .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     English            Indonesian\n",
       "0     34   i m sad .          saya sedih .\n",
       "1     35   it s me !             ini aku !\n",
       "2     53  i get it .        aku mengerti .\n",
       "3     54  i got it .        aku mengerti .\n",
       "4     57  i m okay .  aku baik baik saja ."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \",\n",
    "    \"tom is\", \"tom s\",\n",
    "    \"what s\", \"what a\",\n",
    "   \"are you\", \"do you\",\n",
    "   \"what is\", \"tom was\",\n",
    "   \"don t\", \"it s\", \"where s\",\n",
    "   \"where did\", \"where is\",\n",
    ")\n",
    "\n",
    "def should_keep_row(row):\n",
    "    \"\"\" Should the current row be kept as training set\"\"\"\n",
    "    # indo_num_words = len(word_tokenize(row[\"Indonesian\"]))\n",
    "    eng_num_words = len(word_tokenize(row[\"English\"]))\n",
    "    max_words_required = MAX_LENGTH - 2\n",
    "    min_words_required = MIN_LENGTH\n",
    "\n",
    "    return min_words_required <= eng_num_words <= max_words_required\n",
    "\n",
    "df[\"keep_row\"] = df.apply(should_keep_row, axis=1)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "print(\"Current shape: \" + str(df.shape))\n",
    "df = df[df[\"keep_row\"]]\n",
    "print(\"New shape: \" + str(df.shape))\n",
    "df.head()\n",
    "df = df.reset_index().drop(columns=[\"keep_row\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First English sentence: ['<s>', 'i', 'm', 'sad', '.', '</s>']\n",
      "First Indo sentence: ['<s>', 'saya', 'sedih', '.', '</s>']\n",
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'saya'), (5, 'sedih'), (6, '!'), (7, 'aku'), (8, 'ini'), (9, 'mengerti')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'i'), (5, 'm'), (6, 'sad'), (7, '!'), (8, 'it'), (9, 'me')]\n",
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'saya'), (5, 'sedih'), (6, '!'), (7, 'aku'), (8, 'ini'), (9, 'mengerti')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '.'), (4, 'i'), (5, 'm'), (6, 'sad'), (7, '!'), (8, 'it'), (9, 'me')]\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "UNK, UNK_IDX = 'UNK', 2\n",
    "\n",
    "SOS_token = START_IDX\n",
    "EOS_token = END_IDX\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "english_sents = [START] + df['English'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "indo_sents = [START] + df['Indonesian'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First English sentence:', english_sents[0])\n",
    "print('First Indo sentence:', indo_sents[0])\n",
    "\n",
    "english_vocab = Dictionary([['<s>'], ['</s>'],['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])\n",
    "\n",
    "english_vocab = Dictionary([['<s>'], ['</s>'],['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Lets save our dictionaries.\n",
    "#with open('./vocabs/simple_indo_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "#    pickle.dump(indo_vocab, fout)\n",
    "    \n",
    "#with open('./vocabs/simple_english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "#    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0],\n",
       "        [32],\n",
       "        [ 8],\n",
       "        [45],\n",
       "        [15],\n",
       "        [ 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizes a sentence with a given vocab\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END], unknown_word_index=2)\n",
    "\n",
    "# Creates a PyTorch variable from a sentence against a given vocab\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    #print(vsent)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    #print(result)\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Test\n",
    "new_kopi = \"Is it love?\"\n",
    "variable_from_sent(new_kopi, english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5617, 3)\n",
      "(992, 3)\n",
      "aku suka pergi ke bioskop .\n",
      "('i like going to the movies .', 'aku suka pergi ke bioskop .')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_val = train_test_split(df, test_size=0.15)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_train.head()\n",
    "\n",
    "indo_tensors = df_train['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(df_train.iloc[0]['Indonesian'])\n",
    "df_train\n",
    "\n",
    "english_tensors = df_train['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "#print(df_train.iloc[0]['English'])\n",
    "#print(english_tensors[0])\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "#print(\"############################\")\n",
    "sent_pairs = list(zip(english_tensors.values, indo_tensors.values))\n",
    "#print(sent_pairs[:5])\n",
    "#print(\"############################\")\n",
    "pairs = list(zip(df_train['English'], df_train['Indonesian']))\n",
    "print(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nobody must know .', 'tidak ada yang harus tahu .')\n"
     ]
    }
   ],
   "source": [
    "def get_validation_pairs():\n",
    "    indo_val_tensors = df_val['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "    english_val_tensors = df_val['English'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "    val_sent_tensor_pairs = list(zip(english_val_tensors.values, indo_val_tensors.values))\n",
    "    val_sent_pairs = list(zip(df_val['English'], df_val['Indonesian']))\n",
    "    return val_sent_pairs, val_sent_tensor_pairs\n",
    "\n",
    "val_sent_pairs, val_sent_tensor_pairs = get_validation_pairs()\n",
    "print(val_sent_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tom practiced every day at home .', 'tom berlatih setiap hari di rumah .')\n"
     ]
    }
   ],
   "source": [
    "print(val_sent_pairs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('we have important work to do .', 'kita memiliki pekerjaan penting yang harus dilakukan .')\n"
     ]
    }
   ],
   "source": [
    "print(val_sent_pairs[154])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have important work to do .\n",
      "[115]\n",
      "[75]\n",
      "[1393]\n",
      "[441]\n",
      "[71]\n",
      "[66]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(val_sent_pairs[154][0])\n",
    "\n",
    "for w in val_sent_pairs[154][0].split(' '):\n",
    "    print(english_vocab.doc2idx([w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training and validation loss <- Bug here for evaluation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def get_train_loss(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    print(\"Train\")\n",
    "    print(\"Input tensor shape: {0}\".format(input_tensor.shape))\n",
    "    print(\"Target tensor shape: {0}\".format(target_tensor.shape))\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def get_validation_loss(input_tensor, target_tensor, encoder, decoder, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    print(\"Validation\")\n",
    "    print(\"Input tensor shape: {0}\".format(input_tensor.shape))\n",
    "    print(\"Target tensor shape: {0}\".format(target_tensor.shape))\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss = criterion(decoder_output, target_tensor[di])\n",
    "            total_loss += float(loss.item())\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    return total_loss / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "SAVE_PATH = 'results'\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "  os.makedirs(SAVE_PATH)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop and get evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, batch_size = 1, print_every=1000, save_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    #training_pairs = [sent_pairs[i] for i in range(n_iters)]\n",
    "    training_pairs = [random.sample(sent_pairs, batch_size) for i in range(n_iters)]\n",
    "\n",
    "    # training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        #print(\"################################\")\n",
    "        #print(training_pair)\n",
    "        input_tensor = training_pair[0][0]\n",
    "        target_tensor = training_pair[0][1]\n",
    "        #print(\"printing tensors for training...\")\n",
    "        #print(input_tensor)\n",
    "        #print(target_tensor)\n",
    "\n",
    "        loss = get_train_loss(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('Training loss: %s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            total_val_loss = 0\n",
    "            total_val_pairs = len(val_sent_tensor_pairs)\n",
    "            for itr in range(total_val_pairs):\n",
    "                val_input_tensor = val_sent_tensor_pairs[itr][0]\n",
    "                val_target_tensor = val_sent_tensor_pairs[itr][1]\n",
    "                print(\"Validation record: {0}\".format(itr))\n",
    "                print(val_sent_pairs[itr])\n",
    "                val_loss = get_validation_loss(val_input_tensor, val_target_tensor, encoder, decoder, criterion)\n",
    "                total_val_loss += val_loss\n",
    "\n",
    "            avg_val_loss = total_val_loss / total_val_pairs\n",
    "            print('Validation loss: %s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, avg_val_loss))\n",
    "\n",
    "            print(\"##########################################################\")\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "        # save trained encoder and decoder\n",
    "        if iter % save_every == 0:\n",
    "            encoder_save_path = '%s/%s-%d.pth' % (SAVE_PATH, 'encoder', iter)\n",
    "            print('save encoder weights to ', encoder_save_path)\n",
    "            torch.save(encoder.state_dict(), encoder_save_path)\n",
    "            decoder_save_path = '%s/%s-%d.pth' % (SAVE_PATH, 'decoder', iter)\n",
    "            print('save decoder weights to ', decoder_save_path)\n",
    "            torch.save(decoder.state_dict(), decoder_save_path)\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        # input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_tensor = variable_from_sent(sentence, english_vocab)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('</s>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(indo_vocab.id2token[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Input tensor shape: torch.Size([14, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([14, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([12, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([14, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([13, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([12, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([13, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([12, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([17, 1])\n",
      "Target tensor shape: torch.Size([14, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([12, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([12, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([13, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([13, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([13, 1])\n",
      "Target tensor shape: torch.Size([14, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([14, 1])\n",
      "Target tensor shape: torch.Size([14, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Train\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Training loss: 0m 6s (- 8m 10s) (100 1%) 4.9444\n",
      "Validation record: 0\n",
      "('nobody must know .', 'tidak ada yang harus tahu .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 1\n",
      "('he is eager to become famous .', 'dia ingin menjadi terkenal .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 2\n",
      "('tom needs a cab .', 'tom butuh taksi .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 3\n",
      "('tom persuaded mary to join our band .', 'tom membujuk mary bergabung dengan band kami .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 4\n",
      "('this is good sushi .', 'ini adalah sushi yang enak .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 5\n",
      "('many roads are flooded . as a result there are long delays .', 'beberapa jalan raya banjir . akibatnya terdapat penundaan yang lama .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([15, 1])\n",
      "Target tensor shape: torch.Size([13, 1])\n",
      "Validation record: 6\n",
      "('did you have fun ?', 'apa kamu senang ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 7\n",
      "('i haven t heard of him since then .', 'saya tidak mendengar kabarnya semenjak itu .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 8\n",
      "('that isn t enough .', 'itu tidak cukup .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 9\n",
      "('do you want to give it a try ?', 'anda mau mencobanya ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 10\n",
      "('that s cyanide .', 'itu sianida .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Validation record: 11\n",
      "('my father is not talkative .', 'ayahku tidak suka banyak bicara .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 12\n",
      "('tom looks upset .', 'tom terlihat sedih .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 13\n",
      "('their offer to buy the house was rejected .', 'tawaran mereka untuk membeli rumah itu ditolak .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 14\n",
      "('my brother is always acting foolishly .', 'adikku selalu bertingkah konyol .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 15\n",
      "('what grade is your sister in ?', 'adikmu kelas berapa ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 16\n",
      "('may i hang up your coat ?', 'boleh kugantungkan jasmu ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 17\n",
      "('it s exactly as you say it is .', 'tepat seperti apa yang anda katakan .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 18\n",
      "('would you like something to eat ?', 'apa kau ingin makan sesuatu ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 19\n",
      "('i always have a couple of beach towels in my car .', 'aku selalu punya beberapa handuk pantai di mobilku .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([14, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Validation record: 20\n",
      "('his data is often inaccurate .', 'datanya sering tidak akurat .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 21\n",
      "('tom waited for the applause to die down before he announced the next song .', 'tom menunggu tepuk tangan mereda sebelum dia mengumumkan lagu selanjutnya .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([17, 1])\n",
      "Target tensor shape: torch.Size([13, 1])\n",
      "Validation record: 22\n",
      "('it is unfortunately true .', 'sayang benar .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Validation record: 23\n",
      "('tom accepts that what mary said was the truth .', 'tom menerima bahwa apa yang dikatakan mary adalah kenyataan .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([12, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Validation record: 24\n",
      "('tom needs to change his lifestyle .', 'tom perlu mengubah gaya hidupnya .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 25\n",
      "('tom didn t have to be so formal .', 'tom tidak perlu seformal itu .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 26\n",
      "('we prepared for an attack .', 'kami bersiap untuk melancarkan serangan .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 27\n",
      "('do you mind turning on the tv ?', 'bisa minta tolong nyalakan tv nya ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 28\n",
      "('there is no easy road to learning .', 'tidak ada jalan yang mudah untuk belajar .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 29\n",
      "('you may choose whichever book you like .', 'kau boleh memilih buku manapun yang kau suka .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Validation record: 30\n",
      "('paris is the capital of france .', 'paris adalah ibukota dari prancis .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 31\n",
      "('i was born on march .', 'saya lahir pada tanggal maret .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 32\n",
      "('i think you ve got the flu .', 'saya kira anda terkena flu .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 33\n",
      "('enjoy your meal !', 'nikmati makananmu !')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([6, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Validation record: 34\n",
      "('that s what makes the difference .', 'hal itulah yang membuat perbedaan .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 35\n",
      "('the faucet is leaking .', 'kerannya bocor .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Validation record: 36\n",
      "('don t scare me like that !', 'jangan menakut nakutiku seperti itu !')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 37\n",
      "('she was born and brought up in osaka .', 'dia dilahirkan dan dibesarkan di osaka .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 38\n",
      "('do it your own way if you don t like my way .', 'lakukan caramu sendiri kalau kamu tidak menyukai caraku .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([15, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Validation record: 39\n",
      "('tom could tell that mary was pretty scared .', 'tom dapat mengatakan bahwa mary cukup ketakutan .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 40\n",
      "('anything you could do in support of their effort would be very much appreciated .', 'kami sangat mengharapkan bantuan anda dalam mendukung upaya mereka .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([17, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Validation record: 41\n",
      "('i told tom we could do it today .', 'aku memberitahu tom kalau kita bisa melakukannya hari ini .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Validation record: 42\n",
      "('he felt lost and uncomfortable .', 'dia merasa bingung dan tidak nyaman .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 43\n",
      "('everybody was thrilled by his story .', 'semua orang merasa tegang karena ceritanya .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 44\n",
      "('i don t think you re crazy .', 'aku tidak berpikir kalau kau gila .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 45\n",
      "('we have to transmit our culture to the next generation .', 'kita harus mewariskan budaya kita pada generasi berikutnya .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([13, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Validation record: 46\n",
      "('these are gifts for my friends .', 'ini hadiah untuk teman temanku .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([8, 1])\n",
      "Validation record: 47\n",
      "('i m a human being .', 'aku adalah manusia .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 48\n",
      "('it doesn t look so bad .', 'itu tidak terlalu terlihat buruk')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 49\n",
      "('don t pick up that phone .', 'jangan angkat telepon itu .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 50\n",
      "('it s a beautiful day here in boston .', 'hari ini adalah sebuah hari yang indah di boston .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Validation record: 51\n",
      "('just wait a second .', 'tunggu sebentar .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([7, 1])\n",
      "Target tensor shape: torch.Size([5, 1])\n",
      "Validation record: 52\n",
      "('i can t afford to shop at such an expensive store .', 'aku tidak sanggup kalau harus berbelanja di toko semahal itu .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([14, 1])\n",
      "Target tensor shape: torch.Size([13, 1])\n",
      "Validation record: 53\n",
      "('tom knew that mary needed to buy a car .', 'tom tahu kalau mary perlu membeli mobil .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([12, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 54\n",
      "('when life gives you lemons make lemonade .', 'saat kehidupan memberikanmu lemon buatlah limun .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 55\n",
      "('i can pay no more than a week for rent .', 'aku tidak bisa membayar lebih dari seminggu untuk sewa .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([13, 1])\n",
      "Target tensor shape: torch.Size([12, 1])\n",
      "Validation record: 56\n",
      "('i m sick of conferences these days .', 'akhir akhir ini aku bosan dengan rapat .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 57\n",
      "('what ll you have to drink ?', 'kau mau minum apa ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 58\n",
      "('i like to eat watermelon .', 'aku suka makan semangka .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 59\n",
      "('it s time to wake up .', 'sudah waktunya bangun .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 60\n",
      "('both my mom and my dad aren t home right now .', 'ibu dan ayah saya tidak di rumah sekarang .')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Input tensor shape: torch.Size([14, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n",
      "Validation record: 61\n",
      "('there s a rowboat right over there .', 'ada perahu dayung di sebelah sana .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 62\n",
      "('what sport do you like best ?', 'olahraga apa yang paling anda sukai ?')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([9, 1])\n",
      "Validation record: 63\n",
      "('tom was surprised that mary had a motorcycle .', 'tom terkejut mengetahui mary memiliki sepeda motor .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 64\n",
      "('i was at my wit s end .', 'aku kehabisan akal .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([10, 1])\n",
      "Target tensor shape: torch.Size([6, 1])\n",
      "Validation record: 65\n",
      "('please put on your shoes .', 'tolong kenakan sepatu anda .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([8, 1])\n",
      "Target tensor shape: torch.Size([7, 1])\n",
      "Validation record: 66\n",
      "('don t trust what tom says .', 'jangan percaya pada apa yang tom katakan .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([9, 1])\n",
      "Target tensor shape: torch.Size([10, 1])\n",
      "Validation record: 67\n",
      "('zamenhof the creator of esperanto was an ophthalmologist .', 'zamenhof pencipta bahasa esperanto adalah seorang pakar oftalmologi .')\n",
      "Validation\n",
      "Input tensor shape: torch.Size([11, 1])\n",
      "Target tensor shape: torch.Size([11, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /opt/conda/conda-bld/pytorch_1549636813070/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:191",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-cf1f0cacd357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindo_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2c2c6462b4d1>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, batch_size, print_every, save_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation record: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sent_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_validation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_input_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_target_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mtotal_val_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-4bc39a083545>\u001b[0m in \u001b[0;36mget_validation_loss\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, criterion, max_length)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[0;32m---> 75\u001b[0;31m             input_tensor[ei], encoder_hidden)\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-6a0d361dd8d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m         return F.embedding(\n\u001b[1;32m    117\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /opt/conda/conda-bld/pytorch_1549636813070/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:191"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(len(english_vocab), hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, len(indo_vocab), dropout_p=0.001).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 7500, print_every=100)\n",
    "\n",
    "evaluateRandomly(encoder1, attn_decoder1)\n",
    "\n",
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"do you love me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check some translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "\n",
    "translate(\"tom is playing with ball.\")\n",
    "\n",
    "translate(\"she is standing there .\")\n",
    "\n",
    "translate(\"he is a bad man .\")\n",
    "\n",
    "translate(\"he wants to sleep .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
