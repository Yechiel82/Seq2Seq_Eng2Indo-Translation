{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Bahasa Indonesian Seq-2-Seq Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "# Imports we need.\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "fp = open('./corpus/bbc-468.en', 'r')\n",
    "#fp = open('./corpus/SMERU-26870.en', 'r')\n",
    "eng_text = fp.read()\n",
    "eng_text = eng_text.splitlines()\n",
    "fp.close()\n",
    "\n",
    "fp2 = open('./corpus/bbc-468.id', 'r')\n",
    "#fp2 = open('./corpus/SMERU-26870.id', 'r')\n",
    "id_text = fp2.read()\n",
    "id_text = id_text.splitlines()\n",
    "fp2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_text = pd.DataFrame(eng_text)\n",
    "df_eng_text = df_eng_text.rename(columns={0:'English'})\n",
    "\n",
    "df_id_text = pd.DataFrame(id_text)\n",
    "df_id_text = df_id_text.rename(columns={0:'Indonesian'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_text['English'] = df_eng_text['English'].apply(lambda x : x.lstrip())\n",
    "df_id_text['Indonesian'] = df_id_text['Indonesian'].apply(lambda x : x.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Muslims fined for face veils</td>\n",
       "      <td>Muslimah Prancis didenda karena mengenakan burka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two French Muslim women have become the first ...</td>\n",
       "      <td>Dua Muslimah Prancis menjadi orang-orang perta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hind Ahmas and Najaite Ali were each ordered t...</td>\n",
       "      <td>Hind Ahmas dan Najaite Ali diperintahkan memba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both say they'll appeal as far as the European...</td>\n",
       "      <td>Keduanya menyatakan akan mengajukan banding hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some Muslim groups say veiled women have been ...</td>\n",
       "      <td>Sejumlah organisasi Muslim mengatakan wanita-w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0                French Muslims fined for face veils   \n",
       "1  Two French Muslim women have become the first ...   \n",
       "2  Hind Ahmas and Najaite Ali were each ordered t...   \n",
       "3  Both say they'll appeal as far as the European...   \n",
       "4  Some Muslim groups say veiled women have been ...   \n",
       "\n",
       "                                          Indonesian  \n",
       "0   Muslimah Prancis didenda karena mengenakan burka  \n",
       "1  Dua Muslimah Prancis menjadi orang-orang perta...  \n",
       "2  Hind Ahmas dan Najaite Ali diperintahkan memba...  \n",
       "3  Keduanya menyatakan akan mengajukan banding hi...  \n",
       "4  Sejumlah organisasi Muslim mengatakan wanita-w...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "df = pd.concat([df_eng_text, df_id_text], axis=1)\n",
    "df.head()\n",
    "\n",
    "# corpus_df = pd.read_csv(\"./corpus/trimmed_combined_no_duplicate.csv\")\n",
    "# corpus_df = corpus_df.drop(columns=[\"English_num_words\", \"Indo_num_words\"])\n",
    "# corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_df['English'] = corpus_df['English'].apply(lambda x : x.lstrip())\n",
    "# corpus_df['Indonesian'] = corpus_df['Indonesian'].apply(lambda x : x.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Singlish sentence: ['<s>', 'french', 'muslims', 'fined', 'for', 'face', 'veils', '</s>']\n",
      "First English sentence: ['<s>', 'muslimah', 'prancis', 'didenda', 'karena', 'mengenakan', 'burka', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "UNK, UNK_IDX = 'UNK', 2\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "english_sents = [START] + df_eng_text['English'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "indo_sents = [START] + df_id_text['Indonesian'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First Singlish sentence:', english_sents[0])\n",
    "print('First English sentence:', indo_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, 'burka'), (4, 'didenda'), (5, 'karena'), (6, 'mengenakan'), (7, 'muslimah'), (8, 'prancis'), (9, ',')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, 'face'), (4, 'fined'), (5, 'for'), (6, 'french'), (7, 'muslims'), (8, 'veils'), (9, ',')]\n"
     ]
    }
   ],
   "source": [
    "english_vocab = Dictionary([['<s>'], ['</s>'],['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Lets save our dictionaries.\n",
    "with open('./vocabs/indo_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(indo_vocab, fout)\n",
    "    \n",
    "with open('./vocabs/english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [6],\n",
       "        [7],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [8],\n",
       "        [1]], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizes a sentence with a given vocab\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END], unknown_word_index=2)\n",
    "\n",
    "# Creates a PyTorch variable from a sentence against a given vocab\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    #print(vsent)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    #print(result)\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Test\n",
    "new_kopi = \"French Muslims fined for face veils\"\n",
    "variable_from_sent(new_kopi, english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muslimah Prancis didenda karena mengenakan burka\n",
      "tensor([[0],\n",
      "        [7],\n",
      "        [8],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [3],\n",
      "        [1]], device='cuda:0')\n",
      "French Muslims fined for face veils\n",
      "tensor([[0],\n",
      "        [6],\n",
      "        [7],\n",
      "        [4],\n",
      "        [5],\n",
      "        [3],\n",
      "        [8],\n",
      "        [1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prepare the whole training corpus.\n",
    "indo_tensors = df_id_text['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(df_id_text.iloc[0]['Indonesian'])\n",
    "print(indo_tensors[0])\n",
    "english_tensors = df_eng_text['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "print(df_eng_text.iloc[0]['English'])\n",
    "print(english_tensors[0])\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs = list(zip(english_tensors, indo_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        embedded = self.embedding(input).view(1, 1, -1) # Question: why (1, 1, -1)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of output (i.e. no. of words in output vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # Set the output layer to output a specific symbol \n",
    "        # from the output vocabulary\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # Transform the embedded output with a relu function. \n",
    "        output = F.relu(output)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Take the updated output and find the most appropriate\n",
    "        # output symbol. \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "learning_rate=0.01\n",
    "batch_size = 2\n",
    "epochs = 30 # Since we are taking batch_size=2 and epochs=30, we only look at 60 data points.\n",
    "criterion = nn.NLLLoss()\n",
    "MAX_LENGTH=80\n",
    "\n",
    "# Initialize the network for encoder and decoder.\n",
    "input_vocab, output_vocab = english_vocab, indo_vocab\n",
    "encoder = EncoderRNN(len(input_vocab), hidden_size)\n",
    "decoder = DecoderRNN(hidden_size, len(output_vocab))\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "# Initialize the optimizer for encoder and decoder.\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# If batchsize == 1, choose 1 data points per batch:\n",
    "##training_data = [[random.choice(sent_pairs)] for i in range(epochs)]\n",
    "\n",
    "# If batch_size > 1, use random.sample() instead of random.choice:\n",
    "training_data = [random.sample(sent_pairs, batch_size) for i in range(epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input variable first: tensor([[   0],\n",
      "        [  11],\n",
      "        [ 741],\n",
      "        [  24],\n",
      "        [1179],\n",
      "        [ 194],\n",
      "        [  11],\n",
      "        [1185],\n",
      "        [  20],\n",
      "        [ 932],\n",
      "        [ 297],\n",
      "        [   9],\n",
      "        [  32],\n",
      "        [1183],\n",
      "        [1186],\n",
      "        [ 194],\n",
      "        [  26],\n",
      "        [ 941],\n",
      "        [   9],\n",
      "        [ 129],\n",
      "        [ 252],\n",
      "        [  28],\n",
      "        [  19],\n",
      "        [1188],\n",
      "        [1187],\n",
      "        [  24],\n",
      "        [ 944],\n",
      "        [1184],\n",
      "        [  10],\n",
      "        [   1]], device='cuda:0')\n",
      "Target variable first: tensor([[   0],\n",
      "        [ 731],\n",
      "        [1127],\n",
      "        [ 103],\n",
      "        [ 127],\n",
      "        [1135],\n",
      "        [1138],\n",
      "        [  15],\n",
      "        [ 906],\n",
      "        [1134],\n",
      "        [   9],\n",
      "        [  35],\n",
      "        [1133],\n",
      "        [1137],\n",
      "        [ 103],\n",
      "        [ 913],\n",
      "        [   9],\n",
      "        [ 261],\n",
      "        [1128],\n",
      "        [ 915],\n",
      "        [1139],\n",
      "        [  14],\n",
      "        [1136],\n",
      "        [ 120],\n",
      "        [ 685],\n",
      "        [ 916],\n",
      "        [  10],\n",
      "        [   1]], device='cuda:0')\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(\"Input variable first: {0}\".format(data_batch[0][0]))\n",
    "print(\"Target variable first: {0}\".format(data_batch[0][1]))\n",
    "print(input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) for the GRU.\n",
    "            encoder_outputs[ei] = encoder_output[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(2563, 100)\n",
      "  (gru): GRU(100, 100)\n",
      ") \n",
      "\n",
      "Dictionary(2563 unique tokens: ['<s>', '</s>', 'UNK', 'face', 'fined']...)\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The encoded output for the last sentence in out training_data\"\n",
    "\n",
    "# The encoder has 68 unique words\n",
    "print(encoder, '\\n')\n",
    "print(english_vocab)\n",
    "print('\\n########\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0],\n",
      "        [352],\n",
      "        [353],\n",
      "        [354],\n",
      "        [  5],\n",
      "        [355],\n",
      "        [  1]], device='cuda:0')\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The last input sentence, in PyTorch Tensor data structure.\n",
    "print(data_batch[-1][0]) \n",
    "print('########\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 352, 353, 354, 5, 355, 1] \n",
      "\n",
      "########\n",
      "\n",
      "<s> nobel physics prize for supernovas </s>\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The last input sentence as list(int)\n",
    "print(list(map(int, data_batch[-1][0])), '\\n')\n",
    "print('########\\n')\n",
    "\n",
    "# The last input sentence as list(int)\n",
    "print(' '.join([english_vocab[i] for i in map(int, data_batch[-1][0])]))\n",
    "print('\\n########\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.6679e-02,  2.3664e-01, -8.1809e-02,  ..., -1.1741e-05,\n",
      "         -6.0574e-01,  1.9828e-01],\n",
      "        [-9.1009e-02,  2.6965e-01, -2.7864e-01,  ...,  3.4735e-02,\n",
      "          4.1127e-02,  3.7039e-01],\n",
      "        [-2.0406e-01, -1.3980e-01,  1.0864e-01,  ...,  5.9435e-01,\n",
      "          3.2925e-01,  4.3482e-01],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "tensor([[[ 0.0603, -0.0402,  0.0361, -0.3808, -0.2529, -0.1739,  0.5928,\n",
      "          -0.0989,  0.7042,  0.1274,  0.1783,  0.2687,  0.2004, -0.1557,\n",
      "          -0.2421,  0.3518, -0.3281, -0.1336, -0.5045,  0.1319,  0.1317,\n",
      "           0.1974,  0.1092, -0.1415, -0.4446, -0.5360, -0.1881,  0.3272,\n",
      "          -0.3716, -0.1849,  0.0241, -0.1852, -0.0948,  0.3542, -0.5721,\n",
      "           0.1729, -0.1899, -0.1157,  0.4275, -0.3441,  0.0611,  0.2848,\n",
      "          -0.1300,  0.3277,  0.4199,  0.2420, -0.2494, -0.2119,  0.3166,\n",
      "          -0.5158, -0.6349, -0.1567, -0.0891,  0.1230,  0.4909, -0.0718,\n",
      "           0.1805,  0.1226,  0.1953,  0.1887, -0.0814,  0.0825, -0.1904,\n",
      "          -0.0056,  0.1003,  0.3091, -0.3199, -0.4470, -0.4500,  0.3396,\n",
      "           0.2664, -0.0763, -0.1122,  0.3264, -0.3818,  0.6389, -0.1433,\n",
      "           0.0292,  0.0923, -0.0368, -0.1782,  0.2058, -0.0325, -0.2819,\n",
      "           0.1136,  0.5881, -0.1045,  0.1047, -0.4419,  0.0601,  0.2001,\n",
      "           0.1783, -0.2684, -0.1119, -0.2200, -0.0480,  0.0824,  0.6787,\n",
      "          -0.3395,  0.3464]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_outputs)\n",
    "# The last hidden state of the last input sentence. \n",
    "# Note: For vanilla RNN (Elman Net), the last hidden state of the encoder\n",
    "#       is the start state of the decoder's hidden state.\n",
    "print(encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        \n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) -_-|||\n",
    "            encoder_outputs[ei] = encoder_output[0][0] \n",
    "            \n",
    "            #############################################\n",
    "            # 2.3.4.  Iterating through each word in the decoder.\n",
    "            #############################################\n",
    "            # Initialize the variable input with the index of the START.\n",
    "            decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            # As the first state of the decoder, we take the last step of the encoder.\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # Iterate through each state in the decoder.\n",
    "            # Note: when we are training we know the length of the decoder.\n",
    "            #       so we can use the trick to restrict the loop when decoding.\n",
    "            for di in range(target_length):\n",
    "                # We move forward through each state.\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # What are all these weird syntax, refer to 2.3.4.1\n",
    "                topv, topi = decoder_output.data.topk(1) # topk gives k largest values along a certain dimension, A tuple of (values, indices) is returned,\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                # Replace our decoder input for the next state with the\n",
    "                # embedding of the decoded topi guess. \n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "                \n",
    "                # Update our loss for this batch.\n",
    "                loss += criterion(decoder_output, target_variable[di])\n",
    "                \n",
    "                # If we see the </s> symbol, break the training.\n",
    "                if ni == END_IDX:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(2343, 100)\n",
      "  (gru): GRU(100, 100)\n",
      "  (softmax): LogSoftmax()\n",
      "  (out): Linear(in_features=100, out_features=2343, bias=True)\n",
      ") \n",
      "\n",
      "Dictionary(2343 unique tokens: ['<s>', '</s>', 'UNK', 'burka', 'didenda']...)\n",
      "\n",
      "########\n",
      "\n",
      "<s> nobel physics prize for supernovas </s>\n",
      "<s> nobel fisika untuk supernova </s>\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cut-away: The decoded output for the last sentence in out training_data\"\n",
    "\n",
    "# The encoder has 117 unique words\n",
    "print(decoder, '\\n')\n",
    "print(indo_vocab)\n",
    "print('\\n########\\n')\n",
    "\n",
    "# The last input sentence.\n",
    "print(' '.join([english_vocab[i] for i in map(int, data_batch[-1][0])]))\n",
    "# The last target sentence.\n",
    "print(' '.join([indo_vocab[i] for i in map(int, data_batch[-1][1])]))\n",
    "\n",
    "print('\\n########\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training Starts Here - Backpropagation Portion Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        \n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) -_-|||\n",
    "            encoder_outputs[ei] = encoder_output[0][0] \n",
    "            \n",
    "            #############################################\n",
    "            # 2.3.4.  Iterating through each word in the decoder.\n",
    "            #############################################\n",
    "            # Initialize the variable input with the index of the START.\n",
    "            decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            # As the first state of the decoder, we take the last step of the encoder.\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # Iterate through each state in the decoder.\n",
    "            # Note: when we are training we know the length of the decoder.\n",
    "            #       so we can use the trick to restrict the loop when decoding.\n",
    "            for di in range(target_length):\n",
    "                # We move forward through each state.\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # What are alll these weird syntax, refer to 2.3.4.1\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                # Replace our decoder input for the next state with the\n",
    "                # embedding of the decoded topi guess. \n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "                \n",
    "                # Update our loss for this batch.\n",
    "                loss += criterion(decoder_output, target_variable[di])\n",
    "                \n",
    "                # If we see the </s> symbol, break the training.\n",
    "                if ni == END_IDX:\n",
    "                    break\n",
    "    #####################################################\n",
    "    # 2.3.5 Backpropagate the Loss and Optimizers Takes a Step.\n",
    "    #####################################################\n",
    "    loss.backward() # Backpropagate.\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 100])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(encoder, decoder, input_variable, max_length=MAX_LENGTH):\n",
    "    # The length of the input.\n",
    "    input_length = input_variable.size()[0]\n",
    "    # For each sentence, initilize the hidden states with zeros.\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "    # Initialize the encoder outputs. \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    # Iterate through the input words.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "    # Initialize the decoder with the start symbol <s>.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]])) \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    # Use the last encoder hidden state as the first decoder's hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # Keep a list of the decoded words.\n",
    "    decoded_words = []\n",
    "    \n",
    "    # Iterate through the decoder states.\n",
    "    for di in range(max_length):\n",
    "        # Very similar to how the training works.\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, \n",
    "                                                 decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == END_IDX:\n",
    "            decoded_words.append(END_IDX)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(ni.item())# changed from ni to ni.item()\n",
    "        # Replace the new decoder input for the next state \n",
    "        # with the top guess of this state.\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0],\n",
       "        [223],\n",
       "        [230],\n",
       "        [ 26],\n",
       "        [221],\n",
       "        [  1]], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'caffeine protects the brain' # if words don't appear in corpus, it will be marked as -1\n",
    "variable_from_sent(sent, english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80\n",
    "batches = 100000 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 10\n",
    "\n",
    "my_encoder = EncoderRNN(len(english_vocab), hidden_size)\n",
    "my_decoder = DecoderRNN(hidden_size, len(indo_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words = translator(my_encoder, my_decoder, \n",
    "                          variable_from_sent(sent, english_vocab))\n",
    "len(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat',\n",
       " 'bat',\n",
       " 'bat',\n",
       " 'bat',\n",
       " 'bat',\n",
       " 'bat',\n",
       " 'pengaduan',\n",
       " 'menjatuhkan',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan',\n",
       " 'barunya',\n",
       " 'menjatuhkan']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indo_vocab[i] for i in output_words[1:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Some Logging and Plotting Candies to Monitor Training\n",
    "#########################################################\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "    \n",
    "#########################################################\n",
    "# Training per epoch,\n",
    "# Iterates across data points per epoch.\n",
    "#########################################################\n",
    "def train_one_epoch(input_variable, target_variable, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to put the variables, decoder and optimizers to train per epoch.\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "\n",
    "    # (Re-)Initialize the optimizers, clear all gradients. \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Initialize the length of the PyTorch variables.\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # Iterating through each word in the input.\n",
    "    for ei in range(input_length):\n",
    "        # We move forward through each state.\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        # And we save the encoder outputs. \n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    # Initialize the variable input with the index of the START.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    # As the first state of the decoder, we take the last step of the encoder.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        loss += criterion(decoder_output, target_variable[di])\n",
    "        if ni == END_IDX:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    #return loss.data[0] / target_length\n",
    "    return loss.item() / target_length\n",
    "\n",
    "#########################################################\n",
    "# Top-level function to start the training,\n",
    "# iterates across epochs.\n",
    "#########################################################\n",
    "\n",
    "def train(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.005):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [random.choice(sent_pairs) for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    lowest_loss = np.inf\n",
    "    patience_val = 30\n",
    "    patience = patience_val # iterations for which loss does not go down before giving up\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train_one_epoch(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f Patience left: %.2f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg, patience))\n",
    "            # Early stopping code    \n",
    "            if print_loss_avg < lowest_loss:\n",
    "                patience = patience_val # reset the patience\n",
    "                print(f'Lowest avg loss so far {print_loss_avg}, updating and saving model..')\n",
    "                lowest_loss = print_loss_avg\n",
    "                # In Python >= 3.6\n",
    "                with open(f'./models/encoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "                    pickle.dump(my_encoder, fout)\n",
    "                with open(f'./models/decoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "                    pickle.dump(my_decoder, fout)\n",
    "            else: \n",
    "                patience -= 1\n",
    "                \n",
    "\n",
    "        if patience == 0:\n",
    "            break\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 36m 12s) (100 0%) 5.6034 Patience left: 30.00\n",
      "Lowest avg loss so far 5.603389258480868, updating and saving model..\n",
      "0m 4s (- 37m 54s) (200 0%) 6.5481 Patience left: 30.00\n",
      "0m 6s (- 38m 3s) (300 0%) 6.1470 Patience left: 29.00\n",
      "0m 8s (- 37m 4s) (400 0%) 5.6101 Patience left: 28.00\n",
      "0m 10s (- 36m 19s) (500 0%) 4.2751 Patience left: 27.00\n",
      "Lowest avg loss so far 4.275059035377362, updating and saving model..\n",
      "0m 12s (- 34m 56s) (600 0%) 3.3037 Patience left: 30.00\n",
      "Lowest avg loss so far 3.3037113300928485, updating and saving model..\n",
      "0m 14s (- 33m 20s) (700 0%) 2.1884 Patience left: 30.00\n",
      "Lowest avg loss so far 2.1883805441894997, updating and saving model..\n",
      "0m 15s (- 32m 23s) (800 0%) 3.0441 Patience left: 30.00\n",
      "0m 17s (- 31m 28s) (900 0%) 2.8803 Patience left: 29.00\n",
      "0m 18s (- 31m 4s) (1000 1%) 2.7793 Patience left: 28.00\n",
      "0m 20s (- 30m 32s) (1100 1%) 1.8332 Patience left: 27.00\n",
      "Lowest avg loss so far 1.833218953180949, updating and saving model..\n",
      "0m 21s (- 30m 10s) (1200 1%) 2.1143 Patience left: 30.00\n",
      "0m 23s (- 29m 41s) (1300 1%) 2.0525 Patience left: 29.00\n",
      "0m 25s (- 29m 27s) (1400 1%) 2.7865 Patience left: 28.00\n",
      "0m 26s (- 28m 58s) (1500 1%) 1.5686 Patience left: 27.00\n",
      "Lowest avg loss so far 1.56860958538594, updating and saving model..\n",
      "0m 27s (- 28m 36s) (1600 1%) 1.9294 Patience left: 30.00\n",
      "0m 29s (- 28m 46s) (1700 1%) 3.2009 Patience left: 29.00\n",
      "0m 31s (- 28m 42s) (1800 1%) 3.0318 Patience left: 28.00\n",
      "0m 33s (- 28m 35s) (1900 1%) 2.9010 Patience left: 27.00\n",
      "0m 34s (- 28m 24s) (2000 2%) 2.4995 Patience left: 26.00\n",
      "0m 36s (- 28m 3s) (2100 2%) 1.5762 Patience left: 25.00\n",
      "0m 37s (- 27m 53s) (2200 2%) 2.4700 Patience left: 24.00\n",
      "0m 39s (- 27m 39s) (2300 2%) 1.8195 Patience left: 23.00\n",
      "0m 40s (- 27m 34s) (2400 2%) 2.0298 Patience left: 22.00\n",
      "0m 42s (- 27m 27s) (2500 2%) 2.0564 Patience left: 21.00\n",
      "0m 43s (- 27m 25s) (2600 2%) 2.1447 Patience left: 20.00\n",
      "0m 45s (- 27m 21s) (2700 2%) 2.1477 Patience left: 19.00\n",
      "0m 47s (- 27m 14s) (2800 2%) 2.2817 Patience left: 18.00\n",
      "0m 48s (- 27m 9s) (2900 2%) 2.3261 Patience left: 17.00\n",
      "0m 50s (- 27m 8s) (3000 3%) 2.5228 Patience left: 16.00\n",
      "0m 52s (- 27m 10s) (3100 3%) 2.7781 Patience left: 15.00\n",
      "0m 53s (- 27m 8s) (3200 3%) 2.8793 Patience left: 14.00\n",
      "0m 55s (- 27m 4s) (3300 3%) 2.3356 Patience left: 13.00\n",
      "0m 57s (- 27m 4s) (3400 3%) 2.5092 Patience left: 12.00\n",
      "0m 58s (- 27m 4s) (3500 3%) 2.8891 Patience left: 11.00\n",
      "1m 0s (- 27m 6s) (3600 3%) 2.9597 Patience left: 10.00\n",
      "1m 2s (- 27m 10s) (3700 3%) 3.0974 Patience left: 9.00\n",
      "1m 4s (- 27m 7s) (3800 3%) 2.7712 Patience left: 8.00\n",
      "1m 6s (- 27m 10s) (3900 3%) 2.9342 Patience left: 7.00\n",
      "1m 8s (- 27m 16s) (4000 4%) 3.7568 Patience left: 6.00\n",
      "1m 10s (- 27m 20s) (4100 4%) 4.0675 Patience left: 5.00\n",
      "1m 11s (- 27m 18s) (4200 4%) 3.3078 Patience left: 4.00\n",
      "1m 13s (- 27m 22s) (4300 4%) 3.3107 Patience left: 3.00\n",
      "1m 15s (- 27m 21s) (4400 4%) 2.9157 Patience left: 2.00\n",
      "1m 17s (- 27m 20s) (4500 4%) 3.3622 Patience left: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 80\n",
    "batches = 100000 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 10\n",
    "\n",
    "my_encoder = EncoderRNN(len(english_vocab), hidden_size)\n",
    "my_decoder = DecoderRNN(hidden_size, len(indo_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()\n",
    "\n",
    "train(my_encoder, my_decoder, batches, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100000\n",
      "encoder_vanilla_10_100000.pkl\n"
     ]
    }
   ],
   "source": [
    "print(hidden_size, batches)\n",
    "print(f'encoder_vanilla_{hidden_size}_{batches}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# # In Python >= 3.6\n",
    "# with open(f'./models/encoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "#     pickle.dump(my_encoder, fout)\n",
    "# with open(f'./models/decoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "#     pickle.dump(my_decoder, fout)\n",
    "\n",
    "# # For Python < 3.6\n",
    "# with open('./models/encoder_vanilla_{}_{}.pkl'.format(hidden_size, batches), 'wb') as fout:\n",
    "#     pickle.dump(my_encoder, fout)\n",
    "# with open('./models/decoder_vanilla_{}_{}.pkl'.format(hidden_size, batches), 'wb') as fout:\n",
    "#     pickle.dump(my_decoder, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/encoder_vanilla_10_100000.pkl\n",
      "./models/decoder_vanilla_10_100000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "filename = f'./models/encoder_vanilla_{hidden_size}_{batches}.pkl'\n",
    "print(filename)\n",
    "my_encoder = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename = f'./models/decoder_vanilla_{hidden_size}_{batches}.pkl'\n",
    "print(filename)\n",
    "my_decoder = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(kopi_order):\n",
    "    output_words = translator(my_encoder, my_decoder, variable_from_sent(kopi_order, english_vocab))\n",
    "    print(output_words)\n",
    "    output_sentence = [indo_vocab[i] for i in output_words[1:output_words.index(1)]]\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 9, 9, 0, 9, 0, 9, 0, 9, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> <s> <s> , , <s> , <s> , <s> ,'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('French Muslims fined for face veils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 9, 9, 0, 9, 0, 9, 0, 9, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> <s> <s> , , <s> , <s> , <s> ,'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
