{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Bahasa Indonesian Seq-2-Seq Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "# Imports we need.\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "fp = open('./corpus/bbc-468.en', 'r')\n",
    "#fp = open('./corpus/SMERU-26870.en', 'r')\n",
    "eng_text = fp.read()\n",
    "eng_text = eng_text.splitlines()\n",
    "fp.close()\n",
    "\n",
    "fp2 = open('./corpus/bbc-468.id', 'r')\n",
    "#fp2 = open('./corpus/SMERU-26870.id', 'r')\n",
    "id_text = fp2.read()\n",
    "id_text = id_text.splitlines()\n",
    "fp2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_text = pd.DataFrame(eng_text)\n",
    "df_eng_text = df_eng_text.rename(columns={0:'English'})\n",
    "\n",
    "df_id_text = pd.DataFrame(id_text)\n",
    "df_id_text = df_id_text.rename(columns={0:'Indonesian'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_text['English'] = df_eng_text['English'].apply(lambda x : x.lstrip())\n",
    "df_id_text['Indonesian'] = df_id_text['Indonesian'].apply(lambda x : x.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Muslims fined for face veils</td>\n",
       "      <td>Muslimah Prancis didenda karena mengenakan burka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two French Muslim women have become the first ...</td>\n",
       "      <td>Dua Muslimah Prancis menjadi orang-orang perta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hind Ahmas and Najaite Ali were each ordered t...</td>\n",
       "      <td>Hind Ahmas dan Najaite Ali diperintahkan memba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both say they'll appeal as far as the European...</td>\n",
       "      <td>Keduanya menyatakan akan mengajukan banding hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some Muslim groups say veiled women have been ...</td>\n",
       "      <td>Sejumlah organisasi Muslim mengatakan wanita-w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0                French Muslims fined for face veils   \n",
       "1  Two French Muslim women have become the first ...   \n",
       "2  Hind Ahmas and Najaite Ali were each ordered t...   \n",
       "3  Both say they'll appeal as far as the European...   \n",
       "4  Some Muslim groups say veiled women have been ...   \n",
       "\n",
       "                                          Indonesian  \n",
       "0   Muslimah Prancis didenda karena mengenakan burka  \n",
       "1  Dua Muslimah Prancis menjadi orang-orang perta...  \n",
       "2  Hind Ahmas dan Najaite Ali diperintahkan memba...  \n",
       "3  Keduanya menyatakan akan mengajukan banding hi...  \n",
       "4  Sejumlah organisasi Muslim mengatakan wanita-w...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "df = pd.concat([df_eng_text, df_id_text], axis=1)\n",
    "df.head()\n",
    "\n",
    "# corpus_df = pd.read_csv(\"./corpus/trimmed_combined_no_duplicate.csv\")\n",
    "# corpus_df = corpus_df.drop(columns=[\"English_num_words\", \"Indo_num_words\"])\n",
    "# corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_df['English'] = corpus_df['English'].apply(lambda x : x.lstrip())\n",
    "# corpus_df['Indonesian'] = corpus_df['Indonesian'].apply(lambda x : x.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 2)\n",
      "(71, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_val = train_test_split(df, test_size=0.15)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Singlish sentence: ['<s>', 'french', 'muslims', 'fined', 'for', 'face', 'veils', '</s>']\n",
      "First English sentence: ['<s>', 'muslimah', 'prancis', 'didenda', 'karena', 'mengenakan', 'burka', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "UNK, UNK_IDX = 'UNK', 2\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "english_sents = [START] + df['English'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "indo_sents = [START] + df['Indonesian'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First Singlish sentence:', english_sents[0])\n",
    "print('First English sentence:', indo_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, 'burka'), (4, 'didenda'), (5, 'karena'), (6, 'mengenakan'), (7, 'muslimah'), (8, 'prancis'), (9, ',')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, 'face'), (4, 'fined'), (5, 'for'), (6, 'french'), (7, 'muslims'), (8, 'veils'), (9, ',')]\n"
     ]
    }
   ],
   "source": [
    "english_vocab = Dictionary([['<s>'], ['</s>'],['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Lets save our dictionaries.\n",
    "with open('./vocabs/indo_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(indo_vocab, fout)\n",
    "    \n",
    "with open('./vocabs/english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [6],\n",
       "        [7],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [8],\n",
       "        [1]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizes a sentence with a given vocab\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END], unknown_word_index=2)\n",
    "\n",
    "# Creates a PyTorch variable from a sentence against a given vocab\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    #print(vsent)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    #print(result)\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Test\n",
    "new_kopi = \"French Muslims fined for face veils\"\n",
    "variable_from_sent(new_kopi, english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pemerintah negara bagian Sao Paulo di Brasil menawarkan bantuan keuangan kepada ratusan keluarga yang secara paksa diusir dari pemukiman ilegal, hari Minggu.\n",
      "tensor([[0],\n",
      "        [7],\n",
      "        [8],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [3],\n",
      "        [1]], device='cuda:0')\n",
      "The government of Sao Paulo state in Brazil has offered financial help to hundreds of families who were forcibly evicted from an illegal settlement on Sunday.\n",
      "tensor([[0],\n",
      "        [6],\n",
      "        [7],\n",
      "        [4],\n",
      "        [5],\n",
      "        [3],\n",
      "        [8],\n",
      "        [1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prepare the whole training corpus.\n",
    "indo_tensors = df_train['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(df_train.iloc[0]['Indonesian'])\n",
    "print(indo_tensors[0])\n",
    "english_tensors = df_train['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "print(df_train.iloc[0]['English'])\n",
    "print(english_tensors[0])\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs = list(zip(english_tensors, indo_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularitas Cain terpengaruh oleh sejumlah kasus dugaan pelecehan seksual, yang juga telah ia bantah.\n",
      "tensor([[   0],\n",
      "        [1289],\n",
      "        [1260],\n",
      "        [1291],\n",
      "        [ 194],\n",
      "        [  59],\n",
      "        [ 893],\n",
      "        [ 607],\n",
      "        [  57],\n",
      "        [1290],\n",
      "        [   9],\n",
      "        [  24],\n",
      "        [ 157],\n",
      "        [  77],\n",
      "        [ 334],\n",
      "        [1259],\n",
      "        [  10],\n",
      "        [   1]], device='cuda:0')\n",
      "Mr Cain's popularity has already been affected by multiple allegations of sexual harassment -- which he also denies.\n",
      "tensor([[   0],\n",
      "        [1327],\n",
      "        [1316],\n",
      "        [  88],\n",
      "        [1344],\n",
      "        [  96],\n",
      "        [ 854],\n",
      "        [  62],\n",
      "        [1341],\n",
      "        [ 120],\n",
      "        [1343],\n",
      "        [ 618],\n",
      "        [  24],\n",
      "        [1345],\n",
      "        [1342],\n",
      "        [ 163],\n",
      "        [ 115],\n",
      "        [ 345],\n",
      "        [ 165],\n",
      "        [1251],\n",
      "        [  10],\n",
      "        [   1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prepare validation data\n",
    "# Prepare the whole training corpus.\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "indo_tensors_val = df_val['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(df_val.iloc[0]['Indonesian'])\n",
    "print(indo_tensors_val[0])\n",
    "english_tensors_val = df_val['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "print(df_val.iloc[0]['English'])\n",
    "print(english_tensors_val[0])\n",
    "# # Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs_val = list(zip(english_tensors_val, indo_tensors_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        embedded = self.embedding(input).view(1, 1, -1) # Question: why (1, 1, -1)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of output (i.e. no. of words in output vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # Set the output layer to output a specific symbol \n",
    "        # from the output vocabulary\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # Transform the embedded output with a relu function. \n",
    "        output = F.relu(output)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Take the updated output and find the most appropriate\n",
    "        # output symbol. \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "learning_rate=0.01\n",
    "batch_size = 2\n",
    "epochs = 30 # Since we are taking batch_size=2 and epochs=30, we only look at 60 data points.\n",
    "criterion = nn.NLLLoss()\n",
    "MAX_LENGTH=80\n",
    "\n",
    "# Initialize the network for encoder and decoder.\n",
    "input_vocab, output_vocab = english_vocab, indo_vocab\n",
    "encoder = EncoderRNN(len(input_vocab), hidden_size)\n",
    "decoder = DecoderRNN(hidden_size, len(output_vocab))\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "# Initialize the optimizer for encoder and decoder.\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# If batchsize == 1, choose 1 data points per batch:\n",
    "##training_data = [[random.choice(sent_pairs)] for i in range(epochs)]\n",
    "\n",
    "# If batch_size > 1, use random.sample() instead of random.choice:\n",
    "training_data = [random.sample(sent_pairs, batch_size) for i in range(epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input variable first: tensor([[   0],\n",
      "        [1099],\n",
      "        [1118],\n",
      "        [ 108],\n",
      "        [1116],\n",
      "        [1120],\n",
      "        [  20],\n",
      "        [1121],\n",
      "        [1026],\n",
      "        [  20],\n",
      "        [1115],\n",
      "        [1113],\n",
      "        [  35],\n",
      "        [  47],\n",
      "        [1114],\n",
      "        [1117],\n",
      "        [  20],\n",
      "        [  26],\n",
      "        [1119],\n",
      "        [1115],\n",
      "        [  10],\n",
      "        [   1]], device='cuda:0')\n",
      "Target variable first: tensor([[   0],\n",
      "        [1073],\n",
      "        [1057],\n",
      "        [1078],\n",
      "        [1074],\n",
      "        [ 141],\n",
      "        [1076],\n",
      "        [1080],\n",
      "        [  15],\n",
      "        [1071],\n",
      "        [1079],\n",
      "        [  29],\n",
      "        [ 141],\n",
      "        [1075],\n",
      "        [1077],\n",
      "        [1072],\n",
      "        [  15],\n",
      "        [1079],\n",
      "        [ 407],\n",
      "        [  10],\n",
      "        [   1]], device='cuda:0')\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print(\"Input variable first: {0}\".format(data_batch[0][0]))\n",
    "print(\"Target variable first: {0}\".format(data_batch[0][1]))\n",
    "print(input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) for the GRU.\n",
    "            encoder_outputs[ei] = encoder_output[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(2563, 100)\n",
      "  (gru): GRU(100, 100)\n",
      ") \n",
      "\n",
      "Dictionary(2563 unique tokens: ['<s>', '</s>', 'UNK', 'face', 'fined']...)\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The encoded output for the last sentence in out training_data\"\n",
    "\n",
    "# The encoder has 68 unique words\n",
    "print(encoder, '\\n')\n",
    "print(english_vocab)\n",
    "print('\\n########\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0],\n",
      "        [1533],\n",
      "        [ 258],\n",
      "        [  26],\n",
      "        [1527],\n",
      "        [1529],\n",
      "        [  24],\n",
      "        [ 132],\n",
      "        [  88],\n",
      "        [1530],\n",
      "        [ 390],\n",
      "        [  26],\n",
      "        [ 394],\n",
      "        [1522],\n",
      "        [1532],\n",
      "        [   9],\n",
      "        [1327],\n",
      "        [1524],\n",
      "        [ 126],\n",
      "        [ 551],\n",
      "        [1519],\n",
      "        [ 451],\n",
      "        [1531],\n",
      "        [ 277],\n",
      "        [1528],\n",
      "        [1534],\n",
      "        [ 206],\n",
      "        [  26],\n",
      "        [ 521],\n",
      "        [ 871],\n",
      "        [ 212],\n",
      "        [ 550],\n",
      "        [  10],\n",
      "        [   1]], device='cuda:0')\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The last input sentence, in PyTorch Tensor data structure.\n",
    "print(data_batch[-1][0]) \n",
    "print('########\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1533, 258, 26, 1527, 1529, 24, 132, 88, 1530, 390, 26, 394, 1522, 1532, 9, 1327, 1524, 126, 551, 1519, 451, 1531, 277, 1528, 1534, 206, 26, 521, 871, 212, 550, 10, 1] \n",
      "\n",
      "########\n",
      "\n",
      "<s> speaking on the 10th anniversary of china 's entry into the world trade organization , mr hu said `` imports may exceed $ 8 trillion over the next five years '' . </s>\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The last input sentence as list(int)\n",
    "print(list(map(int, data_batch[-1][0])), '\\n')\n",
    "print('########\\n')\n",
    "\n",
    "# The last input sentence as list(int)\n",
    "print(' '.join([english_vocab[i] for i in map(int, data_batch[-1][0])]))\n",
    "print('\\n########\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1278, -0.2508,  0.1069,  ...,  0.2504, -0.0126, -0.0582],\n",
      "        [ 0.2778, -0.1479,  0.5021,  ...,  0.7497,  0.2774,  0.3082],\n",
      "        [ 0.1153, -0.1580, -0.0455,  ...,  0.8161, -0.1769, -0.0392],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n",
      "tensor([[[-0.0502, -0.3607, -0.5675,  0.0992, -0.2997, -0.3509,  0.0996,\n",
      "          -0.1013,  0.1390, -0.1148, -0.1984, -0.2270,  0.3256,  0.1955,\n",
      "          -0.4675, -0.0921,  0.0981,  0.4299, -0.0900, -0.2975,  0.1595,\n",
      "           0.1148,  0.0369, -0.0912,  0.3450, -0.2704,  0.0496, -0.1259,\n",
      "          -0.1696,  0.0475,  0.0504, -0.0303, -0.1359, -0.7085,  0.2127,\n",
      "          -0.1368, -0.4027,  0.4303, -0.4283, -0.1976, -0.1000,  0.2003,\n",
      "           0.0970,  0.5020, -0.6272,  0.3593, -0.2182,  0.3694, -0.1768,\n",
      "          -0.1235, -0.4191, -0.0355, -0.2476, -0.1265, -0.0888, -0.0855,\n",
      "           0.1434, -0.2462, -0.1454,  0.0384, -0.1609, -0.1918, -0.3844,\n",
      "           0.4687, -0.0091, -0.0578,  0.1357,  0.0525, -0.2709,  0.4163,\n",
      "          -0.2615,  0.1169, -0.2224, -0.1977, -0.1576, -0.3363,  0.1695,\n",
      "          -0.0017,  0.2683, -0.0596,  0.3382,  0.2812,  0.3895,  0.0977,\n",
      "          -0.2481,  0.2611, -0.1400, -0.2642, -0.1152,  0.1392,  0.3283,\n",
      "          -0.2408,  0.5391, -0.4716, -0.0842,  0.1193, -0.1307,  0.1211,\n",
      "          -0.0299, -0.5303]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_outputs)\n",
    "# The last hidden state of the last input sentence. \n",
    "# Note: For vanilla RNN (Elman Net), the last hidden state of the encoder\n",
    "#       is the start state of the decoder's hidden state.\n",
    "print(encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        \n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) -_-|||\n",
    "            encoder_outputs[ei] = encoder_output[0][0] \n",
    "            \n",
    "            #############################################\n",
    "            # 2.3.4.  Iterating through each word in the decoder.\n",
    "            #############################################\n",
    "            # Initialize the variable input with the index of the START.\n",
    "            decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            # As the first state of the decoder, we take the last step of the encoder.\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # Iterate through each state in the decoder.\n",
    "            # Note: when we are training we know the length of the decoder.\n",
    "            #       so we can use the trick to restrict the loop when decoding.\n",
    "            for di in range(target_length):\n",
    "                # We move forward through each state.\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # What are all these weird syntax, refer to 2.3.4.1\n",
    "                topv, topi = decoder_output.data.topk(1) # topk gives k largest values along a certain dimension, A tuple of (values, indices) is returned,\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                # Replace our decoder input for the next state with the\n",
    "                # embedding of the decoded topi guess. \n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "                \n",
    "                # Update our loss for this batch.\n",
    "                loss += criterion(decoder_output, target_variable[di])\n",
    "                \n",
    "                # If we see the </s> symbol, break the training.\n",
    "                if ni == END_IDX:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(2343, 100)\n",
      "  (gru): GRU(100, 100)\n",
      "  (softmax): LogSoftmax()\n",
      "  (out): Linear(in_features=100, out_features=2343, bias=True)\n",
      ") \n",
      "\n",
      "Dictionary(2343 unique tokens: ['<s>', '</s>', 'UNK', 'burka', 'didenda']...)\n",
      "\n",
      "########\n",
      "\n",
      "<s> speaking on the 10th anniversary of china 's entry into the world trade organization , mr hu said `` imports may exceed $ 8 trillion over the next five years '' . </s>\n",
      "<s> janji ini diucapkan presiden hu dalam peringatan sepuluh tahun masuknya cina dalam organisasi perdagangan dunia ( wto ) . menurutnya dalam lima tahun mendatang impor ke cina akan melebihi us $ 8 triliun . </s>\n",
      "\n",
      "########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cut-away: The decoded output for the last sentence in out training_data\"\n",
    "\n",
    "# The encoder has 117 unique words\n",
    "print(decoder, '\\n')\n",
    "print(indo_vocab)\n",
    "print('\\n########\\n')\n",
    "\n",
    "# The last input sentence.\n",
    "print(' '.join([english_vocab[i] for i in map(int, data_batch[-1][0])]))\n",
    "# The last target sentence.\n",
    "print(' '.join([indo_vocab[i] for i in map(int, data_batch[-1][1])]))\n",
    "\n",
    "print('\\n########\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training Starts Here - Backpropagation Portion Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2.3.2. Loop through the batches.\n",
    "#############################################\n",
    "# Start the training.\n",
    "for data_batch in training_data:\n",
    "    # (Re-)Initialize the optimizers, clear all gradients after every batch.\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Reset the loss for every batch.\n",
    "    loss = 0\n",
    "    for input_variable, target_variable in data_batch:\n",
    "        # Initialize the hidden_states for the encoder.\n",
    "        encoder_hidden = encoder.initialize_hidden_states()\n",
    "        # Initialize the length of the PyTorch variables.\n",
    "        input_length = input_variable.size()[0]\n",
    "        target_length = target_variable.size()[0]\n",
    "        encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "        \n",
    "        #############################################\n",
    "        # 2.3.3.  Iterating through each word in the encoder.\n",
    "        #############################################\n",
    "        # Iterating through each word in the input.\n",
    "        for ei in range(input_length):\n",
    "            # We move forward through each state.\n",
    "            encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "            # And we save the encoder outputs. \n",
    "            # Note: We're retrieving [0][0] cos remember the weird .view(1,1,-1) -_-|||\n",
    "            encoder_outputs[ei] = encoder_output[0][0] \n",
    "            \n",
    "            #############################################\n",
    "            # 2.3.4.  Iterating through each word in the decoder.\n",
    "            #############################################\n",
    "            # Initialize the variable input with the index of the START.\n",
    "            decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            # As the first state of the decoder, we take the last step of the encoder.\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # Iterate through each state in the decoder.\n",
    "            # Note: when we are training we know the length of the decoder.\n",
    "            #       so we can use the trick to restrict the loop when decoding.\n",
    "            for di in range(target_length):\n",
    "                # We move forward through each state.\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # What are alll these weird syntax, refer to 2.3.4.1\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                # Replace our decoder input for the next state with the\n",
    "                # embedding of the decoded topi guess. \n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "                \n",
    "                # Update our loss for this batch.\n",
    "                loss += criterion(decoder_output, target_variable[di])\n",
    "                \n",
    "                # If we see the </s> symbol, break the training.\n",
    "                if ni == END_IDX:\n",
    "                    break\n",
    "    #####################################################\n",
    "    # 2.3.5 Backpropagate the Loss and Optimizers Takes a Step.\n",
    "    #####################################################\n",
    "    loss.backward() # Backpropagate.\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(encoder, decoder, input_variable, max_length=MAX_LENGTH):\n",
    "    # The length of the input.\n",
    "    input_length = input_variable.size()[0]\n",
    "    # For each sentence, initilize the hidden states with zeros.\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "    # Initialize the encoder outputs. \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    # Iterate through the input words.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "    # Initialize the decoder with the start symbol <s>.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]])) \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    # Use the last encoder hidden state as the first decoder's hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # Keep a list of the decoded words.\n",
    "    decoded_words = []\n",
    "    \n",
    "    # Iterate through the decoder states.\n",
    "    for di in range(max_length):\n",
    "        # Very similar to how the training works.\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, \n",
    "                                                 decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == END_IDX:\n",
    "            decoded_words.append(END_IDX)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(ni.item())# changed from ni to ni.item()\n",
    "        # Replace the new decoder input for the next state \n",
    "        # with the top guess of this state.\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0],\n",
       "        [223],\n",
       "        [230],\n",
       "        [ 26],\n",
       "        [221],\n",
       "        [  1]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'caffeine protects the brain' # if words don't appear in corpus, it will be marked as 2 <unk>\n",
    "variable_from_sent(sent, english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80\n",
    "batches = 100000 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 10\n",
    "\n",
    "my_encoder = EncoderRNN(len(english_vocab), hidden_size)\n",
    "my_decoder = DecoderRNN(hidden_size, len(indo_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words = translator(my_encoder, my_decoder, \n",
    "                          variable_from_sent(sent, english_vocab))\n",
    "len(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'mengijinkan',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'desain',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'mengijinkan',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'desain',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'mengijinkan',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'desain',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'sebanyak',\n",
       " 'mengijinkan']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indo_vocab[i] for i in output_words[1:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(encoder, decoder, input_variable, target_variable, criterion, max_length=MAX_LENGTH):\n",
    "    # The length of the input.\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    \n",
    "    # For each sentence, initilize the hidden states with zeros.\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "    # Initialize the encoder outputs. \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # Iterate through the input words.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "    # Initialize the decoder with the start symbol <s>.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]])) \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    # Use the last encoder hidden state as the first decoder's hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # Keep a list of the decoded words.\n",
    "    decoded_words = []\n",
    "    \n",
    "    # Iterate through the decoder states.\n",
    "    for di in range(target_length):\n",
    "        # Very similar to how the training works.\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, \n",
    "                                                 decoder_hidden)\n",
    "#         print(f'Decoder output shape {decoder_output.shape}')\n",
    "#         print(f'Target variable shape {target_variable.shape}')\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        # Replace the new decoder input for the next state \n",
    "        # with the top guess of this state.\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        loss += criterion(decoder_output, target_variable[di])\n",
    "        if ni == END_IDX:\n",
    "            break\n",
    "            \n",
    "    return loss.item() / target_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Some Logging and Plotting Candies to Monitor Training\n",
    "#########################################################\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "    \n",
    "#########################################################\n",
    "# Training per epoch,\n",
    "# Iterates across data points per epoch.\n",
    "#########################################################\n",
    "def train_one_epoch(input_variable, target_variable, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to put the variables, decoder and optimizers to train per epoch.\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "\n",
    "    # (Re-)Initialize the optimizers, clear all gradients. \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Initialize the length of the PyTorch variables.\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # Iterating through each word in the input.\n",
    "    for ei in range(input_length):\n",
    "        # We move forward through each state.\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        # And we save the encoder outputs. \n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    # Initialize the variable input with the index of the START.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    # As the first state of the decoder, we take the last step of the encoder.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        loss += criterion(decoder_output, target_variable[di])\n",
    "        if ni == END_IDX:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    #return loss.data[0] / target_length\n",
    "    return loss.item() / target_length\n",
    "\n",
    "#########################################################\n",
    "# Top-level function to start the training,\n",
    "# iterates across epochs.\n",
    "#########################################################\n",
    "\n",
    "def train(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.005):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    plot_losses_val = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    val_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [random.choice(sent_pairs) for i in range(n_iters)] \n",
    "    validation_pairs = [random.choice(sent_pairs_val) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    lowest_loss = np.inf\n",
    "    stopping_criteria = True\n",
    "    patience_val = 100\n",
    "    patience = patience_val # iterations for which loss does not go down before giving up\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train_one_epoch(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        validation_pair = validation_pairs[iter - 1]\n",
    "        input_variable_val = validation_pair[0]\n",
    "        target_variable_val = validation_pair[1]\n",
    "        \n",
    "        val_loss = validate(encoder, decoder, input_variable_val, target_variable_val, criterion, max_length=MAX_LENGTH)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        val_loss_total += val_loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) Training Loss: %.4f Patience left: %.2f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg, patience))\n",
    "            \n",
    "            val_loss_avg = val_loss_total / print_every\n",
    "            print(f'Validation loss : {val_loss_avg}')\n",
    "            \n",
    "            if stopping_criteria:\n",
    "                if val_loss_avg < lowest_loss:\n",
    "                    patience = patience_val # reset the patience\n",
    "                    print(f'Lowest val loss so far {val_loss_avg}, updating and saving model..')\n",
    "                    lowest_loss = val_loss_avg\n",
    "                    # In Python >= 3.6\n",
    "                    with open(f'./models/encoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "                        pickle.dump(my_encoder, fout)\n",
    "                    with open(f'./models/decoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "                        pickle.dump(my_decoder, fout)\n",
    "                else: \n",
    "                    patience -= 1\n",
    "\n",
    "                if patience == 0:\n",
    "                    break\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "        if iter % plot_every == 0:\n",
    "            val_loss_avg = val_loss_total / plot_every\n",
    "            plot_losses_val.append(val_loss_avg)\n",
    "            val_loss_total = 0\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "                \n",
    "    showPlot(plot_losses)\n",
    "    showPlot(plot_losses_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 12m 3s) (100 0%) Training Loss: 3.6886 Patience left: 100.00\n",
      "Validation loss : 3.460494618228349\n",
      "Lowest val loss so far 3.460494618228349, updating and saving model..\n",
      "0m 5s (- 12m 14s) (200 0%) Training Loss: 3.5643 Patience left: 100.00\n",
      "Validation loss : 3.203315412687205\n",
      "Lowest val loss so far 3.203315412687205, updating and saving model..\n",
      "0m 7s (- 11m 38s) (300 1%) Training Loss: 2.8707 Patience left: 100.00\n",
      "Validation loss : 2.485880579211485\n",
      "Lowest val loss so far 2.485880579211485, updating and saving model..\n",
      "0m 10s (- 11m 41s) (400 1%) Training Loss: 3.1159 Patience left: 100.00\n",
      "Validation loss : 3.1491431977450413\n",
      "0m 12s (- 11m 54s) (500 1%) Training Loss: 3.9631 Patience left: 99.00\n",
      "Validation loss : 3.8334400542183253\n",
      "0m 15s (- 11m 58s) (600 2%) Training Loss: 4.0371 Patience left: 98.00\n",
      "Validation loss : 4.247086975296836\n",
      "0m 18s (- 11m 59s) (700 2%) Training Loss: 3.3791 Patience left: 97.00\n",
      "Validation loss : 3.876949331363865\n",
      "0m 20s (- 11m 54s) (800 2%) Training Loss: 3.4185 Patience left: 96.00\n",
      "Validation loss : 3.779815028588674\n",
      "0m 23s (- 11m 50s) (900 3%) Training Loss: 3.2510 Patience left: 95.00\n",
      "Validation loss : 3.4661505733114124\n",
      "0m 26s (- 11m 53s) (1000 3%) Training Loss: 3.7907 Patience left: 94.00\n",
      "Validation loss : 4.135881289648026\n",
      "0m 29s (- 11m 56s) (1100 3%) Training Loss: 3.8120 Patience left: 93.00\n",
      "Validation loss : 3.742941970890891\n",
      "0m 32s (- 11m 59s) (1200 4%) Training Loss: 3.4850 Patience left: 92.00\n",
      "Validation loss : 3.9635967015000713\n",
      "0m 35s (- 12m 2s) (1300 4%) Training Loss: 3.4031 Patience left: 91.00\n",
      "Validation loss : 4.095437833157986\n",
      "0m 38s (- 12m 6s) (1400 4%) Training Loss: 3.2804 Patience left: 90.00\n",
      "Validation loss : 4.292687493331429\n",
      "0m 40s (- 12m 7s) (1500 5%) Training Loss: 3.2520 Patience left: 89.00\n",
      "Validation loss : 4.1240651126853995\n",
      "0m 44s (- 12m 8s) (1600 5%) Training Loss: 3.4188 Patience left: 88.00\n",
      "Validation loss : 4.625254479717855\n",
      "0m 47s (- 12m 10s) (1700 6%) Training Loss: 3.4146 Patience left: 87.00\n",
      "Validation loss : 4.787098046644361\n",
      "0m 49s (- 12m 8s) (1800 6%) Training Loss: 3.1328 Patience left: 86.00\n",
      "Validation loss : 4.331537373929005\n",
      "0m 53s (- 12m 13s) (1900 6%) Training Loss: 3.4075 Patience left: 85.00\n",
      "Validation loss : 5.057128991995365\n",
      "0m 56s (- 12m 14s) (2000 7%) Training Loss: 3.4943 Patience left: 84.00\n",
      "Validation loss : 4.717971573418813\n",
      "0m 59s (- 12m 14s) (2100 7%) Training Loss: 3.3656 Patience left: 83.00\n",
      "Validation loss : 5.085879113845511\n",
      "1m 2s (- 12m 17s) (2200 7%) Training Loss: 3.6348 Patience left: 82.00\n",
      "Validation loss : 5.201101274108653\n",
      "1m 5s (- 12m 17s) (2300 8%) Training Loss: 3.2346 Patience left: 81.00\n",
      "Validation loss : 4.978510878904846\n",
      "1m 8s (- 12m 17s) (2400 8%) Training Loss: 2.9532 Patience left: 80.00\n",
      "Validation loss : 5.062167517761543\n",
      "1m 11s (- 12m 16s) (2500 8%) Training Loss: 2.9240 Patience left: 79.00\n",
      "Validation loss : 4.484687918174736\n",
      "1m 15s (- 12m 16s) (2600 9%) Training Loss: 3.0270 Patience left: 78.00\n",
      "Validation loss : 5.406482454753826\n",
      "1m 18s (- 12m 16s) (2700 9%) Training Loss: 3.1400 Patience left: 77.00\n",
      "Validation loss : 4.790410727512977\n",
      "1m 21s (- 12m 16s) (2800 9%) Training Loss: 3.0485 Patience left: 76.00\n",
      "Validation loss : 5.357057714556444\n",
      "1m 24s (- 12m 16s) (2900 10%) Training Loss: 3.1102 Patience left: 75.00\n",
      "Validation loss : 5.639848448153856\n",
      "1m 28s (- 12m 16s) (3000 10%) Training Loss: 3.1441 Patience left: 74.00\n",
      "Validation loss : 5.220308074014608\n",
      "1m 31s (- 12m 15s) (3100 11%) Training Loss: 3.1254 Patience left: 73.00\n",
      "Validation loss : 5.589939741422682\n",
      "1m 34s (- 12m 14s) (3200 11%) Training Loss: 2.8651 Patience left: 72.00\n",
      "Validation loss : 6.226333503981731\n",
      "1m 37s (- 12m 13s) (3300 11%) Training Loss: 3.0851 Patience left: 71.00\n",
      "Validation loss : 5.679599090559492\n",
      "1m 40s (- 12m 11s) (3400 12%) Training Loss: 2.6103 Patience left: 70.00\n",
      "Validation loss : 5.139630218433395\n",
      "1m 44s (- 12m 12s) (3500 12%) Training Loss: 2.8061 Patience left: 69.00\n",
      "Validation loss : 6.370520724435262\n",
      "1m 47s (- 12m 11s) (3600 12%) Training Loss: 2.5158 Patience left: 68.00\n",
      "Validation loss : 6.202007861803034\n",
      "1m 50s (- 12m 9s) (3700 13%) Training Loss: 2.6152 Patience left: 67.00\n",
      "Validation loss : 5.856482047548748\n",
      "1m 53s (- 12m 8s) (3800 13%) Training Loss: 2.7641 Patience left: 66.00\n",
      "Validation loss : 6.136635655190296\n",
      "1m 57s (- 12m 7s) (3900 13%) Training Loss: 2.8722 Patience left: 65.00\n",
      "Validation loss : 6.104137709918803\n",
      "2m 0s (- 12m 7s) (4000 14%) Training Loss: 2.6834 Patience left: 64.00\n",
      "Validation loss : 5.448929834196609\n",
      "2m 4s (- 12m 7s) (4100 14%) Training Loss: 2.8424 Patience left: 63.00\n",
      "Validation loss : 5.971664855747496\n",
      "2m 7s (- 12m 5s) (4200 14%) Training Loss: 2.6106 Patience left: 62.00\n",
      "Validation loss : 6.327230355434443\n",
      "2m 11s (- 12m 5s) (4300 15%) Training Loss: 2.5112 Patience left: 61.00\n",
      "Validation loss : 6.433834477702778\n",
      "2m 14s (- 12m 4s) (4400 15%) Training Loss: 2.6898 Patience left: 60.00\n",
      "Validation loss : 6.0287303848906255\n",
      "2m 17s (- 12m 3s) (4500 16%) Training Loss: 2.8027 Patience left: 59.00\n",
      "Validation loss : 6.118288990218433\n",
      "2m 21s (- 12m 0s) (4600 16%) Training Loss: 2.5362 Patience left: 58.00\n",
      "Validation loss : 5.7230217929088125\n",
      "2m 24s (- 11m 58s) (4700 16%) Training Loss: 2.6250 Patience left: 57.00\n",
      "Validation loss : 6.039234817148866\n",
      "2m 28s (- 11m 58s) (4800 17%) Training Loss: 2.9156 Patience left: 56.00\n",
      "Validation loss : 6.531312841474927\n",
      "2m 31s (- 11m 56s) (4900 17%) Training Loss: 2.7235 Patience left: 55.00\n",
      "Validation loss : 5.951814187328576\n",
      "2m 34s (- 11m 55s) (5000 17%) Training Loss: 2.4757 Patience left: 54.00\n",
      "Validation loss : 5.68844619728066\n",
      "2m 38s (- 11m 54s) (5100 18%) Training Loss: 2.7570 Patience left: 53.00\n",
      "Validation loss : 6.989176823868938\n",
      "2m 42s (- 11m 55s) (5200 18%) Training Loss: 2.8445 Patience left: 52.00\n",
      "Validation loss : 6.243873129141587\n",
      "2m 45s (- 11m 53s) (5300 18%) Training Loss: 2.6989 Patience left: 51.00\n",
      "Validation loss : 6.5719642488631544\n",
      "2m 49s (- 11m 51s) (5400 19%) Training Loss: 2.8330 Patience left: 50.00\n",
      "Validation loss : 6.86031880456961\n",
      "2m 52s (- 11m 50s) (5500 19%) Training Loss: 2.9821 Patience left: 49.00\n",
      "Validation loss : 6.69277893834491\n",
      "2m 56s (- 11m 49s) (5600 19%) Training Loss: 2.9923 Patience left: 48.00\n",
      "Validation loss : 6.712925130736743\n",
      "3m 0s (- 11m 48s) (5700 20%) Training Loss: 2.7733 Patience left: 47.00\n",
      "Validation loss : 6.490390748312373\n",
      "3m 3s (- 11m 46s) (5800 20%) Training Loss: 2.5513 Patience left: 46.00\n",
      "Validation loss : 6.338664788255411\n",
      "3m 7s (- 11m 44s) (5900 20%) Training Loss: 2.6015 Patience left: 45.00\n",
      "Validation loss : 6.6122715090064785\n",
      "3m 10s (- 11m 41s) (6000 21%) Training Loss: 2.6142 Patience left: 44.00\n",
      "Validation loss : 6.8306926446939835\n",
      "3m 13s (- 11m 38s) (6100 21%) Training Loss: 2.4843 Patience left: 43.00\n",
      "Validation loss : 5.902194574605985\n",
      "3m 16s (- 11m 35s) (6200 22%) Training Loss: 2.5694 Patience left: 42.00\n",
      "Validation loss : 6.374132756427178\n",
      "3m 20s (- 11m 33s) (6300 22%) Training Loss: 2.7249 Patience left: 41.00\n",
      "Validation loss : 7.317432273198993\n",
      "3m 23s (- 11m 30s) (6400 22%) Training Loss: 2.6947 Patience left: 40.00\n",
      "Validation loss : 6.849041939463552\n",
      "3m 27s (- 11m 28s) (6500 23%) Training Loss: 2.5311 Patience left: 39.00\n",
      "Validation loss : 7.059464485104419\n",
      "3m 30s (- 11m 25s) (6600 23%) Training Loss: 2.5615 Patience left: 38.00\n",
      "Validation loss : 7.123279860912895\n",
      "3m 33s (- 11m 23s) (6700 23%) Training Loss: 2.5877 Patience left: 37.00\n",
      "Validation loss : 6.513216791092635\n",
      "3m 37s (- 11m 20s) (6800 24%) Training Loss: 2.6240 Patience left: 36.00\n",
      "Validation loss : 6.84305850021998\n",
      "3m 40s (- 11m 17s) (6900 24%) Training Loss: 2.4357 Patience left: 35.00\n",
      "Validation loss : 7.366541044849917\n",
      "3m 43s (- 11m 14s) (7000 24%) Training Loss: 2.4879 Patience left: 34.00\n",
      "Validation loss : 6.760339097036847\n",
      "3m 47s (- 11m 11s) (7100 25%) Training Loss: 2.5212 Patience left: 33.00\n",
      "Validation loss : 6.6110305398905505\n",
      "3m 50s (- 11m 8s) (7200 25%) Training Loss: 2.4305 Patience left: 32.00\n",
      "Validation loss : 7.2971268741207105\n",
      "3m 53s (- 11m 5s) (7300 25%) Training Loss: 2.4075 Patience left: 31.00\n",
      "Validation loss : 6.892638250992633\n",
      "3m 56s (- 11m 2s) (7400 26%) Training Loss: 2.4264 Patience left: 30.00\n",
      "Validation loss : 7.488808347645276\n",
      "4m 0s (- 11m 0s) (7500 26%) Training Loss: 2.5813 Patience left: 29.00\n",
      "Validation loss : 8.020304524894504\n",
      "4m 3s (- 10m 57s) (7600 27%) Training Loss: 2.3937 Patience left: 28.00\n",
      "Validation loss : 7.548123574204456\n",
      "4m 7s (- 10m 54s) (7700 27%) Training Loss: 2.5759 Patience left: 27.00\n",
      "Validation loss : 7.633025794580024\n",
      "4m 10s (- 10m 52s) (7800 27%) Training Loss: 2.6697 Patience left: 26.00\n",
      "Validation loss : 7.838145623683326\n",
      "4m 14s (- 10m 50s) (7900 28%) Training Loss: 2.8036 Patience left: 25.00\n",
      "Validation loss : 7.57775858441082\n",
      "4m 17s (- 10m 47s) (8000 28%) Training Loss: 2.5180 Patience left: 24.00\n",
      "Validation loss : 7.399734195283935\n",
      "4m 21s (- 10m 45s) (8100 28%) Training Loss: 2.8036 Patience left: 23.00\n",
      "Validation loss : 7.748325749396949\n",
      "4m 25s (- 10m 43s) (8200 29%) Training Loss: 2.6262 Patience left: 22.00\n",
      "Validation loss : 6.670227481180116\n",
      "4m 29s (- 10m 42s) (8300 29%) Training Loss: 2.3591 Patience left: 21.00\n",
      "Validation loss : 7.546863763412896\n",
      "4m 33s (- 10m 40s) (8400 29%) Training Loss: 2.6678 Patience left: 20.00\n",
      "Validation loss : 7.815799351986011\n",
      "4m 36s (- 10m 38s) (8500 30%) Training Loss: 2.5632 Patience left: 19.00\n",
      "Validation loss : 7.6999863444589565\n",
      "4m 40s (- 10m 36s) (8600 30%) Training Loss: 2.6741 Patience left: 18.00\n",
      "Validation loss : 7.7489282924394844\n",
      "4m 44s (- 10m 35s) (8700 30%) Training Loss: 2.4337 Patience left: 17.00\n",
      "Validation loss : 7.964736703927811\n",
      "4m 48s (- 10m 32s) (8800 31%) Training Loss: 2.6463 Patience left: 16.00\n",
      "Validation loss : 7.506705367255643\n",
      "4m 52s (- 10m 30s) (8900 31%) Training Loss: 2.4415 Patience left: 15.00\n",
      "Validation loss : 7.752345633352479\n",
      "4m 56s (- 10m 28s) (9000 32%) Training Loss: 2.7030 Patience left: 14.00\n",
      "Validation loss : 7.215934121755258\n",
      "4m 59s (- 10m 25s) (9100 32%) Training Loss: 2.3396 Patience left: 13.00\n",
      "Validation loss : 7.620282588250129\n",
      "5m 2s (- 10m 22s) (9200 32%) Training Loss: 2.3954 Patience left: 12.00\n",
      "Validation loss : 7.543625355593332\n",
      "5m 6s (- 10m 19s) (9300 33%) Training Loss: 2.7117 Patience left: 11.00\n",
      "Validation loss : 7.524287165322141\n",
      "5m 10s (- 10m 16s) (9400 33%) Training Loss: 2.5559 Patience left: 10.00\n",
      "Validation loss : 7.126183265941627\n",
      "5m 13s (- 10m 13s) (9500 33%) Training Loss: 2.2072 Patience left: 9.00\n",
      "Validation loss : 7.243160698534791\n",
      "5m 16s (- 10m 10s) (9600 34%) Training Loss: 2.4876 Patience left: 8.00\n",
      "Validation loss : 7.808348515650894\n",
      "5m 20s (- 10m 7s) (9700 34%) Training Loss: 2.4993 Patience left: 7.00\n",
      "Validation loss : 7.629429653631725\n",
      "5m 23s (- 10m 4s) (9800 34%) Training Loss: 2.3790 Patience left: 6.00\n",
      "Validation loss : 7.621169398079952\n",
      "5m 27s (- 10m 1s) (9900 35%) Training Loss: 2.3641 Patience left: 5.00\n",
      "Validation loss : 8.151532784758603\n",
      "5m 30s (- 9m 58s) (10000 35%) Training Loss: 2.0668 Patience left: 4.00\n",
      "Validation loss : 7.638611893004447\n",
      "5m 34s (- 9m 55s) (10100 35%) Training Loss: 2.3348 Patience left: 3.00\n",
      "Validation loss : 7.832581091757328\n",
      "5m 37s (- 9m 52s) (10200 36%) Training Loss: 2.3688 Patience left: 2.00\n",
      "Validation loss : 8.279486155590426\n",
      "5m 41s (- 9m 49s) (10300 36%) Training Loss: 2.4565 Patience left: 1.00\n",
      "Validation loss : 7.632962906084898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztvXeYXGd59/95ps/szmyvaitp1V1kW5blBrYx2DSb8IMkhNACISTUAEkgyUt+IXnf90pIIG9eSkIMxIRQTbfBNNsYd8uSLMmSrK6VtvedLdOf949zzuz0nd2dbbP357p0affsmbPPzEj3ued738/9VVprBEEQhPLCttQLEARBEEqPBHdBEIQyRIK7IAhCGSLBXRAEoQyR4C4IglCGSHAXBEEoQyS4C4IglCES3AVBEMoQCe6CIAhliGOpfnF9fb1ua2tbql8vCIKwInnuuecGtNYNM523ZMG9ra2N/fv3L9WvFwRBWJEopS4Uc57IMoIgCGWIBHdBEIQyRIK7IAhCGSLBXRAEoQyR4C4IglCGSHAXBEEoQyS4C4IglCGrKriHonG+8UwHsXhiqZciCIKwoBQd3JVSdqXUQaXU/Tl+5lZKfUspdVop9bRSqq2UiywVX3+6g49/7wgHOkaWeimCIAgLymwy9w8Cx/P87J3AsNa6HfgM8A/zXVip0Vrz9Wc6ABgPR5d4NYIgCAtLUcFdKbUWeDVwT55T7gbuNb++D3iZUkrNf3ml45lzQ5zuGwdgMhJf4tUIgiAsLMVm7v8C/DmQT6xeA1wE0FrHgFGgbt6rKyH//XQHDptxv5kMS3AXBKG8mTG4K6VeA/RprZ8rdFqOYzrHtd6tlNqvlNrf398/i2XOj4HxMD892s1rr2wFYCISW7TfLQiCsBQUk7nfCNyllDoPfBO4TSn1tYxzLgHrAJRSDqAKGMq8kNb6i1rrPVrrPQ0NM06sLBn3PXeJaFzzrps3AiLLCIJQ/swY3LXWH9dar9VatwG/Czyktf79jNN+BLzN/PoN5jlZmftSkEhovv50B3vbatnZEsBhU0xK5i4IQpkz5z53pdQnlVJ3md9+CahTSp0GPgx8rBSLKwUHL47QMTTJm65bh1IKn8vOhGjugiCUObMy69BaPwI8Yn79iZTjIeCNpVxYqRgYDwOwpdEPgM/lkMxdEISyp+x3qIaiRpbucRpP1ee2i+YuCELZU/bBPRw1ujfdDjsAFS6HBHdBEMqesg/uoZiVuRvB3euyMxEWWUYQhPKm/IN7hixT4bIzFZXMXRCE8mYVBHdDlrEyd5/bIZm7IAhlzyoI7nEcNoXTbhZUnVJQFQSh/FkFwT2RzNoBKtxSUBUEofwp/+Aeiyf1dgCfyy597oIglD3lH9yj8WQbJBiZezSuicTEjUkQhPJlVQT31Mzda0o0kr0LglDOrILgnqm5W8FddHdBEMqXYua5e5RSzyilnldKvaCU+tsc56xXSj1seqweVkq9amGWO3uMzH06uPtcxjgdydwFQShnisncw8BtWusrgd3AnUqpfRnn/DXwba31VRhjgT9f2mXOnUxZxucyAr1MhhQEoZwpZp671lqPm986zT+Zs9o1EDC/rgK6SrbCeRKKJvA4cmXuswvuPzzUyWv+7284PzBR0vUJgiAsBEWN/FVK2YHngHbgc1rrpzNO+f+Bnyul3g9UALeXcpHzwWiFzKW5FyfLjIWifOIHR/nBIeN+9dyFYdrqK0q/UEEQhBJSVEFVax3XWu8G1gJ7lVKXZZzyJuA/tdZrgVcB/6WUyrr2UniohqMJ3LlkmSIy97FQlFf/62/48eFu3vPSzQD0m/PhBUEQljOz6pbRWo9gmHXcmfGjdwLfNs95EvAA9Tkev+geqqFoPNn+CNOyzFQRmfuxrjEuDk3xz2+8kr+4cxtep52BoAR3QRCWP8V0yzQoparNr70YksuJjNM6gJeZ5+zACO6Lk5rPQGa3TIUZ3IspqI6HjBvApoYKlFLU+12SuQuCsCIoRnNvAe41dXcbRlfM/UqpTwL7tdY/Aj4C/IdS6k8xiqtvXy4G2aFYIn0Tk6t4zX3cnB5Z6TZepoZKd9K2TxAEYTkzY3DXWh8GrspxPNVD9RhwY2mXNn+i8QTxhE7rlnE5bDjtqijNPRiKAlDpMV6m+ko35welW0YQhOVPWe9QnTbqsKcd97kcTBUT3M3M3e92AtDgdzMwHinxKgVBEEpPmQd3y6gj/Wn6irTaGw/FcNhU8vENfjdDExGicRk6JgjC8qbMg7uRnbuzMvfiDDvGwzEqPQ6UUoAhywAMTUj2LgjC8mZVBPdMWcYw7Jg5cw+GYsliKhiZO0C/tEMKgrDMKfPgbsoyjvSn6XXaiyyopgd3K3OXdkhBEJY7Ky64H+sa469/cKSozDsUm1/mPh6OEvA4k983SuYuCMIKYcUF995giK891cHBjpEZz83fLTM7zd3Cytyl110QhOXOigvu12yoQSl4+tzQjOcW6paZLGKHaqYs43XZqXQ7JHMXBGHZs+KCe8DjZGdLgGeLCu5GAPfm6HOfKEaWCaVn7gD1lS7pdRcEYdmz4oI7wN6NtRzoGJ7R5Dp/t4ydqUicmSYkBMMx/BnBvcHvpj8YmsOqBUEQFo8VGdyv21hLOJbgSGdh3T1kBn93lizjIJbQRApsRgrH4kRiCfzuzMx9aXepFnNTEgRBKImHqnnebyuljpnnfL30S53m2rZaYGbdPVygoAoU1N2tqZGV7lyZ+9Jo7qFonH3/+1f84FDnkvx+QRBWDiXxUFVKbQE+Dtyotd4FfKjkK02hrtJNe2Mlz8wQ3JOyjCNDlrHG/hbQ3aeHhjnTjtdXuhmdihKOLb4H66XhKUanopzuG5/5ZEEQVjWl8lD9Qwz7vWHzMX0lXWUO9m6s5bnzw8QT+SWKUDSBTYHTrtKOW2N/Cw0PC5qz3HNp7gCDSyDN9IwaWv/wZHTRf7cgCCuLojR3pZRdKXUI6AN+kcNDdSuwVSn1uFLqKaVUplNTydnbVkswHON491jecyyjDms2jIXlo1pol+p4ciJktuYOS9Pr3jU6BcCwzLYRBGEGSuWh6gC2ALdg+KneY7k3pVJKD9W9Gw3dvZA0k2mObWFZ7U0WmAxpuTBltkIu5XyZ6cxdgrsgCIUplYfqJeCHWuuo1voc8CJGsM98fMk8VFurvayt8RYM7lORRNZcGZjW3AvtUg2GTc09K3N3AUuTuXebmfuIyDKCIMxAqTxUfwDcap5TjyHTnC3tUrPZu7GWZ88P5W0NzJe5W5p7oYLqeFJzzy6owtJk7l0jkrkLglAcxWTuLcDDSqnDwLMYmvv9SqlPKqXuMs/5GTColDoGPAz8mdZ6cGGWPM21bbUMTkS4MDiZ8+fhaDxrljtMa+6FM/fcBVWP047f41iSXvfUgqr0uguCUIhSeahq4MPmn0WjOeABjEy2jYqsn4eiiay5MpCiuRcqqJouTO4css5S9bp3jU6hFERiCSYjcSrcxfibC4KwGlmRO1QtZmppDEXjWT3ukLqJqVCfuzF6ILPTBgxpZrFnuo+HYwRDMTbWGTcxkWYEQSjEig7uPlfhlsZQLJ68AaTitNtw2W0ztkJmdspYNPjdDCxy5t5jFlN3tAYAKaoKglCYsgju+Yw38skyAD63vaBhhzHu15nzZw1LkLl3m3r7zhYjuEvmLghCIVZ0cPea2vlsZRkAn7OwYcd4OJq1gcmiwe8mGIolxxssBt0jmcFdMndBEPKzooO7z1m46yUUTeTslgHwzWC1Z2nuuViKXndrd+r2Fj8gu1QFQSjMyg7uZkvjVJ4MOhyN55VlKlz25OTHXMykucPC9bqPTEa49n/+kgePdieP9YyGqK9002D22YssIwhCIVZ0cHfZbdhtKr/mnmcTExidNoUGh41nWOyl0ug3WjA7hnL318+XnxzpoT8Y5ufHepPHukZDtFZ7cNht+D0OKagKglCQFR3clVJ5tfN4QhON67yae8UMVnvBApn79mY/DX43PznSnfPn8+XHz3cBsP/8cPJYz+hUsq+/xueSzF0QhIKs6OAO+TPwaYu9fN0yjrxaveXCFPDk7pZx2G3cfWUrD53oK7n23TsW4qlzgzT63XQMTdI3ZhRSu0dCtFZ7AaipcElBVRCEgqz44O5z5c7c8/mnJh/nzN8KmZwIWWAH6OuvXks0rrn/cNdsl1yQ+w93ozX8xZ3bAdh/YZhgKEowHKOlysrcnVJQFQShICs+uHtduTPwqRkzd3temz1rlnuh4L6zNcD2Zj/fPVBay7sfP9/FzpYAd+1uxeO08ez5oeRMmeYqkWUEQSiOFR/cfS47U9HsDDwUNcyv82XuluaeawBXMM8s90z+v6vXcujiCGf6S2N71zE4yaGLI9y1uxWn3cbuddXsPz9MlxncLVmm2ueUgqogCAUpmUG2ee4blFJaKbWntMvMz0yyjDtPQdXrspPQEI4liMQS/Oj5LmJx44aQz2Ivk7t3t2JT8P0ZsnetNfc9d4nvH7zEgY7hvJLKj02J5zVXtADG1Mtj3WOcMT1TrYJqrc/FeDhGJJYo+HsFQVi9FDNW0DLIHldKOYHHlFI/1Vo/lXqSUsoPfADItOBbULxOO31j2f3mloF1rtkyYPS5g7EB6l9+eZKvPnkB31v3cPvOphSLvdwFVYvGgIebtzTw/YOdfPjlW7HZsoeMAZzoCfLR7zyfduwr77iWW7c1ph378fNdXLOhhrU1PgD2tNUST5zmp0e7UQqazOBeXWFsohqZiiTbMgVBEFIplUE2wN8B/wiESre8mfG57EwWkmVyjOwFo1sG4FvPXuSrT14ASPqxjlsuTDNk7gCvv3oNnSNTPHs+vyOUdd0vvW0P//6WawA41pXu/do3FuJET5BXXtacPHbV+mqUgmfPD1Nf6cZlPpcan3HTGZ4QaUYQhNyUxCBbKXUVsE5rff8M1ymZh6qF1+WYoRUyT7eMmbn/489OsGdDDWtrvJzoCQLFdctYvGxHEzYFj58eyHvOiZ4gLoeNl25t4I5dzQQ8DnrH0u+BnSPGeIGN9dNz6QMeJ9ubjVkyrVXTGXqNz8jcpagqCEI+5m2QrZSyAZ8BPlLEdUrmoWpRkVdzn7mgCoZ+/dnfu5pdrQGO9xjZdD4XplxUuh1ctqaKpwp4uR7vHmNrUyUOu/Fyt1R5k1MeLTI7YiyubavJOl5tZu4jEtwFQchDKQyy/cBlwCNKqfPAPuBHi1VUNbpl4lldLzNtYtpYX0GD383/+d2raK7ysL05wPmBCaYicYKhGE57bhemXFy3sZZDF0fyTok80RNMZuAATVWerMzdCvYtVd6049dsqMk6XlthZe4iywiCkJt5G2RrrUe11vVa6zatdRvwFHCX1nr/Aq05Da/LgdbTmbpFKFZYlmmrr+CZv3wZN22pB2BHi5+EhlN9weRcmVwuTLm4bmMdkViC5y+OZP1sYDxMfzDM9mZ/8lhzwJ3M1C16xkK4HLaknm6xd2MtSsH6Wl/ymCXLDMlGJkEQ8lAqg+wlI59hx3RBNXdwB9KCt5VZn+gOMh6O4c8zeiAX17YZAfjpHNLMiW5Dx9/RMp25Nwc89I+Hicanb0jdoyFaqjxZN5SWKi/f/eMb+N2965LHPE47HqdNZBlBEPJSEoPsjOO3zH9ZxeNNaWmsSzme7HPPI8tksr7Wh9dp53jPmOnCVLz5dJXPKHw+fW4Q2JL2sxOmjp+WuVd50doYGWxtTEodDJbJ1etrso4Zu1RFlhEEITdlsUMVsme6h6NxlKJo3dxmU2xr9nOiO0gwFC2qDTKV6zbW8tyF4ayNRce7gzT63dSZc9gBmquMr3tSdHcrcy+WGp9LMndBEPJSNsE9s2MmFEvgdtiK1s3B0N1PmJl7Pou9fFy3sZZQNMGRztG04yd6xtieIsnA9GakXlN3TyQ0vWMhmjOKqYWoqXBK5i4IQl5WfHD3Oo0gnKm5T0XyG3XkY3tzgOHJKBcGJ4pqg0xl78ZaAFOaMYjFE5zqHWdHiiQD050vVofM4ESEaFzPKnOv9rlkMqQgCHlZ8cE9mblnTHgsZI6dD0sXn4jEZy3L1FW6aW+s5JmUouq5gQki8UTS99SixufE5bAl2yHz9bgXosbnlE1MgiDkpXyCezRblsk3VyYfqb3olTPMlcnFdRtr2X9+ODmA7Li54zX1umB06TQF3EnNvds0v56t5j46FSWRyDUJQhCE1c6KD+5WAJ/KaoWMF11MtajyOZPb/Gcry4AhzYyHYzx/ydDdj3eP4bApNjdUZp3bEvAmM3YryM8uc3eR0DAWEt1dEIRsVnxwt8YIZBVUo7PX3IFk8XMuwf3mLQ1UeZ287+sHONM/zonuMdobK5MDv1JpqvKkZO4hHDZFfYU767x81FSYw8OkqCoIQg5WfHD35umWCUcTeUcPFMLS3WfT525RW+Him+/eRzSe4Lf/7UkOXhxJ27yUirVLVWtNz2iIpoAn78jgXFTLLlVBEAqw4oO722HDpsiaDBmKzS9zn0twB2Mn6rf/6HrcDhsjk9G0zUupNAU8hGMJRqeidI9OzUpvh+kRBNLrLghCLlZ8cFdK4cvhozqXbhmAGzbXccPmOq5YWz3nNW1qqOQ7f3wDr79qDa82XZUySW2H7BkNzUpvB2OaJYgsIwhCbuaWni4zvDl8VENzlGXqK918/Q/3zXtNa6q9fPp3duf9eeou1e7REC/f2TSr61dbmrvIMoIg5KAkHqpKqQ8rpY4ppQ4rpX6llNqwMMvNTS4f1bkWVBcLa5fqie4g4VhiVrtTAfxuBx6njb7gohpfCYKwQigmtbU8VK8EdgN3KqUyU9uDwB6t9RXAfRh2e4uG17nygnuj34NScOjiMDC7Hncw5KjmgIeeHP6xgiAIJfFQ1Vo/rLWeNL99CsOxadHwuew5CqqJoidCLgUuh426CjcHO4wZ8LPV3MHI/nvMDVCCIAiplMRDNYN3Aj/Nc52Se6gCZkF1WnNPJDSRWGJOBdXFpLnKTV/QyLxnm7lbj+kZE1lGEIRs5u2hmopS6veBPcCn8lyn5B6qYBRUU2WZmVyYlgvNAUNntyloqCx+A5NFU5WH3tFwlsWgIAhCKTxUAVBK3Q78FYbF3qIKwZkFVcuFybuMZRmY7php9HuS5tmzenzAQySekI1MgiBkMW8PVfP4VcC/YwT2voVYaCEy+9ynzbGXe+ZuSDFz0dthWsoRaUYQhExK5aH6KaAS+I5S6pBS6kcLtN6cGAXVac19pQR3qx1yLnp76uN7JbgLgpBBSTxUtda3l3hds8LnsjMZjaO1Rik1bY69zGUZa5fqXDN363GW6cdMPHi0m8vXVrOmOndP/ehklHf/137W1/r4+Kt2UFvhmtO6BEFYepZ39CsSr8uO1hA2/Uutgqp7mWfuluY+18y9odKNTU3b9RViYDzMe752gE89eCLnz0PROH/41f0c6Bjm+wc7edk/P8J39l+UYq0grFDKIrj7nOmTIZOyzDJvhWyrq+Bt12/gjl3Nc3q8w26jwe8uSnN/4oxh//er432EY+l7AhIJzUe+/TzPnB/i07+9mwc+cDObGyr5s/sOc89vzs1pbYIgLC3lEdxd6T6q1oam2ToxLTYOu42/vfsyNtRVzPkazQFPUbLM46cGAAiGYzx+eiDtZ//rJ8d54Eg3f/WqHbz2yla2Nfv59h9dT1udj4PmDlpBEFYWZRHcp92YjKBuZbJNgdn3jq80mqs8MxZUtdY8dnqA27Y34vc4+MmRnuTPjnePcc9j53jzdet5180bk8dtNsW6Wh9dI1KsFYSVSFkEd1+GYUfn8BQOm6LRPzcteyXRHPAk7frycWFwks6RKW7d3sjLdzbx8xd6iJj1ic89fJoKl50/u2MbSqWbhbRUeegakfEGgrASKYvgnunGdGl4ipZqD/ZZOButVJqqPIyFYmnjFzJ5zJRhbmqv51WXtTAWivHEmQFO943zwJFu3npDW9LZKZXWai/94+HkjcDi7V95hq88Llq8ICxnymKeu6W5WzPdO0emWFvtW8olLRrJjUyjITblMOIGeOLMAGuqvbTV+Wit9lDpdvDTIz1EEwncDhvvvGljzse1VnnR2uijX1drvJ7hWJxfn+ynyutcmCckCEJJKIvM3ZJlJsJW5j7JmprZzUdfqVgbmfJ1zMQTmifODHJjex1KKdwOO7fvaOQnR7r54aEu3nzdBurzzLVpNfvhU6WZS8NTaA2jU+IAJQjLmbIK7lOROJFYgr5gOO9GnXLDGmGQT3c/1jXGyGSUG9vrk8deeXkLwXAMu03x7pdsynvtlmrj2l0pY4U7hozJzmMS3AVhWVNWssxkJEb3qJFZrl0lmXvzDPNlLL39hs3Twf2lWxuo8Tm5e/eaZOafi9YqK3OfvnbHoBncQ/k1fkEQlp4yCe5mQTUa59KwkWWuFlnG53IQ8Djy7lJ9/PQA25v9NPinpReP087DH72FSnfht9/rslPjc6bJMhcGJXMXhJVAqTxU3UqpbymlTiulnlZKtS3EYvPhdthQypBlOs3gvloKqmBk77k2Mk1F4jx7fihNkrGo9rmKGjPcWu1NC+4dQxOAaO6CsNwplYfqO4FhrXU78BngH0q7zMIopfCZPqqXRqawqbkP41qJNFd5c25kevLsAOFYglu2zd0YpbXam3bjsDL3cCyRHPMgCMLyoyQeqsDdwL3m1/cBL1OZO2IWGK850/3S8CRNAQ8uR1nUiouiOZB7vsxDJ/rwuezs3Vg752u3VnnoNDP3RELTMTSZlMGCorsLwrKlVB6qa4CLAFrrGDAK1OW4zoJ4qML0TPfO4alV0ylj0Rzw0B8ME4tPbzbSWvPwiX5uaq/HPY8Baq3VXoKhGMFQlL5gmHAswa7WAABjIZFmAE72Bvn0L05yz2/OLvVSBCFJUQVVrXUc2G06Mn1fKXWZ1vpoyim5svSsWbFa6y8CXwTYs2dPSWfJWlZ7l4anuLatppSXXvY0V3lJaOgfDydnxJ/qG6dzZIr33dY+r2u3mDfK7tEQw6ad32Vrqnj2/PCqL6o+e36Iv/r+EU72Gh9sXQ4bf3DjRmyrYGe0sPwplYfqJWAdgFLKAVQBQyVYX9F4XXbGwzF6xkKrplPGwpoLn9rr/tAJw+3w1m2N87r2GqvXfWSKC2aP++VrqgApqn7+4dMMjkf45N27+MjLtxKJJcTyUFg2lMRDFfgR8Dbz6zcAD+lFdnnwueycG5ggntCsWUWdMpCySzUjuO9sCcy7sNyS0uveMTiJ3abY0WLJMqtXc9dac6RzjFu2NfLW69u4ar3xadEqOAvCUlMqD9UvAXVKqdPAh4GPLcxy8+N1OpJdHatlA5OFFYAteWB0MspzF4a5dfvcu2QsGv1u7DZF96iRubdWe6gz7fdWsyzTMxZiYDzM5WuMG92GOiOhsFpFBWGpKZWHagh4Y2mXNjsq3NNFw9Umy9T4nOzbVMu/PnSKtnofNqWIJzS3bZ+fJAOGoUiT303nyBQdgxNsqK0gYA4NW80F1SOXRgG4fG01YAxwc9iUZO7CsqFs+gV9Ka5Lq61bRinFl952Lde21fChbx3iM788SbXPye51pSksWxuZLgxNsr7Oh8dpx+WwMTa1emWZI52j2BTsNCUqh93GulqfBHdh2VA2wd3rND6E1Fe68SxzY+yFoMLt4Ctv38tN7fWc7Z/gpVsbSjbPvqXay8necUYmo2wwR/8GPM5VXVA9fGmUrU3+NCvH9bU+LogsIywTyia4W5n7apNkUvG67PzHW/fwgdvaed+t82uBTKW12sOQ2QZpacsBr2NFyTKf+tkJPvqd50tyLa01RztHk11DFhvqjMx9kXsJBCEnZTE4DKbdmNauMkkmE4/Tzodfsa2k17SmQwKsrzXMvAMe54oqqD5xZpCz/RNorbPsBGdL12iIwYkIl69ND+7ra30EQzFGJqPUVGQ7WwnCYlJ2mftq65RZDFpTbpjrk5m7c0W1QvaOhhidiiY/gcyHZDE1K3M3bnzWfgBBWErKLrivZllmobCs/OorXckxwVVeJ8EVkrknEpq+YBiAM/3z18SPdI6k9ftbWJLVhUHR3YWlp2yCu9c07FhtnTKLgfWarq+d3hwW8DjmXVD94aFOHjs1MK9rFMPgRIRYwtDBz/SPz3D2zBzpHGNrkz+rcG+9Ph3SMSMsA8omuG9r8tMUcLOrtWrmk4VZUe1z4nXak7IDWLJMdM7Fw2g8wV9//yj/96FTpVpmXlLHIZ/pm19w11pz5NJIcvNSKh6nnaaAm/MS3IVlQNkUVLc1+3n6L29f6mWUJUopPvXGK9jS6E8eC3icROOaUDSR1g5YLIcujhAMx0qSSc+EFdwdNjXv39c5MsXwZDS5eSmTDbUVsktVWBaUTeYuLCyvuaKVbc0pwd1r5AVzbYf89YvGyOeB8Qgjk+lFzh8/38XD5uCzUtA7Zujtu9dVF625f+2pC3zyx8eyjucrplqsr5ONTMLyQIK7MCcCHmMEwVx190dP9eMybf4ys+n//ZPjfPbh0/NbYAo9YyGUgn2b6rg4PDmjg1QiofnsQ6f52lMXiMQSaT873DmKw6bYnnKjS2VDrY++YJipiLhUCUtLMVMh1ymlHlZKHTc9VD+Y45wqpdSPU3xW37EwyxWWC1XWfJk5BPehiQhHOkd57ZWtAJxO0cGHJyJ0jYa4WMJ2wr6xEPWVbrY2+9Eazs/QzbL/wjA9YyEi8QQnesbSfnaoY4TtLdnFVIv1yQFikr0LS0sxmXsM+IjWegewD3ivUmpnxjnvBY6ZPqu3AP+slJJdHGXMfIaH/eZUP1rD7123HpfDlhbcj3UbwbQvGC6ZR2vPWIjmgIfNDUZB+Exf4eD+4+e7cJijGw6bMgxALJ7g+UsjXLM+/8yeNqvXXdohhSWmGA/Vbq31AfPrIHAcw1Yv7TTAb/qmVmIYdaycHS7CrAl4TM09ZXjYu+59li88cmbGxz56csAcbFbNpvqK9ODeNZ0pXxqeKmotPz3SzQOHu/P+vHcsTFPAzab6SpQq3A4Ziyf4yZFu7tjVTG2Fi8OXRpI/e7E3yGQkztUb8gf3DZK5J+kPhvnQNw9mJQCjk1GC+HLhAAAgAElEQVT+9FuHsmotQmmZleaulGrDGP+b6aH6WWAH0AUcAT6otU5knLOgHqrC4pKZuUfjCR55sZ+nzw0WfJzWmkdPGd6udpuivbEyrchpZe4AF4dnDpBaa/7+gcIafe9YiKaAB6/Lzppqb8Hg/uTZQQYnIrz2ylYuX1OVlrkfuDAMwNUFMvdqn4uAxzGj9LMaePBoNz841JV83SyeOjfI9w928ugi7HFYzRQd3JVSlcB3gQ9prccyfnwHcAhoBXYDn1VKZTUCa62/qLXeo7Xe09AwfyMJYelIFlQnjeDeMTRJLKGTnSn5ON4dpD8Y5iVbjfd/c0NlWpHzha5RLjN7yC8Vkf1eGJykc2SK7tHcWX44FmdoIpJ0q9rcUFkwuP/4+S4q3Q5u2dbAlWurONkbZDJifDo50DFCg98944iLDXUV0jEDPGcG9d4M60Hr+1O9wUVf02qiqOCulHJiBPb/1lp/L8cp7wC+pw1OA+eA7aVbprDccDlseJ32ZOZ+1sy+M/8jZ/LoKeMT20u2GMG9vbESrY3Hh6Jxzpjjil0OGxeLkGUeO21kfyOT0ZwdKn3mzaY5Nbj3TZBIZG++CsfiPHi0h1fsasLjtHPF2moSGl4wpaIDHcNcvb56xsFj6+t8Istg3AyBrBu+9W/kxR4J7gtJMd0yCsNG77jW+tN5TusAXmae3wRsA86WapHC8iTgdSQ1dysbHpqIEI7lL4T+5lQ/25r8SW/X9sZKAE73j3OyN0g8obmstYq1Nd6iOmYePz390b4rR/beFzQCSWPAMBHf3FjBVDSe08j6NycHGAvFkl08V6wzetkPXxplYDzMhcHJgpKMxYZaH53DU8TiWcrkqqE/GE7e4DJf655RI9ifmuduYaEwxWTuNwJvAW5TSh0y/7xKKfUepdR7zHP+DrhBKXUE+BXwF1prEdTKnIDHmZK5T/9H7csjzcQTmoMdI+zbVJs8trG+wihy9o0nM+RdrVWsq5k5+40nNE+cGaTNLGJ2j2QHbCuQWDeTzQ3GzSSXNPPzYz1UeZ3c1F4PQKPfQ0uVh8OXRpK68TUFiqkWG+p8xBI66em7GjnQYbxeTruidzS3LHNhcKJkHVFCNsV4qD4GFPwcqrXuAl5RqkUJKwNrvgwYsordZni39gVDrEsZMmZxbmCcyUg8beu+x2lnXY2P0/3jDE1E8LsdrK3xsq7Wy8GO4axrpHK0c5TRqSh/ePNG/unnJ3Nm7lYgafJnBPe+cW7ekl73OT84ybYmP077dM5zxVqjqNpS5cVpV1yWZ2dqKtZzvzA4mfN1WA0c6BjGaVdc21abnbmPhXA5bERiCU73jRf1mgqzR3aoCnMmdTLk2YEJrjDNK6xsOROr8+SKDJOL9sZKM3MfZUdLAJtNsb7Wx1goVnAHrKW3v/7qtUDuzL3XDCTVPqMAXF9pdLPkGkPQOxZKZvgWV6yt5tzABI+82MfO1qqiLBytAWurWXc/cGGYXa1VbKjzZRdUR0PsbTM+vZ3qE919oZDgLsyZgNfJ2FSM4YkIQxMRrt9UB+Qvqh6+NIrXaU9mzxbtjZWcHZjgRE+Qna1Gp8y6GiPjLaS7P356gO3NflqrvdRXuugZy525NwXcySKoUorNjZVpvfVgtFT2jOYK7saN6ERPsODmpVSaAx5cdtu8/VQfOtHLW770dLJusFKIxBIcvjTKNRtqaAp4GBiPJMc4TIRjBMMxrttYi9OuONkruvtCIcFdmDNVpixzdsD4D3rNhhpcdlve4H60c5RdrYEs4+7NDRVEYgkmI/Hp4G7KGZfy9LpPReLsPz+c1Mdbqrx05dLcx0JJScaira4iK6semYwSjiWSLZMWV6yZlpCu3pB7EmQmdptibY133nPd7z/czW9ODfDm/3ia/mDhFtPlxPHuMcKxBFevr0l2KVk3KEuiWVvrZVN9JSeXScfMt57tKIlL13JCgrswZywfVWs7/+aGShoD7pzBPRZP8ELXWJbvKEx3zADsbMnM3HO3Q+6/MEQknuDGLVZw9+Tsde8bC9OUkY2vqfbSMxZK62axgk5LxrlVPmeyYFtMp4xFKdohX+gcY1N9BZeGp3jzPU8xML4yArzV3371hurkzdL6N2EVV5sCHrY0VXJygWWZeELzjw+eoK9Ai27nyBR/8d0jfP3pCwu6lsVGgrswZwJeBwkNhztHcNqNbLU54MnZZnimf4KpaDznqNz2BmPCosOm2NJkBPoqnxO/x5F3l+pjpwdw2lVSu22t9mZp7lrrnJn7mhov8YROW6f1dWbmDrB3Yy0b6nxpXrIzsb7WR8fg5JzNTELROKf7x3n1FS18+e3X0jE0yVu/9EzO/vzlxoGOYVqrPLRUeZOvp1WHsV7n5oCHrU1+Lg5NJTeJLQQv9gT5/CNn+Pmx3rznWDeeF7oy92aubCS4C3PG2qV6sGOEtroKHHYbTQFPzlbII525i6lgBPL6Sjdbmvy4HdMFy0LtkM+cG+LKtdVUmJ6uLVUeguEYwZQ5JuPhGJOROM1V7rTHWraBnSmbpHrMjDJTcwf4xGt38Z33XJ9zHflYX+sjGI4xPDm3kcgv9hg9/7taA1y/uY6Pv3IHx7rHVkSR9mDHCFeZLaPW62kF0GRwrzKCO8CpBdTdu0aM97iQ5GJJXke7RvOesxKR4C7MGWu+zImeIJvMiYtNZuaembEeuTSCz2VnY31l1nUA3nFjG2+9fkPasXW1uTcyaa051Tue1OcBWsyAndpb3psnG7fGB3SOpAd3paDRn34jAKh0O2j0Zwf9Qsy3Y8YKNJZt5O51ht5/vHt5Z5c9oyE6R6aSxecanxOXw5Ymy/g9DnwuB1vNT2kn84whyNUDHwxF+cA3DuYdN5GJdV4xwf3i0NS8fYGXExLchTljZe7xhGaT2QHTFHAzGYkzHk7/qH2kc5TLWquyiqkW7721nTftXZ92bH2tj0vDU1k3iq7REOPhGFuapg0zLK28KyVgW9veM4N7a47Mvdec+Z7a4z4f1id73efWMfNC1xgBjyN5I9rW7Memln9wf/Ks0Z66p80I7kopmgLuZMZujV8G4wbocthy7lQ9PzDBZX/zM545N5R2/KETffzo+S5+c7K4PZKdplQ3WCC496UUq4+VkTQjwV2YM5ZhB8CmeiNTnf4YPv0fplAxtRDran2EY4msThEr09uaUoi1gntPSubeM5o7c/c47dRXutMy9+7R6aBTCqzgPlfTkRc6R9nVWpVs4fQ47Wysr+BY9/LoLsnHz4720hRwc1mKUX1zwJN8L3rGwsl/I3abor2hMueMmVN948QSmp8cSR/l/KgZ1PN1UWViZe6DBYrR/cEwbocRCl8oI2lGgrswZywfVYDNZqC15IvUjplTfeOEY4m8vqP5SHbMZPxHtqYJbk3J3JsCHpQysnqL3qAV3LOlljU13rTgnmsD03zwuuw0+t1zmg4ZjSc43hNMTse02NESWNaZ+1QkziMn+7hjVzO2lE9oTQFPmiyTerPd2lSZczqk1Tr5yIvTXrpaax47bQyey5z1PzwR4WX//EjS49aiWM19Y30FTQF3WRVVJbgLc8aSZQA2m1p6ZgENpoups8/cDUkisx3yZO849ZVuaiqmzb6cdhuNfjfdqQE7Rd/NZG21N72gOlbazB2M7P3CHDL3M/3jRGKJpN5usaMlQOfI8tWFf32yn1A0wZ27mtOOWx1U8YSmfzyc9jpvbfbTNRpKK4TDtA5+fnCScwOGtHW6bzz5iTAzuL/QNcaZ/gmeOJMu13QVIcv0B0M0+I1PG6sqcy/GQ9U87xZzqNgLSqlfl36pwnLDb7ox1VW4qDK391tZcmqb4ZFLo1S6HWw0i4zFsjbPLtVTvcFkMS6VlipvWkG1OyNLTMXK3LXWhKJxRiajJc3cweh1n4ss80KnkT1mZu7WHoATRWTv+88P8bHvHia+iK2TP3uhh2qfk70ba9OON1d5CEUTnO0fJ57QafsOtjYan74yd6r2BcNJA3Ure7fMPa7bWJsly5wzaxupJinxhE4mGcMTkbxtqf3BMI1+D7taA5zuGy8bc/OSeKgqpaqBzwN3aa13AW8s+UqFZYfDbqPClT5OwOdy4Pc40tohD18aYVdrIO2jejF4nHYa/O60jpNEQnOqbzxNkrForfYkh4dFYgmeOjvIFXmkoDXVXsKxBAPjkek2yBJn7htqK+gZC2V1fXSNTPGpn53g7+8/lvNxR7uMMQ2ZnUU7zOA+kzRzYXCCd311P9989iLnBhZne38kluCXx3u5fUcTjoyitHWDPXTRmO+e+jpbhuKpEhkYm882NVSwqaGCh180pJjHTvWzqb6C6zbVGQbmselNaBfM7P5sysyg/mCYWEKzqb6CWEKnWUJaaG18mmjwu9nZWkVCk2WKvlIplYfq72GYdXSY5/UhrAo2NVRmeYo2pRTQhiYiHOkc5Tpz7sysr19fwfGU/2ydI1NMRuLJzU6pNAeMjUyWNjsWivGaK1tyXjfZ6z4ylcz2S5+5e9F6uvh3fmCCP/7ac9z8jw/zuYfPcM9j53Lu5n2ha4wdLf6szqKmgJsan5PjBYqqwVCUd967nwmzW+n0DGbgpeLJs4MEQ7EsSQamX9fnL2UHd6sQ3p0R3PuDIRoDHm7Z2shTZwcZnYzy1NkhbtpSz9oaLwmdXjw/b9Y2UjN360ZvTZ0cnMguqo5MRonGtSHLmJ+UykV3L5WH6lagRin1iFLqOaXUW/M8XjxUy4z7/vh6PvqKrWnHmgOeZDHz4RN9JDTcvqNxTtd/ydYGjnaOJf8jW1ME82XuU9E4o1NR7n++m4DHwU3tue0c19RMt0Pm64efL+trp3vd4wnN+75xgMdODfCumzfyud+7GoD959PHGicSmuNdY1l6OxhthTtaAmk3u1TiCc0Hv3mI8wMTfOHN1wCFzcBLyYNHe/C57NxkjoNIxQrmz1809OzUArff48TvdmTNvu8Lhmn0u7l1ewORWILPPXKaqWicm9rrk+2hqdKM1XLaOxZO3tisYurlyeCerbv3m100jX43a6q9VHmdZaO7l8pD1QFcA7waw0/1fyiltmacIx6qZYjbYc/6GN4YcCdniPzqRHZr3Gx4+c6m5HVgWpu1tNpUWqqM//TnByf5xbFe7tjVjMuR+594MriPTKbtmiwlG+qm57p//ZkOjnaO8b9efzkff+UO08rPxv4L6X3cHUOTBMOxLL3dYkdLgBd7glkuT5FYgo98+xAPnejjb+7axe07m2it8mRNv5wP4VicBw53Z2nX8YTmF8d6uHV7Y86RyA3mxrATPWPYbYq6yvTupZZqT9r+hERCmzq4m70ba/E67fzn4+ex2xTXb65LdlFZRdVEQnNhaDIZ9K3s3RpHsct8LQfHcwR3s3Db4Dcmh+5qDayuzL0ID9VLwINa6wnTgelR4MrSLVNYSTQHPPQFw4SicR49OcBt25tmrbdbbGmsZF2tl18dN5S+k71BGv3uZAE3lZZqIzh/69mLBMMxXmPa5eUi4DFm13QOT9EzGsLvdlDpntG7ZlbUVbjwuewcujjCP/3sRW7YXMdrrjBkIqfdxpVrq5NDtixS3ahysaMlQDiWSJMfRqeivO3Lz/CDQ1189BVbecs+Y6dvrtHG8+GHB7t479cPcLQzPfgd7BhmYDySU5IBo3ZS43MSjWsa/e4suSmzED48GSGWMM51O+zc2F5HJJ7gqnXV+D1Omqs82NR05t5t6u+3bjM+HVrdNV2jU1S4jP0BkLsdMjW4gyHhnOgJEi0Di8RSeaj+ELhZKeVQSvmA6zC0eWEV0hTwEEtofnq0m/FwbM6SDBhSxMu2N/H46QEmIzFO9Y6zrTk7awdoNTP37x64RI3PyQ2bC+v8a6qNjpme0VDW5MhSoJRhOvLDQ11MhGP87V270sy197TV8ELXWFJGAHj2/BAuuy1nTQFgR4vx3K3NTF0jU7zhC0+w/8IQn/mdK3nfbVuS525uqORM/3jJho0d7jQ088xxAVar63UZXTKpWJJXLunLmOg5HdytHaON5rm3mEHbknycdhstVd5k5m4VU1+61VADzplF1a6RKVqqvdSaLbNDOTT3pMeuGdx3tQaSDlErnZJ4qGqtjwMPAoeBZ4B7tNZHF2zVwrLG0lT/+6kOPE4bN7Zn67Cz4eU7mwjHEjx6coDTfeNsySHJgJF9OWyKSCzBnZc1zzhKYG2NESB6xkJZo35LhSXNvOPGtrRxCQB7NtQST2ieN7tI4gnNA0e6uXV7Q9oAtVTaGytx2BTHu8foGpnid7/4FD2jIe79g7381lVrs86djMTpLjDudjZYnypOZ+j4p/rGqfI6k9lvLizJK1dHUkuVl4HxcNJYvS8jm77zsmau21jL3bun+zjW1EwHd6uYuqM1QHPAk2yL7B4N0Vrtxe2w43c7cmvuwTAepy35qW2XOa+oHMYQlMRD1TzvU8CnSrEoYWVjZWf7Lwxz+46moqzpCnFtWy1+t4N7nzjPVDSes8cdjO3sTQEPnSNTvOaK/JKMxZpqL0+fG6LC5aC9cX43oHxcs6GGEz1BPnh7VgmKq9fXoJTxOt3QXs+TZwbpD4bTglgmboed9sZKnjgzyE+PdDM8EeFr77qOK9dlG4lYc/LP9I0nu4PmSjyhky2YmVnt6d5xtjRWpn0qycQK6rnqGpac1jsaZn2dLzl73cqm6yvdfOuP0qdyrq3x8tSZQcAoprocNloCHjbWV0zLMiNTyb0BtZWuvLKMpbfDtElMsYPJljOyQ1UoOakfvecjyVi4HDZesq2BJ88a/5kzM+BUWqo81FW4CkoEFmtqvARDMXqDpd+davHul2zm4Y/cklPPr/I52droZ7+pu//wUCd+t4Pbthd+zXa0BHj+4ggD4xHufefenIEdpoN7KSSGs/3jhKIJXHYbZ1Kup7XmZF8wr4xkUUiWseQ0q3VxuoMl/3uytsaX7HU/PzjBhlofNpuirb6C8wMThGNxBsYjySFxtRWunAXVvmCYhpQCr9thx+9xMJDj3JWGBHeh5BiZkPH1TIGqWF6+oyn5daFA8tE7tvHp39md1cGTizXVRpamdek7ZVIpVEy+pq2GgxeGmYzEePBoD3dc1jzjJ519m2rxexzc+wfXFnSHqqtwUe1zZskoFmOhKI+dKm66ojWC+JZtDVwYmkxuIBqciDAyGc0rlVkkZZmqbOnGytytbLlvLIzf7cDryv86pPa6nx+YTI5Y3lRfwfBklBNmTcKS2+oqXHllmcybSH2le8W4XhVCgrtQcpx2G3UVbq5cV50sis2XW7Y1YLcpWqo8aTNtMtm3qS5ZWJsJqx0SSr87tVj2bKghGI7xb78+SzAc4+7dM8tJv3Pteg78j5dzzYbCn06UUmxuyN0xMxWJ8/YvP8Pvf+nppOZfiBc6x3A7bNyxq5l4Qie7dazi6kyZu9WmaI2USCW5kcksqvYHwzTkGPaW63odQ5NcGJpIWiG2mZ0xj5szZlIz91wFVWt3aip1ebL8lYYEd2FB+OtX7+AvX7m9ZNer9rm4dVtjUXJLsaTq0AuZuRdijxmg//3XZ6ivdHPD5uK0/2Lnzrc3VKbJKGCMYH7/Nw5w8OIIdpvKGqubi6Ndo2xvCSQ7lawbhvX3TJn7jZvr+co7rmXPhuxPGj6XgyqvM9mX3hcM5TRNScXqdT/QMUwommCDGdSttscnThsS3nRwdzOUMV8mHDNmCmUF90pXzt2sFlprOgYnl327pAR3YUF43VVr5jxyIB9ffMs1fOZ3dpfsevWVruQc76UK7utqvTT43YRjCV57ZUteM5O50t5YyeBEhGFTktBa89c/OMovj/fxybt28ZIt9TxwJHtjUipaa17oGuOy1gCbGypRajqon+odx+925ByrnIrNprh1W2PeomuqwXlfDqkkE6vX/bHTRoZuDaVbX+vDpoyWUuu6YGTj0bgmmNJ2aunqmTeSukp3zsx9dDLKV588z6v+9TFe8qmH+crj5wqucamR4C6sGGw2VbAjY7YopVhT7cVpV9T6XDM/YAFQSiWz2dcV6JKZK8mOGVN3/9rTHXzz2Yu8/7Z23nJ9G6+8vIVLw1PJXvVcXByaIhiKsau1Cq/Lzppq73Rw7wvS3lS4U6YYWqu9dJlzgfrGwjNm7lav+8EOoxhttZy6HDbW1hgmL3UVrmT9oq7S7HVPCdqZG5gs6itcDE1G0iZqhqJxbvmnh/nED1/AbjPafR8t0g1qqZDgLqxq1tR4afR75ryDthT8/r4NvPm69TnNw+dLasfM8EQkuVP2wy83WjNfsbMJh03xQAFpxiqmWiMR2lN2vp7uG885CmK2WJn7eDjGVDResGfeYk2Nl2hc47SrpPwC09KMVagFkhuZUouqVstltizjRmtjp6xF92iI4cko/+M1O7n//Tfzysta2H9hKG0y5XJDgruwqnnPSzfz53duW9I13Nhez//8rctL+qnEwtjEY+N03zj/8suTBENRPvHancnfVe1zcWN7PT8pIM280DWKw6aSw9raGyo5OzDOwHiYgfHIjMXUYmip8jA8GU2Od26cQeaB6aLqulpfmpxlBXerxRKgrsK4XqrdXr6WSyvLT5VmrMF1282aw75NtYSiCY50zlyMXiokuAurmhvb6wtuGlrp2G2KTQ2VPPxiH197uoPfu24925vTh5K96vJmLg5NZc2MsTjaOUZ7Y2VS4mhvrCQUTfCIOWe9vbEUwd0IxIdNm7yZNHeY7rxpyzCBSQb3lGy+1pJlJrJlGSuYW+S6EfSMGfUAq09/70ajnvTU2fTBb8sJCe6CUOa0N1Zypn+CCpedD788+1PKK3Y2G10zR7OlGaOYOpqciW5dD+BB8/xCm8qKxZJQDpsz32fS3GE6c88M7lY7ZOpIibpcskwwTG2FK6vzqN4M9gMTqZm7EeitwntthYvtzX6eMjfWLUckuAtCmdNuOmV96PatSe05lZoKFzdsrsspzfQFDenlstbpbN8K7o+eGqDCZae1BJ1GloRy6OJsMnczuNen987vbAngdzvSdu56nHZ8LntW5p7rJmKNJE7N3HvHsieH7ttUx/7zw8tWdy+Zh6p57rVKqbhS6g2lXaYgCHPldVe18ie3bOYt12/Ie87du9dwYXCS933jIONmu2AkluCe35wFYFdK5l7tc1Ff6SISS9De5C9JrcDKiE/2BnE5bAS8M49fvmxNFTe113PzlvRNaw1+N0f+9g72ZbTiGhuZ0oN7rsJttdeJTaVr7t2jU1ntsvs21TIVjS9b3b2YAdaWh+oBpZQfeE4p9QutdZoBpFLKDvwD8LMFWKcgCHNkQ10Ff35n4Q1lr79qDf3BMJ/62QmOd4/xgdu28LmHT3Oqb5y7rmzlqoz5NZsbKhkYH2JLCfR2MDJrK/i2VHmKumEEPE6+9q7riv4ddZXuNFmmPxhmU322abvNpqitcKdtZOoZC2cF91TdfabdwktBqTxUAd6PYegh/qmCsMKw2RR/fMtmvv6H+wiGYnzoW4eYjMT58tv38K9vuiprVo8lzZQquMO0Rl6M3j4XjLECRsDWWufN3MHQ3VOHh/WOhrKGni133X1W1jP5PFSVUmuA3wJuA64t8Ph3A+8GWL9+/exWKgjCgrNvUx0PfOAmfnW8j7t3t+Jz5Q4RyeBegjZIi5YqLy90jRWlt8+F2gpXcmzx4ESESDxRILi7kzeCWDxBXzD3zP99m+r41rMXicYTRY+EWCxK5aH6L8BfaK3jha4hHqqCsPxp9Ht40971eQM7GO5I+zbVcs360skRrWbHTDEbmOaCNRlSa81XnzgPkKXLJ8+tnJ4iOTAeIaFzjyu2dHerhXM5USoP1T3AN5VS54E3AJ9XSr2uZKsUBGFZsbG+gm+++/qcXrZzxep1XyhZprbCKAJfGJzknsfO8eorWtJaPFOpq5ieL2PNvMmVue/dWIfdpvjod57newcuZRmX5+JEz9iidNiUxENVa71Ra92mtW4D7gP+RGv9g5KuVBCEsiapuRexO3UuWG2gf/OjF4jEEnz0Ffl3JtdVuhgPxwhF4/SaYwpyZe61FS7uedsePE47H/7289z+6V9zKsNjNpUTPWO88QtP8vcPHMt7TqkoiYeqIAjCfLE2H63LMfO9FNSb/eu/PtnPm/auT+5kzX3u9KYna/RAPp/dW7c18sD7b+Lf33INl4anuO+5SznP6xqZ4u1ffhaf2857Xrp5Pk+lKErmoZpy/tvnsyBBEFYnu9dV8/0/uYHdeWwD54uVuftcdt7/svaC56aOIOgeC+Gy23JuALOw2RR37GqmKeBJGnynMjoV5e1feYaJcIxvv+f6tNEIC8WsumUEQRAWkqsK2AbOF6N/Ht5186YZO3JSh4f1joZoDLiL6r1vCriTMk4q7//GQc4NTHDvO/ayoyWQ45GlR4K7IAirgsaAh59+8OYZXaNgWsLpHw/TPZq7DTIXTQFP0nrQYjIS49GT/bz31s3c0F6c01YpWF6NmYIgCAvI9uZAUW5XaZn7WPYGpnw0BTz0jaXLMpY3bCmmZ84GCe6CIAgZ+FwOvE47A+NhesaKz9wbA26C4RiTkWk7P8sbtqVq4XX2VCS4C4Ig5KCu0sXZ/nFC0UTxmbup5adm711mn3yrBHdBEISlp67SzQtdxmb8Yg3UrZtAalHVytybqhamfz8fEtwFQRByUF/hSrY1zkaWAegNprs41Ve6cDvspV9kASS4C4Ig5CDVfm/2ssx05t41Elp0vR0kuAuCIOTEcmRSqjhnKICA14HbYUuXZXIYfSwGEtwFQRByYPmu1lW4cTmKC5VKqaxdqt2joZJYEc4WCe6CIAg5sEYPF6u3W6TuUh0PxwiGYrQswriBTErioaqUerNS6rD55wml1JULs1xBEITFwZovU6zebtGYspGpeyT/uOCFppjM3fJQ3QHsA96rlNqZcc454KVa6yuAvwO+WONfiWwAAAZ2SURBVNplCoIgLC5WQbV5li2MTX5PMnPvGl2aDUxQ3FTIbqDb/DqolLI8VI+lnPNEykOeAtaWeJ2CIAiLihXcZxuYGwNuJiJxxsMxegoYfSw0JfFQzeCdwE/nviRBEISlp9Hv4e9edxmv2Nk0q8c1Wb3uYyG6RkIoNXtppxQUHdxn8FC1zrkVI7jflOfnYpAtCMKK4S37Nsz6MVave+9YiO7RKeori++2KSWl8lBFKXUFcA9wt9Z6MNc5YpAtCEK502hm6f3B8JK1QUKJPFSVUuuB7wFv0VqfLO0SBUEQVg6psowxC37xi6lQnCxjeageUUodMo/9JbAeQGv9b8AngDrg86ZbSUxrvaf0yxUEQVjeVLod+Fx2ekbDdI9McdMiGnSkUhIPVa31u4B3lWpRgiAIKxVrl+rp/nEmInFaq5epLCMIgiDMjka/m+cvjgBL0+MOEtwFQRBKTmPAw+hUFEAyd0EQhHKhyT+9q7VZMndBEITywNq0ZFPpgX4xkeAuCIJQYixHpka/B4d9acKsBHdBEIQSY2XuS2HSYSHBXRAEocRYwX2piqkgwV0QBKHkWLtUl6oNEmY5FVIQBEGYGZ/LwcdeuZ1bti3dDC0J7oIgCAvAe166eUl/v8gygiAIZUipPFSVUupflVKnTR/VqxdmuYIgCEIxFCPLWB6qB5RSfuA5pdQvtNbHUs55JbDF/HMd8AXzb0EQBGEJmDFz11p3a60PmF8HActDNZW7ga9qg6eAaqVUS8lXKwiCIBTFrDT3Ah6qa4CLKd9fIvsGIAiCICwSRQf3GTxUc8171zmu8W6l1H6l1P7+/v7ZrVQQBEEomlJ5qF4C1qV8vxboyjxJPFQFQRAWh5J4qAI/At5qds3sA0a11t0lXKcgCIIwC5TWWepJ+glK3QT8BjgCJMzDaR6q5g3gs8CdwCTwDq31/hmu2w9cmOO664GBOT52pbLanrM83/JmtT1fKN1z3qC1nlH6mDG4L0eUUvtXmwH3anvO8nzLm9X2fGHxn7PsUBUEQShDJLgLgiCUISs1uH9xqRewBKy25yzPt7xZbc8XFvk5r0jNXRAEQSjMSs3cBUEQhAKsuOCulLpTKfWiOYHyY0u9nlKTbwqnUqpWKfULpdQp8++apV5rKVFK2ZVSB5VS95vfb1RKPW0+328ppVxLvcZSopSqVkrdp5Q6Yb7X15fze6yU+lPz3/NRpdQ3lFKecnqPlVJfVkr1KaWOphzL+X4u1hTdFRXclVJ24HMYUyh3Am9SSu1c2lWVHGsK5w5gH/Be8zl+DPiV1noL8Cvz+3LigxhD6Sz+AfiM+XyHgXcuyaoWjv8DPKi13g5cifHcy/I9VkqtAT4A7NFaXwbYgd+lvN7j/8TY55NKvvczdYruuzGm6JacFRXcgb3Aaa31Wa11BPgmxkTKsqHAFM67gXvN0+4FXrc0Kyw9Sqm1wKuBe8zvFXAbcJ95Srk93wDwEoyd32itI1rrEcr4PcYYL+5VSjkAH9BNGb3HWutHgaGMw/nez0WZorvSgvuqmj6ZMYWzyRrpYP7duHQrKzn/Avw50zug64ARrXXM/L7c3udNQD/wFVOKukcpVUGZvsda607gn4AOjKA+CjxHeb/HkP/9XJQ4ttKCe1HTJ8uBGaZwlg1KqdcAfVrr51IP5zi1nN5nB3A18AWt9VXABGUiweTC1JrvBjYCrUAFhjSRSTm9x4VYlH/fKy24FzV9cqWTZwpnr/XRzfy7b6nWV2JuBO5SSp3HkNluw8jkq82P8FB+7/Ml4JLW2vJFuA8j2Jfre3w7cE5r3a+1jgLfA26gvN9jyP9+LkocW2nB/Vlgi1lld2EUZX60xGsqKQWmcP4IeJv59duAHy722hYCrfXHtdZrtdZtGO/nQ1rrNwMPA28wTyub5wugte4BLiqltpmHXgYco0zfYww5Zp9Symf++7aeb9m+xyb53s/FmaKrtV5Rf4BXASeBM8BfLfV6FuD53YTxEe0wcMj88yoMHfpXwCnz79qlXusCPPdbgPvNrzcBzwCnge8A7qVeX4mf625gv/k+/wCoKef3GPhb4ARwFPgvwF1O7zHwDYx6QhQjM39nvvcTQ5b5nBnDjmB0EZV8TbJDVRAEoQxZabKMIAiCUAQS3AVBEMoQCe6CIAhliAR3QRCEMkSCuyAIQhkiwV0QBKEMkeAuCIJQhkhwFwRBKEP+H5TlhPQ/zl45AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 80\n",
    "batches = 28100 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 100\n",
    "\n",
    "my_encoder = EncoderRNN(len(english_vocab), hidden_size)\n",
    "my_decoder = DecoderRNN(hidden_size, len(indo_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()\n",
    "\n",
    "train(my_encoder, my_decoder, batches, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 28100\n",
      "encoder_vanilla_100_28100.pkl\n"
     ]
    }
   ],
   "source": [
    "print(hidden_size, batches)\n",
    "print(f'encoder_vanilla_{hidden_size}_{batches}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# # In Python >= 3.6\n",
    "# with open(f'./models/encoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "#     pickle.dump(my_encoder, fout)\n",
    "# with open(f'./models/decoder_vanilla_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "#     pickle.dump(my_decoder, fout)\n",
    "\n",
    "# # For Python < 3.6\n",
    "# with open('./models/encoder_vanilla_{}_{}.pkl'.format(hidden_size, batches), 'wb') as fout:\n",
    "#     pickle.dump(my_encoder, fout)\n",
    "# with open('./models/decoder_vanilla_{}_{}.pkl'.format(hidden_size, batches), 'wb') as fout:\n",
    "#     pickle.dump(my_decoder, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/encoder_vanilla_100_28100.pkl\n",
      "./models/decoder_vanilla_100_28100.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "filename = f'./models/encoder_vanilla_{hidden_size}_{batches}.pkl'\n",
    "print(filename)\n",
    "my_encoder = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename = f'./models/decoder_vanilla_{hidden_size}_{batches}.pkl'\n",
    "print(filename)\n",
    "my_decoder = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(kopi_order):\n",
    "    output_words = translator(my_encoder, my_decoder, variable_from_sent(kopi_order, english_vocab))\n",
    "    print(output_words)\n",
    "    output_sentence = [indo_vocab[i] for i in output_words[1:output_words.index(1)]]\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pier/anaconda3/envs/gensim/lib/python3.6/site-packages/torch/nn/modules/rnn.py:179: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('French Muslims fined for face veils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
