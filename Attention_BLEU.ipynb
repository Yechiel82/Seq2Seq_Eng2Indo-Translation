{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Indonesian attention based translation on simple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "1. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Run!\\tLari!',\n",
       " 'Who?\\tSiapa?',\n",
       " 'Wow!\\tWow!',\n",
       " 'Help!\\tTolong!',\n",
       " 'Jump!\\tLompat!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "fp = open('./corpus/eng-indo.txt', 'r')\n",
    "text = fp.read()\n",
    "text = text.splitlines()\n",
    "fp.close()\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6752, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Lari!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Siapa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Wow!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Tolong!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump!</td>\n",
       "      <td>Lompat!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English Indonesian\n",
       "0    Run!      Lari!\n",
       "1    Who?     Siapa?\n",
       "2    Wow!       Wow!\n",
       "3   Help!    Tolong!\n",
       "4   Jump!    Lompat!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dict = {\"English\": [], \"Indonesian\": []}\n",
    "for l in text:\n",
    "    split_text = l.split(\"\\t\")\n",
    "    text_dict[\"English\"].append(split_text[0])\n",
    "    text_dict[\"Indonesian\"].append(split_text[1])\n",
    "    \n",
    "df = pd.DataFrame.from_dict(text_dict)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "      <th>keep_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Lari!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Siapa?</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>Tolong!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump!</td>\n",
       "      <td>Lompat!</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English Indonesian  keep_column\n",
       "0    Run!      Lari!         True\n",
       "1    Who?     Siapa?         True\n",
       "2    Wow!       Wow!         True\n",
       "3   Help!    Tolong!         True\n",
       "4   Jump!    Lompat!         True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keeping to 20 to heavily restrict the scope for now to be improved as we progress\n",
    "MAX_LEN = 15\n",
    "\n",
    "def check_sentence_len(row):\n",
    "    indo_num_words = len(word_tokenize(row[\"Indonesian\"]))\n",
    "    eng_num_words = len(word_tokenize(row[\"English\"]))\n",
    "    num_words_required = MAX_LEN - 2\n",
    "    return (indo_num_words <= num_words_required) and (eng_num_words <= num_words_required)\n",
    "\n",
    "#df[\"Indo_num_words\"] = df[\"Indonesian\"].apply(str.lower).apply(word_tokenize).apply(len)\n",
    "#df[\"Eng_num_words\"] = df[\"English\"].apply(str.lower).apply(word_tokenize).apply(len)\n",
    "df[\"keep_column\"] = df.apply(check_sentence_len, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape: (6752, 3)\n",
      "New shape: (6535, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Run!</td>\n",
       "      <td>Lari!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Who?</td>\n",
       "      <td>Siapa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>Wow!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Tolong!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Jump!</td>\n",
       "      <td>Lompat!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index English Indonesian\n",
       "0      0    Run!      Lari!\n",
       "1      1    Who?     Siapa?\n",
       "2      2    Wow!       Wow!\n",
       "3      3   Help!    Tolong!\n",
       "4      4   Jump!    Lompat!"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Current shape: \" + str(df.shape))\n",
    "df = df[df[\"keep_column\"]]\n",
    "print(\"New shape: \" + str(df.shape))\n",
    "df.head()\n",
    "df = df.reset_index().drop(columns=[\"keep_column\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First English sentence: ['<s>', 'run', '!', '</s>']\n",
      "First Indo sentence: ['<s>', 'lari', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "UNK, UNK_IDX = 'UNK', 2\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "english_sents = [START] + df['English'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "indo_sents = [START] + df['Indonesian'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First English sentence:', english_sents[0])\n",
    "print('First Indo sentence:', indo_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '!'), (4, 'lari'), (5, '?'), (6, 'siapa'), (7, 'wow'), (8, 'tolong'), (9, 'lompat')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, 'UNK'), (3, '!'), (4, 'run'), (5, '?'), (6, 'who'), (7, 'wow'), (8, 'help'), (9, 'jump')]\n"
     ]
    }
   ],
   "source": [
    "english_vocab = Dictionary([['<s>'], ['</s>'],['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])\n",
    "\n",
    "import pickle\n",
    "# Lets save our dictionaries.\n",
    "#with open('./vocabs/simple_indo_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "#    pickle.dump(indo_vocab, fout)\n",
    "    \n",
    "#with open('./vocabs/simple_english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "#    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0],\n",
       "        [111],\n",
       "        [ 23],\n",
       "        [130],\n",
       "        [  5],\n",
       "        [  1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizes a sentence with a given vocab\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END], unknown_word_index=2)\n",
    "\n",
    "# Creates a PyTorch variable from a sentence against a given vocab\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    #print(vsent)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    #print(result)\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Test\n",
    "new_kopi = \"Is it love?\"\n",
    "variable_from_sent(new_kopi, english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5554, 3)\n",
      "(981, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_val = train_test_split(df, test_size=0.15)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>905</td>\n",
       "      <td>Let's do it again.</td>\n",
       "      <td>Mari kita lakukan lagi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5550</td>\n",
       "      <td>The man lent me two books this morning.</td>\n",
       "      <td>Orang itu telah meminjamkanku dua buku pagi ini.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654</td>\n",
       "      <td>When will you return?</td>\n",
       "      <td>Kapan kamu akan kembali?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>Where've you been?</td>\n",
       "      <td>Ke mana saja kamu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6592</td>\n",
       "      <td>You must not leave her waiting outside in such...</td>\n",
       "      <td>Jangan buat ia menunggu di luar dengan cuaca y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            English  \\\n",
       "0    905                                 Let's do it again.   \n",
       "1   5550            The man lent me two books this morning.   \n",
       "2   1654                              When will you return?   \n",
       "3   1013                                 Where've you been?   \n",
       "4   6592  You must not leave her waiting outside in such...   \n",
       "\n",
       "                                          Indonesian  \n",
       "0                            Mari kita lakukan lagi.  \n",
       "1   Orang itu telah meminjamkanku dua buku pagi ini.  \n",
       "2                           Kapan kamu akan kembali?  \n",
       "3                                 Ke mana saja kamu?  \n",
       "4  Jangan buat ia menunggu di luar dengan cuaca y...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the training and the validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mari kita lakukan lagi.\n"
     ]
    }
   ],
   "source": [
    "indo_tensors = df_train['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(df_train.iloc[0]['Indonesian'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's do it again.\n",
      "tensor([[  0],\n",
      "        [ 94],\n",
      "        [ 41],\n",
      "        [117],\n",
      "        [ 23],\n",
      "        [104],\n",
      "        [ 10],\n",
      "        [  1]])\n"
     ]
    }
   ],
   "source": [
    "english_tensors = df_train['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "print(df_train.iloc[0]['English'])\n",
    "print(english_tensors[0])\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs = list(zip(english_tensors, indo_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                            English  \\\n",
      "0    905                                 Let's do it again.   \n",
      "1   5550            The man lent me two books this morning.   \n",
      "2   1654                              When will you return?   \n",
      "3   1013                                 Where've you been?   \n",
      "4   6592  You must not leave her waiting outside in such...   \n",
      "\n",
      "                                          Indonesian  \n",
      "0                            Mari kita lakukan lagi.  \n",
      "1   Orang itu telah meminjamkanku dua buku pagi ini.  \n",
      "2                           Kapan kamu akan kembali?  \n",
      "3                                 Ke mana saja kamu?  \n",
      "4  Jangan buat ia menunggu di luar dengan cuaca y...  \n",
      "[(tensor([[  0],\n",
      "        [ 94],\n",
      "        [ 41],\n",
      "        [117],\n",
      "        [ 23],\n",
      "        [104],\n",
      "        [ 10],\n",
      "        [  1]]), tensor([[  0],\n",
      "        [106],\n",
      "        [105],\n",
      "        [197],\n",
      "        [117],\n",
      "        [ 10],\n",
      "        [  1]])), (tensor([[   0],\n",
      "        [ 269],\n",
      "        [ 349],\n",
      "        [2738],\n",
      "        [  31],\n",
      "        [ 402],\n",
      "        [ 859],\n",
      "        [ 167],\n",
      "        [ 208],\n",
      "        [  10],\n",
      "        [   1]]), tensor([[   0],\n",
      "        [ 162],\n",
      "        [  75],\n",
      "        [ 191],\n",
      "        [2029],\n",
      "        [ 430],\n",
      "        [ 492],\n",
      "        [ 224],\n",
      "        [  49],\n",
      "        [  10],\n",
      "        [   1]])), (tensor([[   0],\n",
      "        [ 485],\n",
      "        [ 301],\n",
      "        [  45],\n",
      "        [1026],\n",
      "        [   5],\n",
      "        [   1]]), tensor([[  0],\n",
      "        [514],\n",
      "        [124],\n",
      "        [193],\n",
      "        [311],\n",
      "        [  5],\n",
      "        [  1]])), (tensor([[  0],\n",
      "        [381],\n",
      "        [178],\n",
      "        [ 45],\n",
      "        [677],\n",
      "        [  5],\n",
      "        [  1]]), tensor([[  0],\n",
      "        [200],\n",
      "        [333],\n",
      "        [ 73],\n",
      "        [124],\n",
      "        [  5],\n",
      "        [  1]])), (tensor([[   0],\n",
      "        [  45],\n",
      "        [ 213],\n",
      "        [ 172],\n",
      "        [ 354],\n",
      "        [ 813],\n",
      "        [ 840],\n",
      "        [1073],\n",
      "        [ 332],\n",
      "        [1870],\n",
      "        [  93],\n",
      "        [1415],\n",
      "        [  10],\n",
      "        [   1]]), tensor([[   0],\n",
      "        [ 127],\n",
      "        [ 749],\n",
      "        [ 204],\n",
      "        [ 759],\n",
      "        [ 111],\n",
      "        [ 122],\n",
      "        [ 258],\n",
      "        [1699],\n",
      "        [  63],\n",
      "        [3976],\n",
      "        [  49],\n",
      "        [  10],\n",
      "        [   1]]))]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.iloc[:5])\n",
    "print(sent_pairs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
