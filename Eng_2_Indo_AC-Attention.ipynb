{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Bahasa Indonesian Attention based translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "1. https://github.com/ace-racer/kopitiam/blob/master/Kopitiam%20mit%20Attention.ipynb\n",
    "2. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "# Imports we need.\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction: 2007 year in review</td>\n",
       "      <td>Pendahuluan: Tahun peninjauan 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007 was another significant year for the Aust...</td>\n",
       "      <td>2007 kembali menjadi tahun yang signifikan bag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reconstruction after the 2004 Boxing Day tsuna...</td>\n",
       "      <td>Rekonstruksi yang dilakukan setelah terjadinya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This work was the centrepiece of the $1 billio...</td>\n",
       "      <td>Ini merupakan pekerjaan inti dari Kemitraan Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIPRD also includes large-scale social and eco...</td>\n",
       "      <td>AIPRD juga mencakup program pengembangan ekono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0                 Introduction: 2007 year in review    \n",
       "1  2007 was another significant year for the Aust...   \n",
       "2  Reconstruction after the 2004 Boxing Day tsuna...   \n",
       "3  This work was the centrepiece of the $1 billio...   \n",
       "4  AIPRD also includes large-scale social and eco...   \n",
       "\n",
       "                                          Indonesian  \n",
       "0                Pendahuluan: Tahun peninjauan 2007   \n",
       "1  2007 kembali menjadi tahun yang signifikan bag...  \n",
       "2  Rekonstruksi yang dilakukan setelah terjadinya...  \n",
       "3  Ini merupakan pekerjaan inti dari Kemitraan Au...  \n",
       "4  AIPRD juga mencakup program pengembangan ekono...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "corpus_df = pd.read_csv(\"./corpus/trimmed_combined.csv\")\n",
    "corpus_df = corpus_df.drop(columns=[\"English_num_words\", \"Indo_num_words\"])\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First English sentence: ['<s>', 'introduction', ':', '2007', 'year', 'in', 'review', '</s>']\n",
      "First Indonesian sentence: ['<s>', 'pendahuluan', ':', 'tahun', 'peninjauan', '2007', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "english_sents = [START] + corpus_df['English'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "indo_sents = [START] + corpus_df['Indonesian'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First English sentence:', english_sents[0])\n",
    "print('First Indonesian sentence:', indo_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, '2007'), (3, ':'), (4, 'pendahuluan'), (5, 'peninjauan'), (6, 'tahun'), (7, '.'), (8, 'australia'), (9, 'bagi')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, '2007'), (3, ':'), (4, 'in'), (5, 'introduction'), (6, 'review'), (7, 'year'), (8, '.'), (9, 'another')]\n"
     ]
    }
   ],
   "source": [
    "english_vocab = Dictionary([['<s>'], ['</s>']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Lets save our dictionaries.\n",
    "with open('gen/indo_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(indo_vocab, fout)\n",
    "    \n",
    "with open('gen/english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [5417],\n",
       "        [3692],\n",
       "        [5416],\n",
       "        [  11],\n",
       "        [3443],\n",
       "        [5418],\n",
       "        [   1]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizes a sentence with a given vocab\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END])\n",
    "\n",
    "# Creates a PyTorch variable from a sentence against a given vocab\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    #print(vsent)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    #print(result)\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Test\n",
    "new_kopi = \"French Muslims fined for face veils\"\n",
    "variable_from_sent(new_kopi, english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of English vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25933"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of Indo vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25781"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indo_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pendahuluan: Tahun peninjauan 2007 \n",
      "tensor([[0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [6],\n",
      "        [5],\n",
      "        [2],\n",
      "        [1]], device='cuda:0')\n",
      "Introduction: 2007 year in review \n",
      "tensor([[0],\n",
      "        [5],\n",
      "        [3],\n",
      "        [2],\n",
      "        [7],\n",
      "        [4],\n",
      "        [6],\n",
      "        [1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prepare the whole training corpus.\n",
    "indo_tensors = corpus_df['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(corpus_df.iloc[0]['Indonesian'])\n",
    "print(indo_tensors[0])\n",
    "english_tensors = corpus_df['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "print(corpus_df.iloc[0]['English'])\n",
    "print(english_tensors[0])\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs = list(zip(english_tensors, indo_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "MAX_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of output (i.e. no. of words in output vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # Set the output layer to output a specific symbol \n",
    "        # from the output vocabulary\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # Transform the embedded output with a relu function. \n",
    "        output = F.relu(output)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Take the updated output and find the most appropriate\n",
    "        # output symbol. \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        # Batch matrix multiplication: https://pytorch.org/docs/stable/torch.html#torch.bmm\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(input_variable, target_variable, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to put the variables, decoder and optimizers to train per epoch.\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "\n",
    "    # (Re-)Initialize the optimizers, clear all gradients. \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Initialize the length of the PyTorch variables.\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # Iterating through each word in the input.\n",
    "    for ei in range(input_length):\n",
    "        # We move forward through each state.\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        # And we save the encoder outputs. \n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input.\n",
    "        for di in range(target_length):\n",
    "            # We add the encoder_outputs for attention to the decoder forward step.\n",
    "            # And expect it to return the decoder attention.\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                         decoder_hidden, \n",
    "                                                                         encoder_outputs) \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            # We add the encoder_outputs for attention to the decoder forward step.\n",
    "            # And expect it to return the decoder attention.\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                         decoder_hidden, \n",
    "                                                                         encoder_outputs) \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == END_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data / target_length\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Some Logging and Plotting Candies to Monitor Training\n",
    "#########################################################\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Top-level function to start the training,\n",
    "# iterates across epochs.\n",
    "#########################################################\n",
    "\n",
    "def train(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [random.choice(sent_pairs) for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train_one_epoch(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (- 64m 55s) (100 0%) 7.3541\n",
      "0m 8s (- 66m 34s) (200 0%) 6.2347\n",
      "0m 12s (- 67m 58s) (300 0%) 6.2156\n",
      "0m 15s (- 65m 49s) (400 0%) 5.6654\n",
      "0m 20s (- 66m 26s) (500 0%) 6.1851\n",
      "0m 24s (- 66m 26s) (600 0%) 5.9129\n",
      "0m 27s (- 65m 50s) (700 0%) 5.5452\n",
      "0m 31s (- 65m 7s) (800 0%) 5.8880\n",
      "0m 35s (- 65m 10s) (900 0%) 5.7980\n",
      "0m 39s (- 64m 51s) (1000 1%) 5.6908\n",
      "0m 43s (- 64m 29s) (1100 1%) 5.3413\n",
      "0m 46s (- 64m 22s) (1200 1%) 5.7349\n",
      "0m 50s (- 64m 26s) (1300 1%) 5.7251\n",
      "0m 54s (- 64m 22s) (1400 1%) 5.6092\n",
      "0m 58s (- 64m 17s) (1500 1%) 5.6263\n",
      "1m 2s (- 63m 49s) (1600 1%) 5.3886\n",
      "1m 5s (- 63m 35s) (1700 1%) 5.5605\n",
      "1m 9s (- 63m 21s) (1800 1%) 5.3593\n",
      "1m 13s (- 63m 11s) (1900 1%) 5.8647\n",
      "1m 17s (- 63m 3s) (2000 2%) 5.8251\n",
      "1m 21s (- 63m 2s) (2100 2%) 5.5647\n",
      "1m 25s (- 63m 8s) (2200 2%) 5.7904\n",
      "1m 28s (- 62m 57s) (2300 2%) 5.5111\n",
      "1m 32s (- 62m 52s) (2400 2%) 5.5784\n",
      "1m 37s (- 63m 3s) (2500 2%) 5.8182\n",
      "1m 40s (- 62m 52s) (2600 2%) 5.2248\n",
      "1m 44s (- 63m 0s) (2700 2%) 5.8165\n",
      "1m 48s (- 62m 53s) (2800 2%) 5.3930\n",
      "1m 52s (- 62m 44s) (2900 2%) 5.7476\n",
      "1m 56s (- 62m 44s) (3000 3%) 5.4413\n",
      "2m 0s (- 62m 37s) (3100 3%) 5.6477\n",
      "2m 4s (- 62m 39s) (3200 3%) 5.5008\n",
      "2m 8s (- 62m 40s) (3300 3%) 5.5200\n",
      "2m 12s (- 62m 35s) (3400 3%) 5.5072\n",
      "2m 16s (- 62m 37s) (3500 3%) 6.0524\n",
      "2m 19s (- 62m 28s) (3600 3%) 5.3916\n",
      "2m 24s (- 62m 28s) (3700 3%) 5.8729\n",
      "2m 27s (- 62m 16s) (3800 3%) 4.9893\n",
      "2m 31s (- 62m 17s) (3900 3%) 5.6845\n",
      "2m 35s (- 62m 12s) (4000 4%) 5.6208\n",
      "2m 39s (- 62m 13s) (4100 4%) 5.5992\n",
      "2m 43s (- 62m 7s) (4200 4%) 5.3357\n",
      "2m 46s (- 61m 54s) (4300 4%) 5.1077\n",
      "2m 51s (- 61m 55s) (4400 4%) 5.8877\n",
      "2m 55s (- 61m 56s) (4500 4%) 5.2706\n",
      "2m 59s (- 61m 53s) (4600 4%) 5.4483\n",
      "3m 2s (- 61m 47s) (4700 4%) 5.1943\n",
      "3m 6s (- 61m 37s) (4800 4%) 5.0152\n",
      "3m 10s (- 61m 36s) (4900 4%) 5.7334\n",
      "3m 14s (- 61m 34s) (5000 5%) 5.2559\n",
      "3m 19s (- 61m 44s) (5100 5%) 5.7570\n",
      "3m 23s (- 61m 42s) (5200 5%) 5.4014\n",
      "3m 27s (- 61m 42s) (5300 5%) 5.7885\n",
      "3m 31s (- 61m 42s) (5400 5%) 5.7846\n",
      "3m 35s (- 61m 38s) (5500 5%) 5.5817\n",
      "3m 39s (- 61m 35s) (5600 5%) 5.2265\n",
      "3m 43s (- 61m 35s) (5700 5%) 5.6081\n",
      "3m 47s (- 61m 37s) (5800 5%) 5.6995\n",
      "3m 51s (- 61m 32s) (5900 5%) 5.5012\n",
      "3m 56s (- 61m 37s) (6000 6%) 5.7386\n",
      "4m 0s (- 61m 36s) (6100 6%) 5.2416\n",
      "4m 3s (- 61m 27s) (6200 6%) 5.5902\n",
      "4m 7s (- 61m 26s) (6300 6%) 5.6561\n",
      "4m 11s (- 61m 22s) (6400 6%) 5.4747\n",
      "4m 15s (- 61m 13s) (6500 6%) 5.4429\n",
      "4m 19s (- 61m 8s) (6600 6%) 5.5381\n",
      "4m 23s (- 61m 10s) (6700 6%) 5.7532\n",
      "4m 27s (- 61m 12s) (6800 6%) 5.5839\n",
      "4m 32s (- 61m 10s) (6900 6%) 5.4556\n",
      "4m 36s (- 61m 9s) (7000 7%) 5.4643\n",
      "4m 39s (- 60m 59s) (7100 7%) 5.4041\n",
      "4m 44s (- 61m 2s) (7200 7%) 5.5833\n",
      "4m 48s (- 61m 2s) (7300 7%) 5.7456\n",
      "4m 52s (- 61m 3s) (7400 7%) 5.4647\n",
      "4m 57s (- 61m 3s) (7500 7%) 5.5643\n",
      "5m 1s (- 60m 59s) (7600 7%) 5.3192\n",
      "5m 5s (- 60m 57s) (7700 7%) 5.7982\n",
      "5m 8s (- 60m 50s) (7800 7%) 5.5349\n",
      "5m 12s (- 60m 47s) (7900 7%) 5.6301\n",
      "5m 16s (- 60m 43s) (8000 8%) 5.4638\n",
      "5m 20s (- 60m 41s) (8100 8%) 5.3644\n",
      "5m 24s (- 60m 37s) (8200 8%) 5.6547\n",
      "5m 29s (- 60m 36s) (8300 8%) 5.5214\n",
      "5m 32s (- 60m 30s) (8400 8%) 5.2872\n",
      "5m 37s (- 60m 31s) (8500 8%) 5.6519\n",
      "5m 41s (- 60m 32s) (8600 8%) 5.5882\n",
      "5m 46s (- 60m 33s) (8700 8%) 5.7843\n",
      "5m 50s (- 60m 31s) (8800 8%) 5.2966\n",
      "5m 54s (- 60m 29s) (8900 8%) 5.4295\n",
      "5m 58s (- 60m 22s) (9000 9%) 5.3247\n",
      "6m 2s (- 60m 19s) (9100 9%) 5.5294\n",
      "6m 6s (- 60m 15s) (9200 9%) 5.7746\n",
      "6m 10s (- 60m 10s) (9300 9%) 5.3384\n",
      "6m 14s (- 60m 9s) (9400 9%) 5.5690\n",
      "6m 18s (- 60m 9s) (9500 9%) 5.4117\n",
      "6m 23s (- 60m 8s) (9600 9%) 5.4791\n",
      "6m 27s (- 60m 6s) (9700 9%) 5.3923\n",
      "6m 31s (- 60m 3s) (9800 9%) 5.2958\n",
      "6m 35s (- 60m 1s) (9900 9%) 5.4272\n",
      "6m 39s (- 59m 54s) (10000 10%) 5.3708\n",
      "6m 43s (- 59m 52s) (10100 10%) 5.5808\n",
      "6m 47s (- 59m 50s) (10200 10%) 5.3552\n",
      "6m 51s (- 59m 45s) (10300 10%) 5.3488\n",
      "6m 55s (- 59m 43s) (10400 10%) 5.5937\n",
      "7m 0s (- 59m 42s) (10500 10%) 5.4703\n",
      "7m 4s (- 59m 37s) (10600 10%) 5.4717\n",
      "7m 8s (- 59m 37s) (10700 10%) 5.6396\n",
      "7m 12s (- 59m 33s) (10800 10%) 5.1243\n",
      "7m 17s (- 59m 33s) (10900 10%) 5.8116\n",
      "7m 21s (- 59m 31s) (11000 11%) 5.6040\n",
      "7m 25s (- 59m 28s) (11100 11%) 5.5260\n",
      "7m 29s (- 59m 22s) (11200 11%) 5.3418\n",
      "7m 33s (- 59m 23s) (11300 11%) 5.5901\n",
      "7m 38s (- 59m 23s) (11400 11%) 5.4972\n",
      "7m 42s (- 59m 22s) (11500 11%) 5.5837\n",
      "7m 46s (- 59m 17s) (11600 11%) 5.0885\n",
      "7m 51s (- 59m 15s) (11700 11%) 5.4035\n",
      "7m 55s (- 59m 14s) (11800 11%) 5.4530\n",
      "7m 59s (- 59m 10s) (11900 11%) 5.4824\n",
      "8m 3s (- 59m 4s) (12000 12%) 5.4571\n",
      "8m 7s (- 59m 1s) (12100 12%) 5.3448\n",
      "8m 11s (- 58m 57s) (12200 12%) 5.4158\n",
      "8m 15s (- 58m 56s) (12300 12%) 5.7001\n",
      "8m 20s (- 58m 54s) (12400 12%) 5.4579\n",
      "8m 24s (- 58m 51s) (12500 12%) 5.3714\n",
      "8m 28s (- 58m 48s) (12600 12%) 5.4705\n",
      "8m 33s (- 58m 49s) (12700 12%) 5.6044\n",
      "8m 37s (- 58m 44s) (12800 12%) 5.6576\n",
      "8m 41s (- 58m 39s) (12900 12%) 5.3427\n",
      "8m 45s (- 58m 33s) (13000 13%) 5.3696\n",
      "8m 49s (- 58m 29s) (13100 13%) 5.4479\n",
      "8m 53s (- 58m 28s) (13200 13%) 5.3673\n",
      "8m 57s (- 58m 25s) (13300 13%) 5.4535\n",
      "9m 2s (- 58m 27s) (13400 13%) 5.6960\n",
      "9m 7s (- 58m 26s) (13500 13%) 5.4003\n",
      "9m 11s (- 58m 23s) (13600 13%) 5.3786\n",
      "9m 15s (- 58m 20s) (13700 13%) 5.6315\n",
      "9m 19s (- 58m 16s) (13800 13%) 5.5811\n",
      "9m 24s (- 58m 14s) (13900 13%) 5.5509\n",
      "9m 28s (- 58m 13s) (14000 14%) 5.4311\n",
      "9m 33s (- 58m 12s) (14100 14%) 5.3726\n",
      "9m 37s (- 58m 9s) (14200 14%) 5.4644\n",
      "9m 41s (- 58m 7s) (14300 14%) 5.3617\n",
      "9m 45s (- 58m 2s) (14400 14%) 5.2727\n",
      "9m 50s (- 57m 59s) (14500 14%) 5.4016\n",
      "9m 54s (- 57m 56s) (14600 14%) 5.2943\n",
      "9m 58s (- 57m 53s) (14700 14%) 5.3662\n",
      "10m 2s (- 57m 49s) (14800 14%) 5.4976\n",
      "10m 7s (- 57m 46s) (14900 14%) 5.5084\n"
     ]
    }
   ],
   "source": [
    "batches = 100000 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 100\n",
    "\n",
    "my_encoder = EncoderRNN(len(english_vocab), hidden_size)\n",
    "my_decoder = AttnDecoderRNN(hidden_size, len(indo_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()\n",
    "\n",
    "\n",
    "# Load the pre-trained model with teacher forcing.\n",
    "\"\"\"\n",
    "with open('encoder_attention_100_100000_0.5.pkl', 'rb') as fin:\n",
    "    my_encoder = pickle.load(fin)\n",
    "    \n",
    "with open('decoder_attention_100_100000_0.5.pkl', 'rb') as fin:\n",
    "    my_decoder = pickle.load(fin)\n",
    "\"\"\"\n",
    "\n",
    "# Or train a new model; un-comment the following lines\n",
    "\n",
    "train(my_encoder, my_decoder, batches, print_every=100)\n",
    "# In Python >= 3.6\n",
    "with open(f'encoder_attention_{hidden_size}_{batches}_{teacher_forcing_ratio}.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_encoder, fout)\n",
    "with open(f'decoder_attention_{hidden_size}_{batches}_{teacher_forcing_ratio}.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_decoder, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(encoder, decoder, input_variable, max_length=MAX_LENGTH):\n",
    "    # The length of the input.\n",
    "    input_length = input_variable.size()[0]\n",
    "    # For each sentence, initilize the hidden states with zeros.\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "    # Initialize the encoder outputs. \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    # Iterate through the input words.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "    # Initialize the decoder with the start symbol <s>.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]])) \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    # Use the last encoder hidden state as the first decoder's hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # Keep a list of the decoded words.\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Iterate through the decoder states.\n",
    "    for di in range(max_length):\n",
    "        # Very similar to how the training works.\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                    decoder_hidden,\n",
    "                                                                    encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == END_IDX:\n",
    "            decoded_words.append(END_IDX)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(ni)\n",
    "        # Replace the new decoder input for the next state \n",
    "        # with the top guess of this state.\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "    \n",
    "def translate(english_text):\n",
    "    output_words, _ = translator(my_encoder, my_decoder, variable_from_sent(english_text, english_vocab))\n",
    "    output_sentence = [indo_vocab[i] for i in output_words[1:output_words.index(1)]]\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('French Muslims fined for face veils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
