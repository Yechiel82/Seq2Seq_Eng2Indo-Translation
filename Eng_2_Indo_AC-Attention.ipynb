{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Bahasa Indonesian Attention based translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "1. https://github.com/ace-racer/kopitiam/blob/master/Kopitiam%20mit%20Attention.ipynb\n",
    "2. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "# Imports we need.\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Indonesian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction: 2007 year in review</td>\n",
       "      <td>Pendahuluan: Tahun peninjauan 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007 was another significant year for the Aust...</td>\n",
       "      <td>2007 kembali menjadi tahun yang signifikan bag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reconstruction after the 2004 Boxing Day tsuna...</td>\n",
       "      <td>Rekonstruksi yang dilakukan setelah terjadinya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This work was the centrepiece of the $1 billio...</td>\n",
       "      <td>Ini merupakan pekerjaan inti dari Kemitraan Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIPRD also includes large-scale social and eco...</td>\n",
       "      <td>AIPRD juga mencakup program pengembangan ekono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0                 Introduction: 2007 year in review    \n",
       "1  2007 was another significant year for the Aust...   \n",
       "2  Reconstruction after the 2004 Boxing Day tsuna...   \n",
       "3  This work was the centrepiece of the $1 billio...   \n",
       "4  AIPRD also includes large-scale social and eco...   \n",
       "\n",
       "                                          Indonesian  \n",
       "0                Pendahuluan: Tahun peninjauan 2007   \n",
       "1  2007 kembali menjadi tahun yang signifikan bag...  \n",
       "2  Rekonstruksi yang dilakukan setelah terjadinya...  \n",
       "3  Ini merupakan pekerjaan inti dari Kemitraan Au...  \n",
       "4  AIPRD juga mencakup program pengembangan ekono...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "corpus_df = pd.read_csv(\"./corpus/trimmed_combined_no_duplicate.csv\")\n",
    "corpus_df = corpus_df.drop(columns=[\"English_num_words\", \"Indo_num_words\"])\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First English sentence: ['<s>', 'introduction', ':', '2007', 'year', 'in', 'review', '</s>']\n",
      "First Indonesian sentence: ['<s>', 'pendahuluan', ':', 'tahun', 'peninjauan', '2007', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Use a unique string to indicate START and END of a sentence.\n",
    "# Assign a unique index to them.\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "\n",
    "# We use this idiom to tokenize our sentences in the dataframe column:\n",
    "# >>> DataFrame['column'].apply(str.lower).apply(word_tokenize)\n",
    "\n",
    "# Also we added the START and the END symbol to the sentences. \n",
    "english_sents = [START] + corpus_df['English'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "indo_sents = [START] + corpus_df['Indonesian'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "# We're sort of getting into the data into the shape we want. \n",
    "# But now it's still too humanly readable and redundant.\n",
    "## Cut-away: Computers like it to be simpler, more concise. -_-|||\n",
    "print('First English sentence:', english_sents[0])\n",
    "print('First Indonesian sentence:', indo_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Indonesian words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, '2007'), (3, ':'), (4, 'pendahuluan'), (5, 'peninjauan'), (6, 'tahun'), (7, '.'), (8, 'australia'), (9, 'bagi')]\n",
      "\n",
      "First 10 English words in Dictionary:\n",
      " [(0, '<s>'), (1, '</s>'), (2, '2007'), (3, ':'), (4, 'in'), (5, 'introduction'), (6, 'review'), (7, 'year'), (8, '.'), (9, 'another')]\n"
     ]
    }
   ],
   "source": [
    "english_vocab = Dictionary([['<s>'], ['</s>']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "indo_vocab = Dictionary([['<s>'], ['</s>']])\n",
    "indo_vocab.add_documents(indo_sents)\n",
    "\n",
    "# First ten words in the vocabulary.\n",
    "print('First 10 Indonesian words in Dictionary:\\n', sorted(indo_vocab.items())[:10])\n",
    "print()\n",
    "print('First 10 English words in Dictionary:\\n', sorted(english_vocab.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Lets save our dictionaries.\n",
    "with open('gen/indo_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(indo_vocab, fout)\n",
    "    \n",
    "with open('gen/english_vocab.Dictionary.pkl', 'wb') as fout:\n",
    "    pickle.dump(english_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [5406],\n",
       "        [3685],\n",
       "        [5405],\n",
       "        [  11],\n",
       "        [3436],\n",
       "        [5407],\n",
       "        [   1]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizes a sentence with a given vocab\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END])\n",
    "\n",
    "# Creates a PyTorch variable from a sentence against a given vocab\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    #print(vsent)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    #print(result)\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Test\n",
    "new_kopi = \"French Muslims fined for face veils\"\n",
    "variable_from_sent(new_kopi, english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of English vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25917"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of Indo vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25745"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indo_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pendahuluan: Tahun peninjauan 2007 \n",
      "tensor([[0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [6],\n",
      "        [5],\n",
      "        [2],\n",
      "        [1]], device='cuda:0')\n",
      "Introduction: 2007 year in review \n",
      "tensor([[0],\n",
      "        [5],\n",
      "        [3],\n",
      "        [2],\n",
      "        [7],\n",
      "        [4],\n",
      "        [6],\n",
      "        [1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prepare the whole training corpus.\n",
    "indo_tensors = corpus_df['Indonesian'].apply(lambda s: variable_from_sent(s, indo_vocab))\n",
    "print(corpus_df.iloc[0]['Indonesian'])\n",
    "print(indo_tensors[0])\n",
    "english_tensors = corpus_df['English'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "print(corpus_df.iloc[0]['English'])\n",
    "print(english_tensors[0])\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs = list(zip(english_tensors, indo_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "MAX_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of output (i.e. no. of words in output vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # Set the output layer to output a specific symbol \n",
    "        # from the output vocabulary\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # Transform the embedded output with a relu function. \n",
    "        output = F.relu(output)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Take the updated output and find the most appropriate\n",
    "        # output symbol. \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        # Batch matrix multiplication: https://pytorch.org/docs/stable/torch.html#torch.bmm\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(input_variable, target_variable, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to put the variables, decoder and optimizers to train per epoch.\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "\n",
    "    # (Re-)Initialize the optimizers, clear all gradients. \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Initialize the length of the PyTorch variables.\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # Iterating through each word in the input.\n",
    "    for ei in range(input_length):\n",
    "        # We move forward through each state.\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        # And we save the encoder outputs. \n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input.\n",
    "        for di in range(target_length):\n",
    "            # We add the encoder_outputs for attention to the decoder forward step.\n",
    "            # And expect it to return the decoder attention.\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                         decoder_hidden, \n",
    "                                                                         encoder_outputs) \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            # We add the encoder_outputs for attention to the decoder forward step.\n",
    "            # And expect it to return the decoder attention.\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                         decoder_hidden, \n",
    "                                                                         encoder_outputs) \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == END_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data / target_length\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Some Logging and Plotting Candies to Monitor Training\n",
    "#########################################################\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Top-level function to start the training,\n",
    "# iterates across epochs.\n",
    "#########################################################\n",
    "\n",
    "def train(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [random.choice(sent_pairs) for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train_one_epoch(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (- 65m 53s) (100 0%) 7.2818\n",
      "0m 8s (- 67m 56s) (200 0%) 6.3534\n",
      "0m 12s (- 68m 39s) (300 0%) 5.9664\n",
      "0m 16s (- 67m 22s) (400 0%) 6.0469\n",
      "0m 19s (- 65m 26s) (500 0%) 5.4315\n",
      "0m 23s (- 65m 14s) (600 0%) 5.6394\n",
      "0m 26s (- 63m 47s) (700 0%) 5.0517\n",
      "0m 30s (- 63m 21s) (800 0%) 5.7313\n",
      "0m 34s (- 63m 3s) (900 0%) 5.6950\n",
      "0m 38s (- 62m 57s) (1000 1%) 5.8352\n",
      "0m 42s (- 62m 59s) (1100 1%) 5.9729\n",
      "0m 45s (- 62m 45s) (1200 1%) 5.5350\n",
      "0m 49s (- 62m 58s) (1300 1%) 5.9319\n",
      "0m 53s (- 63m 18s) (1400 1%) 6.0400\n",
      "0m 57s (- 63m 12s) (1500 1%) 5.7176\n",
      "1m 1s (- 63m 6s) (1600 1%) 5.9394\n",
      "1m 5s (- 62m 53s) (1700 1%) 5.5103\n",
      "1m 9s (- 62m 58s) (1800 1%) 5.6508\n",
      "1m 13s (- 63m 6s) (1900 1%) 5.5196\n",
      "1m 17s (- 63m 18s) (2000 2%) 5.9546\n",
      "1m 21s (- 63m 20s) (2100 2%) 5.4626\n",
      "1m 25s (- 63m 23s) (2200 2%) 5.6138\n",
      "1m 29s (- 63m 19s) (2300 2%) 5.6124\n",
      "1m 33s (- 63m 21s) (2400 2%) 5.8101\n",
      "1m 37s (- 63m 12s) (2500 2%) 5.3712\n",
      "1m 41s (- 63m 7s) (2600 2%) 5.6155\n",
      "1m 44s (- 63m 1s) (2700 2%) 5.5702\n",
      "1m 48s (- 63m 0s) (2800 2%) 5.4017\n",
      "1m 53s (- 63m 14s) (2900 2%) 6.0575\n",
      "1m 57s (- 63m 20s) (3000 3%) 5.5740\n",
      "2m 0s (- 63m 0s) (3100 3%) 5.3631\n",
      "2m 4s (- 62m 58s) (3200 3%) 5.2511\n",
      "2m 8s (- 62m 54s) (3300 3%) 5.5430\n",
      "2m 12s (- 62m 48s) (3400 3%) 5.4918\n",
      "2m 16s (- 62m 46s) (3500 3%) 5.5937\n",
      "2m 20s (- 62m 41s) (3600 3%) 5.4050\n",
      "2m 24s (- 62m 35s) (3700 3%) 5.5833\n",
      "2m 28s (- 62m 30s) (3800 3%) 5.2580\n",
      "2m 32s (- 62m 27s) (3900 3%) 5.6432\n",
      "2m 36s (- 62m 27s) (4000 4%) 5.6507\n",
      "2m 40s (- 62m 23s) (4100 4%) 5.7810\n",
      "2m 43s (- 62m 15s) (4200 4%) 5.2258\n",
      "2m 47s (- 62m 14s) (4300 4%) 5.4766\n",
      "2m 52s (- 62m 18s) (4400 4%) 5.8571\n",
      "2m 55s (- 62m 13s) (4500 4%) 5.2619\n",
      "3m 0s (- 62m 17s) (4600 4%) 5.9924\n",
      "3m 4s (- 62m 13s) (4700 4%) 5.5435\n",
      "3m 8s (- 62m 12s) (4800 4%) 5.6790\n",
      "3m 12s (- 62m 10s) (4900 4%) 5.6414\n",
      "3m 16s (- 62m 15s) (5000 5%) 5.6416\n",
      "3m 20s (- 62m 2s) (5100 5%) 5.2240\n",
      "3m 24s (- 62m 1s) (5200 5%) 5.3884\n",
      "3m 28s (- 62m 0s) (5300 5%) 5.7942\n",
      "3m 32s (- 62m 4s) (5400 5%) 5.6158\n",
      "3m 36s (- 62m 0s) (5500 5%) 5.7966\n",
      "3m 40s (- 62m 3s) (5600 5%) 5.5173\n",
      "3m 45s (- 62m 2s) (5700 5%) 5.5725\n",
      "3m 49s (- 62m 8s) (5800 5%) 5.9950\n",
      "3m 54s (- 62m 12s) (5900 5%) 5.8159\n",
      "3m 57s (- 62m 7s) (6000 6%) 5.5698\n",
      "4m 2s (- 62m 6s) (6100 6%) 5.5718\n",
      "4m 6s (- 62m 5s) (6200 6%) 5.4293\n",
      "4m 10s (- 62m 5s) (6300 6%) 5.6234\n",
      "4m 14s (- 62m 2s) (6400 6%) 5.7141\n",
      "4m 19s (- 62m 10s) (6500 6%) 6.0375\n",
      "4m 23s (- 62m 7s) (6600 6%) 5.4005\n",
      "4m 27s (- 62m 7s) (6700 6%) 5.5712\n",
      "4m 31s (- 62m 5s) (6800 6%) 5.3931\n",
      "4m 35s (- 62m 0s) (6900 6%) 5.7371\n",
      "4m 39s (- 61m 57s) (7000 7%) 5.5523\n",
      "4m 43s (- 61m 55s) (7100 7%) 5.5164\n",
      "4m 48s (- 61m 53s) (7200 7%) 5.7085\n",
      "4m 52s (- 61m 50s) (7300 7%) 5.4850\n",
      "4m 56s (- 61m 47s) (7400 7%) 5.5436\n",
      "5m 0s (- 61m 46s) (7500 7%) 5.5997\n",
      "5m 4s (- 61m 41s) (7600 7%) 5.6586\n",
      "5m 8s (- 61m 42s) (7700 7%) 5.9315\n",
      "5m 13s (- 61m 42s) (7800 7%) 5.5689\n",
      "5m 17s (- 61m 41s) (7900 7%) 5.8425\n",
      "5m 22s (- 61m 46s) (8000 8%) 5.7796\n",
      "5m 26s (- 61m 42s) (8100 8%) 5.7030\n",
      "5m 30s (- 61m 39s) (8200 8%) 5.6801\n",
      "5m 34s (- 61m 39s) (8300 8%) 5.6449\n",
      "5m 39s (- 61m 37s) (8400 8%) 5.5899\n",
      "5m 43s (- 61m 38s) (8500 8%) 5.6240\n",
      "5m 47s (- 61m 35s) (8600 8%) 5.5618\n",
      "5m 52s (- 61m 34s) (8700 8%) 5.7365\n",
      "5m 56s (- 61m 30s) (8800 8%) 5.5295\n",
      "6m 0s (- 61m 27s) (8900 8%) 5.5202\n",
      "6m 4s (- 61m 26s) (9000 9%) 5.3257\n",
      "6m 8s (- 61m 25s) (9100 9%) 5.4480\n",
      "6m 12s (- 61m 19s) (9200 9%) 5.4780\n",
      "6m 17s (- 61m 18s) (9300 9%) 5.4949\n",
      "6m 21s (- 61m 19s) (9400 9%) 5.7709\n",
      "6m 25s (- 61m 16s) (9500 9%) 5.4922\n",
      "6m 30s (- 61m 15s) (9600 9%) 5.6126\n",
      "6m 34s (- 61m 9s) (9700 9%) 5.7444\n",
      "6m 38s (- 61m 11s) (9800 9%) 5.6604\n",
      "6m 43s (- 61m 8s) (9900 9%) 5.5187\n",
      "6m 46s (- 61m 2s) (10000 10%) 5.5375\n",
      "6m 51s (- 60m 59s) (10100 10%) 5.5165\n",
      "6m 55s (- 60m 59s) (10200 10%) 5.6065\n",
      "7m 0s (- 60m 59s) (10300 10%) 5.5386\n",
      "7m 4s (- 60m 58s) (10400 10%) 5.6456\n",
      "7m 8s (- 60m 53s) (10500 10%) 5.5633\n",
      "7m 12s (- 60m 50s) (10600 10%) 5.5603\n",
      "7m 17s (- 60m 47s) (10700 10%) 5.5282\n",
      "7m 21s (- 60m 46s) (10800 10%) 5.6282\n",
      "7m 25s (- 60m 41s) (10900 10%) 5.6547\n",
      "7m 29s (- 60m 37s) (11000 11%) 5.6020\n",
      "7m 33s (- 60m 32s) (11100 11%) 5.4542\n",
      "7m 38s (- 60m 31s) (11200 11%) 5.6408\n",
      "7m 42s (- 60m 28s) (11300 11%) 5.6120\n",
      "7m 46s (- 60m 27s) (11400 11%) 5.4679\n",
      "7m 50s (- 60m 22s) (11500 11%) 5.3073\n",
      "7m 54s (- 60m 18s) (11600 11%) 5.5819\n",
      "7m 59s (- 60m 15s) (11700 11%) 5.3637\n",
      "8m 3s (- 60m 13s) (11800 11%) 5.6114\n",
      "8m 7s (- 60m 11s) (11900 11%) 5.8044\n",
      "8m 11s (- 60m 7s) (12000 12%) 5.4133\n",
      "8m 16s (- 60m 7s) (12100 12%) 5.6123\n",
      "8m 20s (- 60m 3s) (12200 12%) 5.5554\n",
      "8m 24s (- 60m 0s) (12300 12%) 5.5639\n",
      "8m 29s (- 59m 56s) (12400 12%) 5.4549\n",
      "8m 33s (- 59m 51s) (12500 12%) 5.7192\n",
      "8m 37s (- 59m 47s) (12600 12%) 5.5057\n",
      "8m 41s (- 59m 45s) (12700 12%) 5.3476\n",
      "8m 45s (- 59m 43s) (12800 12%) 5.4568\n",
      "8m 50s (- 59m 41s) (12900 12%) 5.6250\n",
      "8m 54s (- 59m 36s) (13000 13%) 5.6418\n",
      "8m 58s (- 59m 33s) (13100 13%) 5.6064\n",
      "9m 2s (- 59m 28s) (13200 13%) 5.3270\n",
      "9m 6s (- 59m 24s) (13300 13%) 5.5579\n",
      "9m 10s (- 59m 20s) (13400 13%) 5.3146\n",
      "9m 15s (- 59m 17s) (13500 13%) 5.7481\n",
      "9m 19s (- 59m 11s) (13600 13%) 5.4267\n",
      "9m 23s (- 59m 7s) (13700 13%) 5.5969\n",
      "9m 27s (- 59m 5s) (13800 13%) 5.7174\n",
      "9m 32s (- 59m 5s) (13900 13%) 5.6028\n",
      "9m 36s (- 59m 1s) (14000 14%) 5.3832\n",
      "9m 40s (- 58m 57s) (14100 14%) 5.2194\n",
      "9m 45s (- 58m 55s) (14200 14%) 5.4598\n",
      "9m 49s (- 58m 53s) (14300 14%) 5.5750\n",
      "9m 53s (- 58m 49s) (14400 14%) 5.5254\n",
      "9m 58s (- 58m 47s) (14500 14%) 5.4854\n",
      "10m 3s (- 58m 47s) (14600 14%) 5.5990\n",
      "10m 7s (- 58m 43s) (14700 14%) 5.5308\n",
      "10m 11s (- 58m 38s) (14800 14%) 5.2366\n",
      "10m 15s (- 58m 37s) (14900 14%) 5.6121\n",
      "10m 20s (- 58m 34s) (15000 15%) 5.3314\n",
      "10m 24s (- 58m 29s) (15100 15%) 5.2237\n",
      "10m 29s (- 58m 29s) (15200 15%) 5.4932\n",
      "10m 33s (- 58m 29s) (15300 15%) 5.3955\n",
      "10m 38s (- 58m 25s) (15400 15%) 5.4043\n",
      "10m 42s (- 58m 21s) (15500 15%) 5.3658\n",
      "10m 46s (- 58m 18s) (15600 15%) 5.3482\n",
      "10m 51s (- 58m 15s) (15700 15%) 5.5726\n",
      "10m 55s (- 58m 12s) (15800 15%) 5.4412\n",
      "10m 59s (- 58m 7s) (15900 15%) 5.5933\n",
      "11m 3s (- 58m 5s) (16000 16%) 5.4049\n",
      "11m 8s (- 58m 1s) (16100 16%) 5.5131\n",
      "11m 12s (- 57m 56s) (16200 16%) 5.3165\n",
      "11m 16s (- 57m 52s) (16300 16%) 5.4273\n",
      "11m 20s (- 57m 48s) (16400 16%) 5.2721\n",
      "11m 24s (- 57m 45s) (16500 16%) 5.5027\n",
      "11m 28s (- 57m 40s) (16600 16%) 5.4447\n",
      "11m 32s (- 57m 34s) (16700 16%) 5.4786\n",
      "11m 36s (- 57m 30s) (16800 16%) 5.5412\n",
      "11m 41s (- 57m 27s) (16900 16%) 5.4794\n",
      "11m 45s (- 57m 24s) (17000 17%) 5.5352\n",
      "11m 49s (- 57m 19s) (17100 17%) 5.3734\n",
      "11m 53s (- 57m 16s) (17200 17%) 5.2439\n",
      "11m 57s (- 57m 11s) (17300 17%) 5.5970\n",
      "12m 1s (- 57m 6s) (17400 17%) 5.4104\n",
      "12m 6s (- 57m 2s) (17500 17%) 5.3302\n",
      "12m 10s (- 56m 59s) (17600 17%) 5.2442\n",
      "12m 14s (- 56m 54s) (17700 17%) 5.4534\n",
      "12m 18s (- 56m 51s) (17800 17%) 5.4659\n",
      "12m 23s (- 56m 49s) (17900 17%) 5.3196\n",
      "12m 27s (- 56m 46s) (18000 18%) 5.4661\n",
      "12m 32s (- 56m 43s) (18100 18%) 5.2842\n",
      "12m 36s (- 56m 39s) (18200 18%) 5.2719\n",
      "12m 41s (- 56m 38s) (18300 18%) 5.6771\n",
      "12m 45s (- 56m 34s) (18400 18%) 5.3147\n",
      "12m 49s (- 56m 31s) (18500 18%) 5.2624\n",
      "12m 54s (- 56m 28s) (18600 18%) 5.3545\n",
      "12m 58s (- 56m 26s) (18700 18%) 5.4275\n",
      "13m 3s (- 56m 24s) (18800 18%) 5.5750\n",
      "13m 7s (- 56m 21s) (18900 18%) 5.4630\n",
      "13m 12s (- 56m 18s) (19000 19%) 5.5085\n",
      "13m 16s (- 56m 14s) (19100 19%) 5.5347\n",
      "13m 20s (- 56m 10s) (19200 19%) 5.3135\n",
      "13m 25s (- 56m 6s) (19300 19%) 5.1582\n",
      "13m 29s (- 56m 2s) (19400 19%) 5.4349\n",
      "13m 34s (- 56m 0s) (19500 19%) 5.4271\n",
      "13m 38s (- 55m 55s) (19600 19%) 5.3185\n",
      "13m 42s (- 55m 52s) (19700 19%) 5.3322\n",
      "13m 47s (- 55m 51s) (19800 19%) 5.6090\n",
      "13m 51s (- 55m 46s) (19900 19%) 5.4237\n",
      "13m 55s (- 55m 43s) (20000 20%) 5.2709\n",
      "13m 59s (- 55m 38s) (20100 20%) 5.3160\n",
      "14m 4s (- 55m 34s) (20200 20%) 5.5871\n",
      "14m 8s (- 55m 31s) (20300 20%) 5.4894\n",
      "14m 13s (- 55m 28s) (20400 20%) 5.3653\n",
      "14m 17s (- 55m 24s) (20500 20%) 5.0444\n",
      "14m 21s (- 55m 20s) (20600 20%) 5.5843\n",
      "14m 25s (- 55m 17s) (20700 20%) 5.3737\n",
      "14m 30s (- 55m 13s) (20800 20%) 5.2542\n",
      "14m 34s (- 55m 8s) (20900 20%) 5.2170\n",
      "14m 38s (- 55m 5s) (21000 21%) 5.5335\n",
      "14m 43s (- 55m 2s) (21100 21%) 5.5622\n",
      "14m 47s (- 54m 59s) (21200 21%) 5.1860\n",
      "14m 52s (- 54m 56s) (21300 21%) 5.5447\n",
      "14m 56s (- 54m 52s) (21400 21%) 5.3698\n",
      "15m 0s (- 54m 49s) (21500 21%) 5.5234\n",
      "15m 5s (- 54m 45s) (21600 21%) 5.4382\n",
      "15m 9s (- 54m 41s) (21700 21%) 5.2793\n",
      "15m 13s (- 54m 37s) (21800 21%) 5.0831\n",
      "15m 17s (- 54m 33s) (21900 21%) 5.2048\n",
      "15m 21s (- 54m 27s) (22000 22%) 5.4547\n",
      "15m 26s (- 54m 24s) (22100 22%) 5.3247\n",
      "15m 30s (- 54m 20s) (22200 22%) 5.5324\n",
      "15m 34s (- 54m 16s) (22300 22%) 5.3588\n",
      "15m 38s (- 54m 11s) (22400 22%) 5.2852\n",
      "15m 42s (- 54m 7s) (22500 22%) 5.2798\n",
      "15m 46s (- 54m 3s) (22600 22%) 5.2147\n",
      "15m 50s (- 53m 58s) (22700 22%) 5.2817\n",
      "15m 55s (- 53m 55s) (22800 22%) 5.3685\n",
      "15m 59s (- 53m 51s) (22900 22%) 5.2697\n",
      "16m 4s (- 53m 47s) (23000 23%) 5.3769\n",
      "16m 8s (- 53m 44s) (23100 23%) 5.5246\n",
      "16m 13s (- 53m 41s) (23200 23%) 5.4829\n",
      "16m 17s (- 53m 37s) (23300 23%) 5.2912\n",
      "16m 21s (- 53m 33s) (23400 23%) 5.3431\n",
      "16m 26s (- 53m 30s) (23500 23%) 5.1264\n",
      "16m 30s (- 53m 26s) (23600 23%) 5.4262\n",
      "16m 34s (- 53m 21s) (23700 23%) 5.3033\n",
      "16m 38s (- 53m 16s) (23800 23%) 5.4227\n",
      "16m 42s (- 53m 11s) (23900 23%) 5.2303\n",
      "16m 46s (- 53m 7s) (24000 24%) 5.3441\n",
      "16m 50s (- 53m 3s) (24100 24%) 5.1988\n",
      "16m 54s (- 52m 58s) (24200 24%) 5.4473\n",
      "16m 59s (- 52m 55s) (24300 24%) 5.5190\n",
      "17m 3s (- 52m 50s) (24400 24%) 5.1516\n",
      "17m 7s (- 52m 46s) (24500 24%) 5.2284\n",
      "17m 11s (- 52m 42s) (24600 24%) 5.2991\n",
      "17m 16s (- 52m 38s) (24700 24%) 5.3950\n",
      "17m 20s (- 52m 34s) (24800 24%) 5.2216\n",
      "17m 24s (- 52m 31s) (24900 24%) 5.4616\n",
      "17m 29s (- 52m 27s) (25000 25%) 5.3141\n",
      "17m 32s (- 52m 21s) (25100 25%) 5.1502\n",
      "17m 36s (- 52m 16s) (25200 25%) 5.1787\n",
      "17m 40s (- 52m 12s) (25300 25%) 5.2572\n",
      "17m 44s (- 52m 7s) (25400 25%) 5.3740\n",
      "17m 49s (- 52m 3s) (25500 25%) 5.1847\n",
      "17m 53s (- 52m 0s) (25600 25%) 5.3198\n",
      "17m 58s (- 51m 56s) (25700 25%) 5.0926\n",
      "18m 2s (- 51m 53s) (25800 25%) 5.4395\n",
      "18m 6s (- 51m 49s) (25900 25%) 5.3360\n",
      "18m 10s (- 51m 44s) (26000 26%) 5.0213\n",
      "18m 14s (- 51m 39s) (26100 26%) 5.6128\n",
      "18m 19s (- 51m 36s) (26200 26%) 5.2562\n",
      "18m 23s (- 51m 32s) (26300 26%) 5.3528\n",
      "18m 27s (- 51m 28s) (26400 26%) 5.2126\n",
      "18m 32s (- 51m 24s) (26500 26%) 5.3905\n",
      "18m 36s (- 51m 21s) (26600 26%) 5.3259\n",
      "18m 41s (- 51m 18s) (26700 26%) 5.5717\n",
      "18m 45s (- 51m 14s) (26800 26%) 5.4471\n",
      "18m 49s (- 51m 9s) (26900 26%) 5.2461\n",
      "18m 54s (- 51m 6s) (27000 27%) 5.4869\n",
      "18m 58s (- 51m 3s) (27100 27%) 5.2753\n",
      "19m 2s (- 50m 58s) (27200 27%) 5.3363\n",
      "19m 7s (- 50m 54s) (27300 27%) 5.3667\n",
      "19m 11s (- 50m 51s) (27400 27%) 5.1988\n",
      "19m 15s (- 50m 47s) (27500 27%) 5.4657\n",
      "19m 20s (- 50m 43s) (27600 27%) 5.3044\n",
      "19m 24s (- 50m 40s) (27700 27%) 5.2655\n",
      "19m 29s (- 50m 36s) (27800 27%) 5.1432\n",
      "19m 33s (- 50m 32s) (27900 27%) 5.3088\n",
      "19m 37s (- 50m 28s) (28000 28%) 5.1951\n",
      "19m 42s (- 50m 24s) (28100 28%) 5.2281\n",
      "19m 46s (- 50m 20s) (28200 28%) 5.0159\n",
      "19m 50s (- 50m 17s) (28300 28%) 5.4222\n",
      "19m 55s (- 50m 12s) (28400 28%) 5.1724\n",
      "19m 59s (- 50m 8s) (28500 28%) 5.1251\n",
      "20m 3s (- 50m 4s) (28600 28%) 5.3073\n",
      "20m 7s (- 49m 59s) (28700 28%) 5.2584\n",
      "20m 12s (- 49m 56s) (28800 28%) 5.2286\n",
      "20m 16s (- 49m 53s) (28900 28%) 5.1845\n",
      "20m 21s (- 49m 49s) (29000 28%) 5.1610\n",
      "20m 25s (- 49m 45s) (29100 29%) 5.3785\n",
      "20m 29s (- 49m 41s) (29200 29%) 5.2044\n",
      "20m 33s (- 49m 36s) (29300 29%) 5.3388\n",
      "20m 37s (- 49m 32s) (29400 29%) 5.1421\n",
      "20m 42s (- 49m 28s) (29500 29%) 5.0176\n",
      "20m 46s (- 49m 23s) (29600 29%) 5.0862\n",
      "20m 50s (- 49m 20s) (29700 29%) 5.1914\n",
      "20m 54s (- 49m 15s) (29800 29%) 5.2519\n",
      "20m 58s (- 49m 11s) (29900 29%) 5.0370\n",
      "21m 3s (- 49m 7s) (30000 30%) 5.1950\n",
      "21m 7s (- 49m 3s) (30100 30%) 5.1383\n",
      "21m 11s (- 48m 57s) (30200 30%) 5.2736\n",
      "21m 15s (- 48m 54s) (30300 30%) 5.4043\n",
      "21m 19s (- 48m 49s) (30400 30%) 5.0902\n",
      "21m 24s (- 48m 47s) (30500 30%) 5.2590\n",
      "21m 29s (- 48m 43s) (30600 30%) 5.1910\n",
      "21m 33s (- 48m 39s) (30700 30%) 5.1154\n",
      "21m 37s (- 48m 35s) (30800 30%) 5.2108\n",
      "21m 42s (- 48m 32s) (30900 30%) 5.2967\n",
      "21m 46s (- 48m 28s) (31000 31%) 5.1741\n",
      "21m 51s (- 48m 25s) (31100 31%) 5.2880\n",
      "21m 55s (- 48m 21s) (31200 31%) 5.3100\n",
      "22m 0s (- 48m 18s) (31300 31%) 5.1075\n",
      "22m 4s (- 48m 14s) (31400 31%) 5.2544\n",
      "22m 9s (- 48m 10s) (31500 31%) 5.2609\n",
      "22m 13s (- 48m 6s) (31600 31%) 5.1832\n",
      "22m 17s (- 48m 2s) (31700 31%) 5.0959\n",
      "22m 21s (- 47m 57s) (31800 31%) 5.4080\n",
      "22m 26s (- 47m 53s) (31900 31%) 5.4075\n",
      "22m 30s (- 47m 49s) (32000 32%) 5.2938\n",
      "22m 34s (- 47m 45s) (32100 32%) 5.3177\n",
      "22m 38s (- 47m 41s) (32200 32%) 5.0635\n",
      "22m 43s (- 47m 37s) (32300 32%) 5.2049\n",
      "22m 47s (- 47m 32s) (32400 32%) 5.0285\n",
      "22m 51s (- 47m 27s) (32500 32%) 5.1806\n",
      "22m 55s (- 47m 24s) (32600 32%) 5.2081\n",
      "22m 59s (- 47m 19s) (32700 32%) 4.8407\n",
      "23m 4s (- 47m 15s) (32800 32%) 5.0146\n",
      "23m 8s (- 47m 10s) (32900 32%) 5.0642\n",
      "23m 12s (- 47m 6s) (33000 33%) 5.1046\n",
      "23m 16s (- 47m 2s) (33100 33%) 5.1726\n",
      "23m 20s (- 46m 57s) (33200 33%) 5.2593\n",
      "23m 24s (- 46m 53s) (33300 33%) 5.0893\n",
      "23m 28s (- 46m 49s) (33400 33%) 5.2066\n",
      "23m 32s (- 46m 44s) (33500 33%) 5.2341\n",
      "23m 36s (- 46m 40s) (33600 33%) 5.2353\n",
      "23m 40s (- 46m 35s) (33700 33%) 5.0107\n",
      "23m 45s (- 46m 31s) (33800 33%) 5.2876\n",
      "23m 49s (- 46m 27s) (33900 33%) 5.0699\n",
      "23m 53s (- 46m 23s) (34000 34%) 5.2920\n",
      "23m 58s (- 46m 19s) (34100 34%) 5.1033\n",
      "24m 2s (- 46m 15s) (34200 34%) 5.2079\n",
      "24m 6s (- 46m 10s) (34300 34%) 5.2036\n",
      "24m 10s (- 46m 6s) (34400 34%) 5.2287\n",
      "24m 15s (- 46m 3s) (34500 34%) 5.2597\n",
      "24m 19s (- 45m 58s) (34600 34%) 5.0631\n",
      "24m 23s (- 45m 54s) (34700 34%) 5.0642\n",
      "24m 27s (- 45m 49s) (34800 34%) 5.0387\n",
      "24m 32s (- 45m 46s) (34900 34%) 5.2743\n",
      "24m 36s (- 45m 42s) (35000 35%) 5.3924\n",
      "24m 41s (- 45m 38s) (35100 35%) 5.2454\n",
      "24m 45s (- 45m 34s) (35200 35%) 5.0190\n",
      "24m 49s (- 45m 30s) (35300 35%) 5.2380\n",
      "24m 54s (- 45m 26s) (35400 35%) 5.1369\n",
      "24m 58s (- 45m 22s) (35500 35%) 5.3698\n",
      "25m 2s (- 45m 18s) (35600 35%) 5.0778\n",
      "25m 7s (- 45m 14s) (35700 35%) 5.1297\n",
      "25m 10s (- 45m 9s) (35800 35%) 4.9445\n",
      "25m 14s (- 45m 4s) (35900 35%) 5.1128\n",
      "25m 18s (- 44m 59s) (36000 36%) 5.1596\n",
      "25m 22s (- 44m 55s) (36100 36%) 5.0132\n",
      "25m 27s (- 44m 52s) (36200 36%) 5.4086\n",
      "25m 31s (- 44m 47s) (36300 36%) 5.1566\n",
      "25m 36s (- 44m 43s) (36400 36%) 5.0372\n",
      "25m 40s (- 44m 40s) (36500 36%) 5.1649\n",
      "25m 44s (- 44m 36s) (36600 36%) 5.1242\n",
      "25m 49s (- 44m 31s) (36700 36%) 5.0880\n",
      "25m 52s (- 44m 26s) (36800 36%) 4.9747\n",
      "25m 57s (- 44m 23s) (36900 36%) 5.2755\n",
      "26m 1s (- 44m 19s) (37000 37%) 5.1221\n",
      "26m 6s (- 44m 15s) (37100 37%) 4.9824\n",
      "26m 10s (- 44m 10s) (37200 37%) 5.1097\n",
      "26m 13s (- 44m 5s) (37300 37%) 5.1770\n",
      "26m 18s (- 44m 2s) (37400 37%) 5.2269\n",
      "26m 22s (- 43m 58s) (37500 37%) 5.2933\n",
      "26m 27s (- 43m 54s) (37600 37%) 5.2765\n",
      "26m 31s (- 43m 50s) (37700 37%) 5.1881\n",
      "26m 35s (- 43m 46s) (37800 37%) 5.1466\n",
      "26m 40s (- 43m 41s) (37900 37%) 5.1561\n",
      "26m 44s (- 43m 37s) (38000 38%) 5.0482\n",
      "26m 48s (- 43m 33s) (38100 38%) 5.2628\n",
      "26m 53s (- 43m 29s) (38200 38%) 5.0503\n",
      "26m 57s (- 43m 25s) (38300 38%) 5.0392\n",
      "27m 1s (- 43m 21s) (38400 38%) 5.1581\n",
      "27m 6s (- 43m 17s) (38500 38%) 5.1254\n",
      "27m 10s (- 43m 13s) (38600 38%) 5.1920\n",
      "27m 14s (- 43m 9s) (38700 38%) 4.8938\n",
      "27m 19s (- 43m 5s) (38800 38%) 5.2753\n",
      "27m 23s (- 43m 2s) (38900 38%) 4.9628\n",
      "27m 28s (- 42m 58s) (39000 39%) 5.1011\n",
      "27m 32s (- 42m 53s) (39100 39%) 5.0462\n",
      "27m 36s (- 42m 48s) (39200 39%) 5.1754\n",
      "27m 41s (- 42m 45s) (39300 39%) 5.2500\n",
      "27m 45s (- 42m 41s) (39400 39%) 4.9968\n",
      "27m 49s (- 42m 36s) (39500 39%) 4.9320\n",
      "27m 53s (- 42m 32s) (39600 39%) 5.0268\n",
      "27m 57s (- 42m 28s) (39700 39%) 5.0782\n",
      "28m 2s (- 42m 24s) (39800 39%) 4.9076\n",
      "28m 6s (- 42m 20s) (39900 39%) 5.1724\n",
      "28m 10s (- 42m 16s) (40000 40%) 5.1427\n",
      "28m 15s (- 42m 12s) (40100 40%) 5.2119\n",
      "28m 19s (- 42m 8s) (40200 40%) 5.1420\n",
      "28m 23s (- 42m 3s) (40300 40%) 5.1070\n",
      "28m 28s (- 42m 0s) (40400 40%) 4.9805\n",
      "28m 32s (- 41m 56s) (40500 40%) 5.3419\n",
      "28m 36s (- 41m 51s) (40600 40%) 5.1872\n",
      "28m 40s (- 41m 47s) (40700 40%) 5.1335\n",
      "28m 44s (- 41m 42s) (40800 40%) 5.0633\n",
      "28m 49s (- 41m 38s) (40900 40%) 5.0366\n",
      "28m 53s (- 41m 34s) (41000 41%) 5.0062\n",
      "28m 57s (- 41m 30s) (41100 41%) 5.3118\n",
      "29m 1s (- 41m 26s) (41200 41%) 5.1203\n",
      "29m 6s (- 41m 21s) (41300 41%) 4.9821\n",
      "29m 10s (- 41m 17s) (41400 41%) 5.1681\n",
      "29m 14s (- 41m 13s) (41500 41%) 5.3466\n",
      "29m 19s (- 41m 9s) (41600 41%) 5.2114\n",
      "29m 23s (- 41m 5s) (41700 41%) 5.1136\n",
      "29m 27s (- 41m 1s) (41800 41%) 4.9216\n",
      "29m 31s (- 40m 56s) (41900 41%) 4.8149\n",
      "29m 35s (- 40m 51s) (42000 42%) 4.9904\n",
      "29m 39s (- 40m 47s) (42100 42%) 5.3442\n",
      "29m 44s (- 40m 43s) (42200 42%) 5.1229\n",
      "29m 48s (- 40m 39s) (42300 42%) 4.9513\n",
      "29m 52s (- 40m 34s) (42400 42%) 5.0893\n",
      "29m 56s (- 40m 30s) (42500 42%) 5.1555\n",
      "30m 0s (- 40m 26s) (42600 42%) 4.7955\n",
      "30m 6s (- 40m 23s) (42700 42%) 5.1700\n",
      "30m 10s (- 40m 19s) (42800 42%) 5.2068\n",
      "30m 14s (- 40m 15s) (42900 42%) 5.0029\n",
      "30m 18s (- 40m 10s) (43000 43%) 5.2571\n",
      "30m 22s (- 40m 6s) (43100 43%) 5.3049\n",
      "30m 27s (- 40m 2s) (43200 43%) 5.1655\n",
      "30m 31s (- 39m 58s) (43300 43%) 5.1584\n",
      "30m 35s (- 39m 54s) (43400 43%) 5.0219\n",
      "30m 40s (- 39m 50s) (43500 43%) 5.2299\n",
      "30m 44s (- 39m 46s) (43600 43%) 4.9951\n",
      "30m 49s (- 39m 42s) (43700 43%) 5.0880\n",
      "30m 53s (- 39m 38s) (43800 43%) 5.3491\n",
      "30m 57s (- 39m 33s) (43900 43%) 4.8777\n",
      "31m 1s (- 39m 29s) (44000 44%) 5.1754\n",
      "31m 5s (- 39m 25s) (44100 44%) 5.2240\n",
      "31m 9s (- 39m 20s) (44200 44%) 4.9712\n",
      "31m 14s (- 39m 16s) (44300 44%) 4.9277\n",
      "31m 18s (- 39m 12s) (44400 44%) 5.0351\n",
      "31m 22s (- 39m 7s) (44500 44%) 5.1146\n",
      "31m 27s (- 39m 4s) (44600 44%) 5.1542\n",
      "31m 31s (- 39m 0s) (44700 44%) 5.1199\n",
      "31m 36s (- 38m 56s) (44800 44%) 5.1162\n",
      "31m 40s (- 38m 51s) (44900 44%) 4.8993\n",
      "31m 44s (- 38m 47s) (45000 45%) 5.1009\n",
      "31m 49s (- 38m 44s) (45100 45%) 5.0440\n",
      "31m 53s (- 38m 40s) (45200 45%) 5.1815\n",
      "31m 57s (- 38m 35s) (45300 45%) 5.0247\n",
      "32m 2s (- 38m 31s) (45400 45%) 5.1240\n",
      "32m 6s (- 38m 27s) (45500 45%) 5.2873\n",
      "32m 10s (- 38m 23s) (45600 45%) 5.0104\n",
      "32m 14s (- 38m 18s) (45700 45%) 5.0606\n",
      "32m 18s (- 38m 14s) (45800 45%) 5.2112\n",
      "32m 23s (- 38m 10s) (45900 45%) 5.1759\n",
      "32m 27s (- 38m 5s) (46000 46%) 5.2944\n",
      "32m 31s (- 38m 1s) (46100 46%) 5.2043\n",
      "32m 35s (- 37m 57s) (46200 46%) 5.2016\n",
      "32m 40s (- 37m 53s) (46300 46%) 5.1983\n",
      "32m 44s (- 37m 48s) (46400 46%) 4.9670\n",
      "32m 48s (- 37m 44s) (46500 46%) 5.2173\n",
      "32m 52s (- 37m 40s) (46600 46%) 5.0158\n",
      "32m 56s (- 37m 35s) (46700 46%) 5.1602\n",
      "33m 1s (- 37m 31s) (46800 46%) 5.0346\n",
      "33m 5s (- 37m 28s) (46900 46%) 5.1964\n",
      "33m 9s (- 37m 23s) (47000 47%) 5.1212\n",
      "33m 14s (- 37m 19s) (47100 47%) 4.9885\n",
      "33m 18s (- 37m 15s) (47200 47%) 5.1068\n",
      "33m 23s (- 37m 11s) (47300 47%) 5.0180\n",
      "33m 27s (- 37m 8s) (47400 47%) 5.1464\n",
      "33m 31s (- 37m 3s) (47500 47%) 4.9364\n",
      "33m 36s (- 36m 59s) (47600 47%) 5.1132\n",
      "33m 40s (- 36m 55s) (47700 47%) 5.2391\n",
      "33m 44s (- 36m 51s) (47800 47%) 5.1213\n",
      "33m 49s (- 36m 47s) (47900 47%) 4.9087\n",
      "33m 53s (- 36m 42s) (48000 48%) 5.1794\n",
      "33m 57s (- 36m 38s) (48100 48%) 5.1377\n",
      "34m 1s (- 36m 34s) (48200 48%) 5.2121\n",
      "34m 6s (- 36m 30s) (48300 48%) 5.0751\n",
      "34m 10s (- 36m 25s) (48400 48%) 5.2842\n",
      "34m 14s (- 36m 21s) (48500 48%) 4.8320\n",
      "34m 18s (- 36m 16s) (48600 48%) 5.0451\n",
      "34m 22s (- 36m 12s) (48700 48%) 5.0768\n",
      "34m 26s (- 36m 7s) (48800 48%) 4.9673\n",
      "34m 30s (- 36m 3s) (48900 48%) 4.9395\n",
      "34m 34s (- 35m 59s) (49000 49%) 4.8978\n",
      "34m 39s (- 35m 55s) (49100 49%) 5.1308\n",
      "34m 43s (- 35m 51s) (49200 49%) 5.1794\n",
      "34m 47s (- 35m 46s) (49300 49%) 5.0203\n",
      "34m 51s (- 35m 42s) (49400 49%) 5.0380\n",
      "34m 56s (- 35m 38s) (49500 49%) 5.1287\n",
      "35m 0s (- 35m 34s) (49600 49%) 5.1352\n",
      "35m 5s (- 35m 30s) (49700 49%) 5.0835\n",
      "35m 9s (- 35m 26s) (49800 49%) 5.1817\n",
      "35m 14s (- 35m 22s) (49900 49%) 4.9097\n",
      "35m 18s (- 35m 18s) (50000 50%) 5.0907\n",
      "35m 22s (- 35m 14s) (50100 50%) 5.0607\n",
      "35m 26s (- 35m 9s) (50200 50%) 4.9895\n",
      "35m 31s (- 35m 5s) (50300 50%) 5.1909\n",
      "35m 35s (- 35m 1s) (50400 50%) 4.8842\n",
      "35m 39s (- 34m 57s) (50500 50%) 5.0646\n",
      "35m 44s (- 34m 53s) (50600 50%) 5.1551\n",
      "35m 48s (- 34m 48s) (50700 50%) 5.0439\n",
      "35m 52s (- 34m 44s) (50800 50%) 4.9851\n",
      "35m 56s (- 34m 40s) (50900 50%) 5.0710\n",
      "36m 1s (- 34m 36s) (51000 51%) 4.9461\n",
      "36m 5s (- 34m 32s) (51100 51%) 5.2365\n",
      "36m 9s (- 34m 27s) (51200 51%) 5.0309\n",
      "36m 13s (- 34m 23s) (51300 51%) 5.1671\n",
      "36m 17s (- 34m 19s) (51400 51%) 5.0597\n",
      "36m 22s (- 34m 15s) (51500 51%) 5.0497\n",
      "36m 26s (- 34m 11s) (51600 51%) 4.9550\n",
      "36m 30s (- 34m 6s) (51700 51%) 5.1395\n",
      "36m 35s (- 34m 2s) (51800 51%) 5.0603\n",
      "36m 39s (- 33m 58s) (51900 51%) 5.0993\n",
      "36m 43s (- 33m 54s) (52000 52%) 4.9304\n",
      "36m 48s (- 33m 50s) (52100 52%) 5.2116\n",
      "36m 52s (- 33m 45s) (52200 52%) 5.1811\n",
      "36m 56s (- 33m 41s) (52300 52%) 4.9993\n",
      "37m 0s (- 33m 36s) (52400 52%) 4.8532\n",
      "37m 4s (- 33m 32s) (52500 52%) 5.1712\n",
      "37m 8s (- 33m 28s) (52600 52%) 4.9309\n",
      "37m 13s (- 33m 24s) (52700 52%) 5.1027\n",
      "37m 17s (- 33m 20s) (52800 52%) 5.0944\n",
      "37m 22s (- 33m 16s) (52900 52%) 4.9502\n",
      "37m 26s (- 33m 12s) (53000 53%) 5.1330\n",
      "37m 31s (- 33m 8s) (53100 53%) 4.8312\n",
      "37m 35s (- 33m 4s) (53200 53%) 4.9831\n",
      "37m 39s (- 32m 59s) (53300 53%) 4.9367\n",
      "37m 43s (- 32m 55s) (53400 53%) 4.9514\n",
      "37m 48s (- 32m 51s) (53500 53%) 5.0720\n",
      "37m 52s (- 32m 47s) (53600 53%) 4.9735\n",
      "37m 56s (- 32m 43s) (53700 53%) 5.1123\n",
      "38m 1s (- 32m 38s) (53800 53%) 5.0711\n",
      "38m 5s (- 32m 34s) (53900 53%) 4.8793\n",
      "38m 9s (- 32m 30s) (54000 54%) 5.1163\n",
      "38m 13s (- 32m 26s) (54100 54%) 4.8602\n",
      "38m 18s (- 32m 22s) (54200 54%) 4.9277\n",
      "38m 22s (- 32m 17s) (54300 54%) 4.8425\n",
      "38m 26s (- 32m 13s) (54400 54%) 5.1763\n",
      "38m 31s (- 32m 9s) (54500 54%) 5.0207\n",
      "38m 35s (- 32m 5s) (54600 54%) 4.9449\n",
      "38m 39s (- 32m 1s) (54700 54%) 5.0852\n",
      "38m 43s (- 31m 56s) (54800 54%) 4.9790\n",
      "38m 48s (- 31m 52s) (54900 54%) 5.2190\n",
      "38m 52s (- 31m 48s) (55000 55%) 5.0188\n",
      "38m 57s (- 31m 44s) (55100 55%) 5.0247\n",
      "39m 1s (- 31m 40s) (55200 55%) 5.0430\n",
      "39m 5s (- 31m 35s) (55300 55%) 4.9138\n",
      "39m 9s (- 31m 31s) (55400 55%) 4.9892\n",
      "39m 13s (- 31m 27s) (55500 55%) 4.9918\n",
      "39m 18s (- 31m 23s) (55600 55%) 5.0098\n",
      "39m 22s (- 31m 18s) (55700 55%) 4.9000\n",
      "39m 26s (- 31m 14s) (55800 55%) 4.9573\n",
      "39m 31s (- 31m 10s) (55900 55%) 5.1894\n",
      "39m 35s (- 31m 6s) (56000 56%) 5.2747\n",
      "39m 39s (- 31m 2s) (56100 56%) 4.9480\n",
      "39m 43s (- 30m 57s) (56200 56%) 5.0736\n",
      "39m 48s (- 30m 53s) (56300 56%) 4.8458\n",
      "39m 52s (- 30m 49s) (56400 56%) 5.1170\n",
      "39m 56s (- 30m 45s) (56500 56%) 5.0678\n",
      "40m 0s (- 30m 40s) (56600 56%) 4.9461\n",
      "40m 5s (- 30m 36s) (56700 56%) 5.2588\n",
      "40m 9s (- 30m 32s) (56800 56%) 4.8574\n",
      "40m 13s (- 30m 28s) (56900 56%) 5.1127\n",
      "40m 17s (- 30m 23s) (57000 56%) 5.1645\n",
      "40m 22s (- 30m 19s) (57100 57%) 4.8534\n",
      "40m 26s (- 30m 15s) (57200 57%) 4.9443\n",
      "40m 30s (- 30m 10s) (57300 57%) 5.0012\n",
      "40m 34s (- 30m 6s) (57400 57%) 5.1605\n",
      "40m 38s (- 30m 2s) (57500 57%) 5.0121\n",
      "40m 42s (- 29m 57s) (57600 57%) 4.8779\n",
      "40m 46s (- 29m 53s) (57700 57%) 5.1153\n",
      "40m 50s (- 29m 49s) (57800 57%) 4.9543\n",
      "40m 54s (- 29m 45s) (57900 57%) 5.0726\n",
      "40m 59s (- 29m 41s) (58000 57%) 4.8708\n",
      "41m 4s (- 29m 36s) (58100 58%) 4.9561\n",
      "41m 8s (- 29m 32s) (58200 58%) 4.9820\n",
      "41m 12s (- 29m 28s) (58300 58%) 4.9975\n",
      "41m 17s (- 29m 24s) (58400 58%) 5.0466\n",
      "41m 21s (- 29m 20s) (58500 58%) 5.0805\n",
      "41m 26s (- 29m 16s) (58600 58%) 4.7635\n",
      "41m 30s (- 29m 12s) (58700 58%) 5.1223\n",
      "41m 34s (- 29m 8s) (58800 58%) 4.8419\n",
      "41m 39s (- 29m 4s) (58900 58%) 5.2065\n",
      "41m 43s (- 28m 59s) (59000 59%) 4.9585\n",
      "41m 48s (- 28m 55s) (59100 59%) 5.1883\n",
      "41m 52s (- 28m 51s) (59200 59%) 4.9602\n",
      "41m 56s (- 28m 47s) (59300 59%) 4.8820\n",
      "42m 1s (- 28m 43s) (59400 59%) 5.0375\n",
      "42m 5s (- 28m 39s) (59500 59%) 5.1371\n",
      "42m 9s (- 28m 34s) (59600 59%) 5.2155\n",
      "42m 13s (- 28m 30s) (59700 59%) 4.9583\n",
      "42m 17s (- 28m 25s) (59800 59%) 4.8072\n",
      "42m 21s (- 28m 21s) (59900 59%) 4.9663\n",
      "42m 25s (- 28m 17s) (60000 60%) 4.8987\n",
      "42m 29s (- 28m 12s) (60100 60%) 5.0149\n",
      "42m 34s (- 28m 8s) (60200 60%) 5.0899\n",
      "42m 39s (- 28m 5s) (60300 60%) 5.0379\n",
      "42m 43s (- 28m 0s) (60400 60%) 5.0064\n",
      "42m 48s (- 27m 56s) (60500 60%) 5.0035\n",
      "42m 52s (- 27m 52s) (60600 60%) 4.9974\n",
      "42m 56s (- 27m 48s) (60700 60%) 4.8193\n",
      "43m 1s (- 27m 44s) (60800 60%) 4.9512\n",
      "43m 6s (- 27m 40s) (60900 60%) 5.1638\n",
      "43m 10s (- 27m 36s) (61000 61%) 4.8820\n",
      "43m 14s (- 27m 31s) (61100 61%) 4.7910\n",
      "43m 19s (- 27m 27s) (61200 61%) 5.1019\n",
      "43m 23s (- 27m 23s) (61300 61%) 4.8336\n",
      "43m 27s (- 27m 19s) (61400 61%) 4.9180\n",
      "43m 31s (- 27m 14s) (61500 61%) 4.9305\n",
      "43m 35s (- 27m 10s) (61600 61%) 4.9835\n",
      "43m 39s (- 27m 6s) (61700 61%) 4.8780\n",
      "43m 43s (- 27m 1s) (61800 61%) 4.8355\n",
      "43m 48s (- 26m 57s) (61900 61%) 4.9613\n",
      "43m 52s (- 26m 53s) (62000 62%) 4.9414\n",
      "43m 57s (- 26m 49s) (62100 62%) 5.0609\n",
      "44m 1s (- 26m 45s) (62200 62%) 4.8792\n",
      "44m 6s (- 26m 41s) (62300 62%) 4.8807\n",
      "44m 10s (- 26m 37s) (62400 62%) 4.8569\n",
      "44m 14s (- 26m 32s) (62500 62%) 4.9216\n",
      "44m 18s (- 26m 28s) (62600 62%) 4.8943\n",
      "44m 23s (- 26m 24s) (62700 62%) 5.1804\n",
      "44m 27s (- 26m 20s) (62800 62%) 4.8104\n",
      "44m 31s (- 26m 15s) (62900 62%) 5.1061\n",
      "44m 36s (- 26m 11s) (63000 63%) 5.2695\n",
      "44m 40s (- 26m 7s) (63100 63%) 4.6343\n",
      "44m 44s (- 26m 3s) (63200 63%) 5.0114\n",
      "44m 48s (- 25m 59s) (63300 63%) 4.9188\n",
      "44m 53s (- 25m 54s) (63400 63%) 4.9732\n",
      "44m 57s (- 25m 50s) (63500 63%) 4.9517\n",
      "45m 2s (- 25m 46s) (63600 63%) 5.2084\n",
      "45m 6s (- 25m 42s) (63700 63%) 4.9544\n",
      "45m 11s (- 25m 38s) (63800 63%) 4.8853\n",
      "45m 14s (- 25m 33s) (63900 63%) 4.7499\n",
      "45m 19s (- 25m 29s) (64000 64%) 5.0240\n",
      "45m 23s (- 25m 25s) (64100 64%) 5.0895\n",
      "45m 28s (- 25m 21s) (64200 64%) 4.8955\n",
      "45m 32s (- 25m 17s) (64300 64%) 4.9225\n",
      "45m 36s (- 25m 12s) (64400 64%) 4.9417\n",
      "45m 41s (- 25m 9s) (64500 64%) 5.1970\n",
      "45m 46s (- 25m 5s) (64600 64%) 5.1265\n",
      "45m 50s (- 25m 0s) (64700 64%) 4.8523\n",
      "45m 54s (- 24m 56s) (64800 64%) 4.9532\n",
      "45m 58s (- 24m 52s) (64900 64%) 4.7826\n",
      "46m 3s (- 24m 47s) (65000 65%) 4.8958\n",
      "46m 7s (- 24m 43s) (65100 65%) 5.1351\n",
      "46m 12s (- 24m 39s) (65200 65%) 5.2528\n",
      "46m 16s (- 24m 35s) (65300 65%) 4.8364\n",
      "46m 21s (- 24m 31s) (65400 65%) 4.8790\n",
      "46m 25s (- 24m 26s) (65500 65%) 4.8347\n",
      "46m 29s (- 24m 22s) (65600 65%) 4.8705\n",
      "46m 33s (- 24m 18s) (65700 65%) 4.9759\n",
      "46m 37s (- 24m 14s) (65800 65%) 4.9076\n",
      "46m 41s (- 24m 9s) (65900 65%) 5.1117\n",
      "46m 46s (- 24m 5s) (66000 66%) 5.1340\n",
      "46m 50s (- 24m 1s) (66100 66%) 4.8976\n",
      "46m 54s (- 23m 56s) (66200 66%) 4.8404\n",
      "46m 58s (- 23m 52s) (66300 66%) 4.9941\n",
      "47m 2s (- 23m 48s) (66400 66%) 4.8976\n",
      "47m 6s (- 23m 44s) (66500 66%) 4.9133\n",
      "47m 11s (- 23m 39s) (66600 66%) 5.0431\n",
      "47m 15s (- 23m 35s) (66700 66%) 5.0038\n",
      "47m 19s (- 23m 31s) (66800 66%) 4.8517\n",
      "47m 24s (- 23m 27s) (66900 66%) 4.9326\n",
      "47m 28s (- 23m 23s) (67000 67%) 4.9635\n",
      "47m 32s (- 23m 18s) (67100 67%) 4.8729\n",
      "47m 37s (- 23m 14s) (67200 67%) 5.0671\n",
      "47m 41s (- 23m 10s) (67300 67%) 4.9859\n",
      "47m 45s (- 23m 6s) (67400 67%) 4.7646\n",
      "47m 50s (- 23m 1s) (67500 67%) 4.9539\n",
      "47m 55s (- 22m 58s) (67600 67%) 5.1185\n",
      "47m 59s (- 22m 53s) (67700 67%) 4.9343\n",
      "48m 3s (- 22m 49s) (67800 67%) 4.9022\n",
      "48m 8s (- 22m 45s) (67900 67%) 4.9531\n",
      "48m 12s (- 22m 41s) (68000 68%) 4.9017\n",
      "48m 17s (- 22m 37s) (68100 68%) 4.9693\n",
      "48m 21s (- 22m 33s) (68200 68%) 4.9816\n",
      "48m 26s (- 22m 28s) (68300 68%) 4.9271\n",
      "48m 30s (- 22m 24s) (68400 68%) 4.9392\n",
      "48m 35s (- 22m 20s) (68500 68%) 4.9549\n",
      "48m 39s (- 22m 16s) (68600 68%) 4.8561\n",
      "48m 43s (- 22m 12s) (68700 68%) 4.9641\n",
      "48m 48s (- 22m 8s) (68800 68%) 5.0320\n",
      "48m 52s (- 22m 3s) (68900 68%) 4.9523\n",
      "48m 57s (- 21m 59s) (69000 69%) 4.9134\n",
      "49m 1s (- 21m 55s) (69100 69%) 4.7483\n",
      "49m 5s (- 21m 51s) (69200 69%) 4.9664\n",
      "49m 10s (- 21m 46s) (69300 69%) 4.8371\n",
      "49m 14s (- 21m 42s) (69400 69%) 5.0039\n",
      "49m 18s (- 21m 38s) (69500 69%) 4.8415\n",
      "49m 23s (- 21m 34s) (69600 69%) 4.8662\n",
      "49m 27s (- 21m 29s) (69700 69%) 4.7594\n",
      "49m 31s (- 21m 25s) (69800 69%) 5.1050\n",
      "49m 35s (- 21m 21s) (69900 69%) 4.7012\n",
      "49m 39s (- 21m 16s) (70000 70%) 5.0870\n",
      "49m 43s (- 21m 12s) (70100 70%) 4.7577\n",
      "49m 48s (- 21m 8s) (70200 70%) 5.0735\n",
      "49m 53s (- 21m 4s) (70300 70%) 4.8210\n",
      "49m 57s (- 21m 0s) (70400 70%) 5.0823\n",
      "50m 1s (- 20m 56s) (70500 70%) 5.0115\n",
      "50m 6s (- 20m 51s) (70600 70%) 4.9457\n",
      "50m 11s (- 20m 47s) (70700 70%) 5.0694\n",
      "50m 15s (- 20m 43s) (70800 70%) 4.6153\n",
      "50m 19s (- 20m 39s) (70900 70%) 4.9776\n",
      "50m 24s (- 20m 35s) (71000 71%) 4.8446\n",
      "50m 28s (- 20m 31s) (71100 71%) 4.8818\n",
      "50m 33s (- 20m 26s) (71200 71%) 4.9188\n",
      "50m 37s (- 20m 22s) (71300 71%) 4.9053\n",
      "50m 42s (- 20m 18s) (71400 71%) 4.9772\n",
      "50m 46s (- 20m 14s) (71500 71%) 5.0122\n",
      "50m 50s (- 20m 10s) (71600 71%) 4.8610\n",
      "50m 55s (- 20m 5s) (71700 71%) 4.9455\n",
      "50m 59s (- 20m 1s) (71800 71%) 4.9314\n",
      "51m 3s (- 19m 57s) (71900 71%) 4.9241\n",
      "51m 7s (- 19m 53s) (72000 72%) 4.9140\n",
      "51m 11s (- 19m 48s) (72100 72%) 5.0449\n",
      "51m 15s (- 19m 44s) (72200 72%) 4.7334\n",
      "51m 20s (- 19m 40s) (72300 72%) 5.0464\n",
      "51m 24s (- 19m 35s) (72400 72%) 4.9219\n",
      "51m 29s (- 19m 31s) (72500 72%) 4.7819\n",
      "51m 33s (- 19m 27s) (72600 72%) 4.8292\n",
      "51m 37s (- 19m 23s) (72700 72%) 4.7926\n",
      "51m 42s (- 19m 19s) (72800 72%) 4.7833\n",
      "51m 47s (- 19m 15s) (72900 72%) 5.0569\n",
      "51m 51s (- 19m 10s) (73000 73%) 4.7913\n",
      "51m 55s (- 19m 6s) (73100 73%) 4.8786\n",
      "52m 0s (- 19m 2s) (73200 73%) 5.0389\n",
      "52m 4s (- 18m 58s) (73300 73%) 4.6194\n",
      "52m 8s (- 18m 53s) (73400 73%) 4.8314\n",
      "52m 12s (- 18m 49s) (73500 73%) 5.0188\n",
      "52m 16s (- 18m 45s) (73600 73%) 4.9681\n",
      "52m 20s (- 18m 40s) (73700 73%) 4.7655\n",
      "52m 25s (- 18m 36s) (73800 73%) 4.9313\n",
      "52m 29s (- 18m 32s) (73900 73%) 4.8055\n",
      "52m 33s (- 18m 27s) (74000 74%) 4.7230\n",
      "52m 37s (- 18m 23s) (74100 74%) 4.7590\n",
      "52m 42s (- 18m 19s) (74200 74%) 4.8275\n",
      "52m 46s (- 18m 15s) (74300 74%) 4.9230\n",
      "52m 51s (- 18m 11s) (74400 74%) 5.0270\n",
      "52m 55s (- 18m 6s) (74500 74%) 4.8881\n",
      "52m 59s (- 18m 2s) (74600 74%) 4.7539\n",
      "53m 4s (- 17m 58s) (74700 74%) 4.9710\n",
      "53m 8s (- 17m 54s) (74800 74%) 4.9386\n",
      "53m 12s (- 17m 50s) (74900 74%) 4.8988\n",
      "53m 17s (- 17m 45s) (75000 75%) 5.2233\n",
      "53m 21s (- 17m 41s) (75100 75%) 4.9385\n",
      "53m 25s (- 17m 37s) (75200 75%) 4.9144\n",
      "53m 29s (- 17m 32s) (75300 75%) 4.6329\n",
      "53m 33s (- 17m 28s) (75400 75%) 5.1227\n",
      "53m 38s (- 17m 24s) (75500 75%) 4.9331\n",
      "53m 42s (- 17m 20s) (75600 75%) 4.9513\n",
      "53m 46s (- 17m 15s) (75700 75%) 4.8307\n",
      "53m 50s (- 17m 11s) (75800 75%) 4.9528\n",
      "53m 54s (- 17m 7s) (75900 75%) 4.7952\n",
      "53m 58s (- 17m 2s) (76000 76%) 4.9523\n",
      "54m 2s (- 16m 58s) (76100 76%) 4.7600\n",
      "54m 7s (- 16m 54s) (76200 76%) 4.9760\n",
      "54m 11s (- 16m 49s) (76300 76%) 4.9825\n",
      "54m 15s (- 16m 45s) (76400 76%) 4.8876\n",
      "54m 19s (- 16m 41s) (76500 76%) 4.9922\n",
      "54m 23s (- 16m 37s) (76600 76%) 5.0231\n",
      "54m 27s (- 16m 32s) (76700 76%) 4.8816\n",
      "54m 32s (- 16m 28s) (76800 76%) 4.7055\n",
      "54m 35s (- 16m 24s) (76900 76%) 4.8538\n",
      "54m 40s (- 16m 19s) (77000 77%) 4.9964\n",
      "54m 44s (- 16m 15s) (77100 77%) 4.7804\n",
      "54m 48s (- 16m 11s) (77200 77%) 5.0841\n",
      "54m 53s (- 16m 7s) (77300 77%) 4.8193\n",
      "54m 57s (- 16m 2s) (77400 77%) 4.9029\n",
      "55m 2s (- 15m 58s) (77500 77%) 4.8036\n",
      "55m 6s (- 15m 54s) (77600 77%) 4.6575\n",
      "55m 10s (- 15m 50s) (77700 77%) 4.8011\n",
      "55m 15s (- 15m 45s) (77800 77%) 5.0419\n",
      "55m 19s (- 15m 41s) (77900 77%) 4.8437\n",
      "55m 23s (- 15m 37s) (78000 78%) 4.8018\n",
      "55m 28s (- 15m 33s) (78100 78%) 4.7961\n",
      "55m 32s (- 15m 29s) (78200 78%) 4.9180\n",
      "55m 37s (- 15m 24s) (78300 78%) 4.6851\n",
      "55m 41s (- 15m 20s) (78400 78%) 4.7801\n",
      "55m 45s (- 15m 16s) (78500 78%) 4.8142\n",
      "55m 50s (- 15m 12s) (78600 78%) 4.7493\n",
      "55m 54s (- 15m 7s) (78700 78%) 4.8909\n",
      "55m 59s (- 15m 3s) (78800 78%) 4.9339\n",
      "56m 4s (- 14m 59s) (78900 78%) 5.1928\n",
      "56m 8s (- 14m 55s) (79000 79%) 4.9299\n",
      "56m 13s (- 14m 51s) (79100 79%) 4.9492\n",
      "56m 17s (- 14m 47s) (79200 79%) 4.9166\n",
      "56m 22s (- 14m 42s) (79300 79%) 5.0223\n",
      "56m 26s (- 14m 38s) (79400 79%) 4.7913\n",
      "56m 30s (- 14m 34s) (79500 79%) 5.0916\n",
      "56m 34s (- 14m 30s) (79600 79%) 4.7765\n",
      "56m 38s (- 14m 25s) (79700 79%) 4.9199\n",
      "56m 43s (- 14m 21s) (79800 79%) 4.9262\n",
      "56m 47s (- 14m 17s) (79900 79%) 4.8998\n",
      "56m 52s (- 14m 13s) (80000 80%) 4.9813\n",
      "56m 56s (- 14m 8s) (80100 80%) 5.1161\n",
      "57m 0s (- 14m 4s) (80200 80%) 4.9238\n",
      "57m 5s (- 14m 0s) (80300 80%) 4.7721\n",
      "57m 9s (- 13m 56s) (80400 80%) 4.8482\n",
      "57m 14s (- 13m 51s) (80500 80%) 4.8350\n",
      "57m 18s (- 13m 47s) (80600 80%) 4.5866\n",
      "57m 22s (- 13m 43s) (80700 80%) 4.7729\n",
      "57m 26s (- 13m 39s) (80800 80%) 4.8027\n",
      "57m 31s (- 13m 34s) (80900 80%) 5.0357\n",
      "57m 36s (- 13m 30s) (81000 81%) 5.1761\n",
      "57m 40s (- 13m 26s) (81100 81%) 4.9341\n",
      "57m 44s (- 13m 22s) (81200 81%) 4.7993\n",
      "57m 49s (- 13m 18s) (81300 81%) 5.0287\n",
      "57m 54s (- 13m 13s) (81400 81%) 4.8931\n",
      "57m 58s (- 13m 9s) (81500 81%) 4.8585\n",
      "58m 2s (- 13m 5s) (81600 81%) 4.9012\n",
      "58m 6s (- 13m 1s) (81700 81%) 4.8037\n",
      "58m 11s (- 12m 56s) (81800 81%) 4.7157\n",
      "58m 15s (- 12m 52s) (81900 81%) 4.9116\n",
      "58m 19s (- 12m 48s) (82000 82%) 4.9322\n",
      "58m 23s (- 12m 43s) (82100 82%) 4.6601\n",
      "58m 28s (- 12m 39s) (82200 82%) 4.8144\n",
      "58m 32s (- 12m 35s) (82300 82%) 4.9765\n",
      "58m 36s (- 12m 31s) (82400 82%) 4.9538\n",
      "58m 41s (- 12m 26s) (82500 82%) 5.1305\n",
      "58m 45s (- 12m 22s) (82600 82%) 4.8101\n",
      "58m 49s (- 12m 18s) (82700 82%) 4.8600\n",
      "58m 54s (- 12m 14s) (82800 82%) 4.8315\n",
      "58m 58s (- 12m 9s) (82900 82%) 4.7070\n",
      "59m 2s (- 12m 5s) (83000 83%) 4.8017\n",
      "59m 6s (- 12m 1s) (83100 83%) 4.9030\n",
      "59m 11s (- 11m 57s) (83200 83%) 4.9072\n",
      "59m 15s (- 11m 52s) (83300 83%) 4.9145\n",
      "59m 19s (- 11m 48s) (83400 83%) 5.0755\n",
      "59m 24s (- 11m 44s) (83500 83%) 4.8775\n",
      "59m 28s (- 11m 40s) (83600 83%) 4.7649\n",
      "59m 32s (- 11m 35s) (83700 83%) 4.7106\n",
      "59m 36s (- 11m 31s) (83800 83%) 4.8691\n",
      "59m 41s (- 11m 27s) (83900 83%) 5.1593\n",
      "59m 45s (- 11m 23s) (84000 84%) 4.9197\n",
      "59m 49s (- 11m 18s) (84100 84%) 4.8539\n",
      "59m 54s (- 11m 14s) (84200 84%) 4.8520\n",
      "59m 58s (- 11m 10s) (84300 84%) 5.0084\n",
      "60m 3s (- 11m 5s) (84400 84%) 4.9353\n",
      "60m 7s (- 11m 1s) (84500 84%) 4.8560\n",
      "60m 11s (- 10m 57s) (84600 84%) 4.8180\n",
      "60m 15s (- 10m 53s) (84700 84%) 4.9383\n",
      "60m 20s (- 10m 48s) (84800 84%) 4.9256\n",
      "60m 24s (- 10m 44s) (84900 84%) 5.0371\n",
      "60m 29s (- 10m 40s) (85000 85%) 4.7767\n",
      "60m 33s (- 10m 36s) (85100 85%) 4.7785\n",
      "60m 38s (- 10m 32s) (85200 85%) 5.0732\n",
      "60m 43s (- 10m 27s) (85300 85%) 5.1030\n",
      "60m 47s (- 10m 23s) (85400 85%) 4.7170\n",
      "60m 52s (- 10m 19s) (85500 85%) 4.8492\n",
      "60m 56s (- 10m 15s) (85600 85%) 4.7276\n",
      "61m 1s (- 10m 10s) (85700 85%) 4.8309\n",
      "61m 5s (- 10m 6s) (85800 85%) 4.8329\n",
      "61m 9s (- 10m 2s) (85900 85%) 4.7664\n",
      "61m 14s (- 9m 58s) (86000 86%) 4.8068\n",
      "61m 18s (- 9m 53s) (86100 86%) 4.8154\n",
      "61m 22s (- 9m 49s) (86200 86%) 4.9418\n",
      "61m 27s (- 9m 45s) (86300 86%) 4.9286\n",
      "61m 31s (- 9m 41s) (86400 86%) 4.8859\n",
      "61m 35s (- 9m 36s) (86500 86%) 4.9034\n",
      "61m 40s (- 9m 32s) (86600 86%) 4.8599\n",
      "61m 44s (- 9m 28s) (86700 86%) 4.9583\n",
      "61m 49s (- 9m 24s) (86800 86%) 4.8711\n",
      "61m 53s (- 9m 19s) (86900 86%) 4.7209\n",
      "61m 57s (- 9m 15s) (87000 87%) 4.8226\n",
      "62m 2s (- 9m 11s) (87100 87%) 4.9130\n",
      "62m 6s (- 9m 7s) (87200 87%) 5.0039\n",
      "62m 11s (- 9m 2s) (87300 87%) 4.8472\n",
      "62m 15s (- 8m 58s) (87400 87%) 5.2279\n",
      "62m 19s (- 8m 54s) (87500 87%) 5.0809\n",
      "62m 23s (- 8m 49s) (87600 87%) 4.7886\n",
      "62m 27s (- 8m 45s) (87700 87%) 4.6408\n",
      "62m 32s (- 8m 41s) (87800 87%) 4.7928\n",
      "62m 37s (- 8m 37s) (87900 87%) 5.0303\n",
      "62m 41s (- 8m 32s) (88000 88%) 4.9226\n",
      "62m 45s (- 8m 28s) (88100 88%) 4.6693\n",
      "62m 49s (- 8m 24s) (88200 88%) 4.8320\n",
      "62m 53s (- 8m 20s) (88300 88%) 4.8705\n",
      "62m 58s (- 8m 15s) (88400 88%) 4.9518\n",
      "63m 3s (- 8m 11s) (88500 88%) 5.0793\n",
      "63m 7s (- 8m 7s) (88600 88%) 5.0608\n",
      "63m 12s (- 8m 3s) (88700 88%) 4.9150\n",
      "63m 16s (- 7m 58s) (88800 88%) 4.7724\n",
      "63m 20s (- 7m 54s) (88900 88%) 5.0063\n",
      "63m 25s (- 7m 50s) (89000 89%) 4.8423\n",
      "63m 29s (- 7m 46s) (89100 89%) 4.8014\n",
      "63m 33s (- 7m 41s) (89200 89%) 4.9556\n",
      "63m 37s (- 7m 37s) (89300 89%) 5.1273\n",
      "63m 42s (- 7m 33s) (89400 89%) 5.0334\n",
      "63m 46s (- 7m 28s) (89500 89%) 4.8590\n",
      "63m 51s (- 7m 24s) (89600 89%) 4.8695\n",
      "63m 56s (- 7m 20s) (89700 89%) 4.9491\n",
      "64m 0s (- 7m 16s) (89800 89%) 4.7347\n",
      "64m 4s (- 7m 11s) (89900 89%) 4.8822\n",
      "64m 9s (- 7m 7s) (90000 90%) 4.9337\n",
      "64m 13s (- 7m 3s) (90100 90%) 4.8769\n",
      "64m 18s (- 6m 59s) (90200 90%) 4.9666\n",
      "64m 22s (- 6m 54s) (90300 90%) 4.9939\n",
      "64m 27s (- 6m 50s) (90400 90%) 4.9772\n",
      "64m 31s (- 6m 46s) (90500 90%) 4.7168\n",
      "64m 36s (- 6m 42s) (90600 90%) 4.8798\n",
      "64m 40s (- 6m 37s) (90700 90%) 5.0146\n",
      "64m 44s (- 6m 33s) (90800 90%) 4.9225\n",
      "64m 48s (- 6m 29s) (90900 90%) 4.6928\n",
      "64m 53s (- 6m 25s) (91000 91%) 4.5947\n",
      "64m 57s (- 6m 20s) (91100 91%) 4.7937\n",
      "65m 2s (- 6m 16s) (91200 91%) 4.8049\n",
      "65m 6s (- 6m 12s) (91300 91%) 4.7263\n",
      "65m 10s (- 6m 7s) (91400 91%) 4.7513\n",
      "65m 14s (- 6m 3s) (91500 91%) 4.7091\n",
      "65m 19s (- 5m 59s) (91600 91%) 4.8209\n",
      "65m 23s (- 5m 55s) (91700 91%) 4.7480\n",
      "65m 28s (- 5m 50s) (91800 91%) 4.6680\n",
      "65m 32s (- 5m 46s) (91900 91%) 4.9756\n",
      "65m 37s (- 5m 42s) (92000 92%) 4.8718\n",
      "65m 41s (- 5m 38s) (92100 92%) 4.9746\n",
      "65m 46s (- 5m 33s) (92200 92%) 4.7132\n",
      "65m 50s (- 5m 29s) (92300 92%) 4.9082\n",
      "65m 54s (- 5m 25s) (92400 92%) 4.7335\n",
      "65m 59s (- 5m 21s) (92500 92%) 4.8886\n",
      "66m 3s (- 5m 16s) (92600 92%) 5.0595\n",
      "66m 7s (- 5m 12s) (92700 92%) 4.8292\n",
      "66m 11s (- 5m 8s) (92800 92%) 4.8734\n",
      "66m 15s (- 5m 3s) (92900 92%) 4.9021\n",
      "66m 20s (- 4m 59s) (93000 93%) 4.9442\n",
      "66m 24s (- 4m 55s) (93100 93%) 4.6979\n",
      "66m 29s (- 4m 51s) (93200 93%) 4.8112\n",
      "66m 33s (- 4m 46s) (93300 93%) 5.0609\n",
      "66m 37s (- 4m 42s) (93400 93%) 4.9664\n",
      "66m 41s (- 4m 38s) (93500 93%) 4.8560\n",
      "66m 45s (- 4m 33s) (93600 93%) 4.7465\n",
      "66m 50s (- 4m 29s) (93700 93%) 4.8480\n",
      "66m 54s (- 4m 25s) (93800 93%) 4.6464\n",
      "66m 58s (- 4m 21s) (93900 93%) 4.7756\n",
      "67m 3s (- 4m 16s) (94000 94%) 4.9211\n",
      "67m 7s (- 4m 12s) (94100 94%) 4.7959\n",
      "67m 12s (- 4m 8s) (94200 94%) 4.9561\n",
      "67m 16s (- 4m 4s) (94300 94%) 4.9606\n",
      "67m 21s (- 3m 59s) (94400 94%) 4.9725\n",
      "67m 26s (- 3m 55s) (94500 94%) 4.8806\n",
      "67m 30s (- 3m 51s) (94600 94%) 5.0872\n",
      "67m 34s (- 3m 46s) (94700 94%) 4.7750\n",
      "67m 39s (- 3m 42s) (94800 94%) 5.0082\n",
      "67m 43s (- 3m 38s) (94900 94%) 4.7223\n",
      "67m 48s (- 3m 34s) (95000 95%) 4.9962\n",
      "67m 52s (- 3m 29s) (95100 95%) 4.4514\n",
      "67m 56s (- 3m 25s) (95200 95%) 4.8619\n",
      "68m 1s (- 3m 21s) (95300 95%) 4.8265\n",
      "68m 5s (- 3m 16s) (95400 95%) 4.9627\n",
      "68m 9s (- 3m 12s) (95500 95%) 5.0707\n",
      "68m 14s (- 3m 8s) (95600 95%) 4.8570\n",
      "68m 18s (- 3m 4s) (95700 95%) 4.6283\n",
      "68m 22s (- 2m 59s) (95800 95%) 4.9381\n",
      "68m 27s (- 2m 55s) (95900 95%) 4.6219\n",
      "68m 31s (- 2m 51s) (96000 96%) 4.8753\n",
      "68m 35s (- 2m 47s) (96100 96%) 5.0009\n",
      "68m 39s (- 2m 42s) (96200 96%) 4.8909\n",
      "68m 43s (- 2m 38s) (96300 96%) 4.6750\n",
      "68m 47s (- 2m 34s) (96400 96%) 4.7812\n",
      "68m 52s (- 2m 29s) (96500 96%) 4.9047\n",
      "68m 56s (- 2m 25s) (96600 96%) 4.6870\n",
      "69m 1s (- 2m 21s) (96700 96%) 4.8469\n",
      "69m 5s (- 2m 17s) (96800 96%) 4.8497\n",
      "69m 9s (- 2m 12s) (96900 96%) 4.9317\n",
      "69m 14s (- 2m 8s) (97000 97%) 4.7568\n",
      "69m 17s (- 2m 4s) (97100 97%) 4.4337\n",
      "69m 22s (- 1m 59s) (97200 97%) 4.8345\n",
      "69m 26s (- 1m 55s) (97300 97%) 5.0333\n",
      "69m 30s (- 1m 51s) (97400 97%) 4.9489\n",
      "69m 34s (- 1m 47s) (97500 97%) 4.8034\n",
      "69m 39s (- 1m 42s) (97600 97%) 4.7094\n",
      "69m 43s (- 1m 38s) (97700 97%) 4.6847\n",
      "69m 47s (- 1m 34s) (97800 97%) 4.7834\n",
      "69m 52s (- 1m 29s) (97900 97%) 4.8839\n",
      "69m 56s (- 1m 25s) (98000 98%) 5.0656\n",
      "70m 0s (- 1m 21s) (98100 98%) 4.6178\n",
      "70m 4s (- 1m 17s) (98200 98%) 4.7730\n",
      "70m 8s (- 1m 12s) (98300 98%) 4.7498\n",
      "70m 13s (- 1m 8s) (98400 98%) 4.9710\n",
      "70m 17s (- 1m 4s) (98500 98%) 4.7677\n",
      "70m 22s (- 0m 59s) (98600 98%) 4.9397\n",
      "70m 26s (- 0m 55s) (98700 98%) 4.8760\n",
      "70m 31s (- 0m 51s) (98800 98%) 4.7833\n",
      "70m 35s (- 0m 47s) (98900 98%) 4.9044\n",
      "70m 40s (- 0m 42s) (99000 99%) 5.0084\n",
      "70m 44s (- 0m 38s) (99100 99%) 4.7063\n",
      "70m 48s (- 0m 34s) (99200 99%) 4.8029\n",
      "70m 53s (- 0m 29s) (99300 99%) 4.8951\n",
      "70m 57s (- 0m 25s) (99400 99%) 5.1122\n",
      "71m 2s (- 0m 21s) (99500 99%) 4.9999\n",
      "71m 6s (- 0m 17s) (99600 99%) 4.5974\n",
      "71m 11s (- 0m 12s) (99700 99%) 4.7840\n",
      "71m 15s (- 0m 8s) (99800 99%) 4.7779\n",
      "71m 20s (- 0m 4s) (99900 99%) 4.8915\n",
      "71m 25s (- 0m 0s) (100000 100%) 4.8921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batches = 100000 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 100\n",
    "\n",
    "my_encoder = EncoderRNN(len(english_vocab), hidden_size)\n",
    "my_decoder = AttnDecoderRNN(hidden_size, len(indo_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()\n",
    "\n",
    "\n",
    "# Load the pre-trained model with teacher forcing.\n",
    "\"\"\"\n",
    "with open('encoder_attention_100_100000_0.5.pkl', 'rb') as fin:\n",
    "    my_encoder = pickle.load(fin)\n",
    "    \n",
    "with open('decoder_attention_100_100000_0.5.pkl', 'rb') as fin:\n",
    "    my_decoder = pickle.load(fin)\n",
    "\"\"\"\n",
    "\n",
    "# Or train a new model; un-comment the following lines\n",
    "\n",
    "train(my_encoder, my_decoder, batches, print_every=100)\n",
    "# In Python >= 3.6\n",
    "with open(f'encoder_attention_{hidden_size}_{batches}_{teacher_forcing_ratio}.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_encoder, fout)\n",
    "with open(f'decoder_attention_{hidden_size}_{batches}_{teacher_forcing_ratio}.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_decoder, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(encoder, decoder, input_variable, max_length=MAX_LENGTH):\n",
    "    # The length of the input.\n",
    "    input_length = input_variable.size()[0]\n",
    "    # For each sentence, initilize the hidden states with zeros.\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "    # Initialize the encoder outputs. \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    # Iterate through the input words.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "    # Initialize the decoder with the start symbol <s>.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]])) \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    # Use the last encoder hidden state as the first decoder's hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # Keep a list of the decoded words.\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Iterate through the decoder states.\n",
    "    for di in range(max_length):\n",
    "        # Very similar to how the training works.\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                    decoder_hidden,\n",
    "                                                                    encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == END_IDX:\n",
    "            decoded_words.append(END_IDX)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(ni.item())# changed from ni to ni.item() : Pier FIXED\n",
    "        # Replace the new decoder input for the next state \n",
    "        # with the top guess of this state.\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "    \n",
    "def translate(english_text):\n",
    "    output_words, _ = translator(my_encoder, my_decoder, variable_from_sent(english_text, english_vocab))\n",
    "    print(output_words)\n",
    "    output_sentence = [indo_vocab[i] for i in output_words[1:output_words.index(1)]]\n",
    "    return ' '.join(output_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4281, 39, 15, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e ) yang'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('French Muslims fined for face veils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100000\n",
      "encoder_attention_100_100000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "# print(hidden_size, batches)\n",
    "# print(f'encoder_attention_{hidden_size}_{batches}.pkl')\n",
    "\n",
    "# # In Python >= 3.6\n",
    "# with open(f'./models/encoder_attention_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "#     pickle.dump(my_encoder, fout)\n",
    "# with open(f'./models/decoder_attention_{hidden_size}_{batches}.pkl', 'wb') as fout:\n",
    "#     pickle.dump(my_decoder, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
